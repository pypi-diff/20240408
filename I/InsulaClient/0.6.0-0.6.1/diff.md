# Comparing `tmp/insulaclient-0.6.0-py3-none-any.whl.zip` & `tmp/insulaclient-0.6.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,30 +1,31 @@
-Zip file size: 22756 bytes, number of entries: 28
+Zip file size: 23256 bytes, number of entries: 29
 -rw-r--r--  2.0 fat     2765 b- defN 20-Feb-02 00:00 insulaClient/InsulaApiConfig.py
 -rw-r--r--  2.0 fat      565 b- defN 20-Feb-02 00:00 insulaClient/InsulaClient.py
 -rw-r--r--  2.0 fat      625 b- defN 20-Feb-02 00:00 insulaClient/InsulaQuery.py
 -rw-r--r--  2.0 fat     1365 b- defN 20-Feb-02 00:00 insulaClient/InsulaSearch.py
 -rw-r--r--  2.0 fat     1389 b- defN 20-Feb-02 00:00 insulaClient/SingletonMemoryManager.py
 -rw-r--r--  2.0 fat     1667 b- defN 20-Feb-02 00:00 insulaClient/WorkflowDataManager.py
--rw-r--r--  2.0 fat      374 b- defN 20-Feb-02 00:00 insulaClient/__init__.py
--rw-r--r--  2.0 fat      894 b- defN 20-Feb-02 00:00 insulaClient/delete.py
+-rw-r--r--  2.0 fat      390 b- defN 20-Feb-02 00:00 insulaClient/__init__.py
+-rw-r--r--  2.0 fat      928 b- defN 20-Feb-02 00:00 insulaClient/delete.py
 -rw-r--r--  2.0 fat     1933 b- defN 20-Feb-02 00:00 insulaClient/downloadJob_results.py
 -rw-r--r--  2.0 fat     1495 b- defN 20-Feb-02 00:00 insulaClient/files_job_result.py
 -rw-r--r--  2.0 fat      881 b- defN 20-Feb-02 00:00 insulaClient/job_logs.py
 -rw-r--r--  2.0 fat      785 b- defN 20-Feb-02 00:00 insulaClient/job_params.py
--rw-r--r--  2.0 fat     3525 b- defN 20-Feb-02 00:00 insulaClient/job_runner.py
+-rw-r--r--  2.0 fat     3558 b- defN 20-Feb-02 00:00 insulaClient/job_runner.py
 -rw-r--r--  2.0 fat     3153 b- defN 20-Feb-02 00:00 insulaClient/job_status.py
--rw-r--r--  2.0 fat     4619 b- defN 20-Feb-02 00:00 insulaClient/placeholders.py
--rw-r--r--  2.0 fat      743 b- defN 20-Feb-02 00:00 insulaClient/results_manager.py
--rw-r--r--  2.0 fat     1849 b- defN 20-Feb-02 00:00 insulaClient/s3.py
+-rw-r--r--  2.0 fat      262 b- defN 20-Feb-02 00:00 insulaClient/logger.py
+-rw-r--r--  2.0 fat     4617 b- defN 20-Feb-02 00:00 insulaClient/placeholders.py
+-rw-r--r--  2.0 fat     1341 b- defN 20-Feb-02 00:00 insulaClient/results_manager.py
+-rw-r--r--  2.0 fat     1894 b- defN 20-Feb-02 00:00 insulaClient/s3.py
 -rw-r--r--  2.0 fat      725 b- defN 20-Feb-02 00:00 insulaClient/step_result.py
 -rw-r--r--  2.0 fat      929 b- defN 20-Feb-02 00:00 insulaClient/utils.py
 -rw-r--r--  2.0 fat     4630 b- defN 20-Feb-02 00:00 insulaClient/workflow.py
--rw-r--r--  2.0 fat     6376 b- defN 20-Feb-02 00:00 insulaClient/workflow_manager.py
+-rw-r--r--  2.0 fat     6449 b- defN 20-Feb-02 00:00 insulaClient/workflow_manager.py
 -rw-r--r--  2.0 fat      818 b- defN 20-Feb-02 00:00 insulaClient/workflow_step.py
--rw-r--r--  2.0 fat    14584 b- defN 20-Feb-02 00:00 insulaClient/workflow_step_runner.py
-?rw-r--r--  2.0 fat     9960 b- defN 20-Feb-02 00:00 insulaclient-0.6.0.dist-info/METADATA
-?rw-r--r--  2.0 fat       87 b- defN 20-Feb-02 00:00 insulaclient-0.6.0.dist-info/WHEEL
-?rw-r--r--  2.0 fat       58 b- defN 20-Feb-02 00:00 insulaclient-0.6.0.dist-info/entry_points.txt
-?rw-r--r--  2.0 fat        0 b- defN 20-Feb-02 00:00 insulaclient-0.6.0.dist-info/licenses/LICENSE.txt
-?rw-r--r--  2.0 fat     2374 b- defN 20-Feb-02 00:00 insulaclient-0.6.0.dist-info/RECORD
-28 files, 69168 bytes uncompressed, 18910 bytes compressed:  72.7%
+-rw-r--r--  2.0 fat    14627 b- defN 20-Feb-02 00:00 insulaClient/workflow_step_runner.py
+?rw-r--r--  2.0 fat     9984 b- defN 20-Feb-02 00:00 insulaclient-0.6.1.dist-info/METADATA
+?rw-r--r--  2.0 fat       87 b- defN 20-Feb-02 00:00 insulaclient-0.6.1.dist-info/WHEEL
+?rw-r--r--  2.0 fat       58 b- defN 20-Feb-02 00:00 insulaclient-0.6.1.dist-info/entry_points.txt
+?rw-r--r--  2.0 fat        0 b- defN 20-Feb-02 00:00 insulaclient-0.6.1.dist-info/licenses/LICENSE.txt
+?rw-r--r--  2.0 fat     2453 b- defN 20-Feb-02 00:00 insulaclient-0.6.1.dist-info/RECORD
+29 files, 70373 bytes uncompressed, 19290 bytes compressed:  72.6%
```

## zipnote {}

```diff
@@ -36,14 +36,17 @@
 
 Filename: insulaClient/job_runner.py
 Comment: 
 
 Filename: insulaClient/job_status.py
 Comment: 
 
+Filename: insulaClient/logger.py
+Comment: 
+
 Filename: insulaClient/placeholders.py
 Comment: 
 
 Filename: insulaClient/results_manager.py
 Comment: 
 
 Filename: insulaClient/s3.py
@@ -63,23 +66,23 @@
 
 Filename: insulaClient/workflow_step.py
 Comment: 
 
 Filename: insulaClient/workflow_step_runner.py
 Comment: 
 
-Filename: insulaclient-0.6.0.dist-info/METADATA
+Filename: insulaclient-0.6.1.dist-info/METADATA
 Comment: 
 
-Filename: insulaclient-0.6.0.dist-info/WHEEL
+Filename: insulaclient-0.6.1.dist-info/WHEEL
 Comment: 
 
-Filename: insulaclient-0.6.0.dist-info/entry_points.txt
+Filename: insulaclient-0.6.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: insulaclient-0.6.0.dist-info/licenses/LICENSE.txt
+Filename: insulaclient-0.6.1.dist-info/licenses/LICENSE.txt
 Comment: 
 
-Filename: insulaclient-0.6.0.dist-info/RECORD
+Filename: insulaclient-0.6.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## insulaClient/__init__.py

```diff
@@ -1,11 +1,11 @@
 from snakenest import Nest
 from .workflow_manager import WorkflowManager
-from .results_manager import ResultsManager
+from .results_manager import ResultManager
 from .InsulaClient import InsulaClient
 from .InsulaQuery import InsulaQuery
 from .InsulaSearch import InsulaSearch
 from .InsulaApiConfig import InsulaApiConfig
 
 Nest.initialize()
 
-__all__ = ['InsulaClient', 'InsulaQuery', 'InsulaSearch', 'InsulaApiConfig']
+__all__ = ['InsulaClient', 'InsulaQuery', 'InsulaSearch', 'InsulaApiConfig', 'ResultManager']
```

## insulaClient/delete.py

```diff
@@ -1,11 +1,12 @@
 import requests
 from time import sleep
 from .InsulaApiConfig import InsulaApiConfig
 from .step_result import StepResult
+from .logger import logger
 
 
 class InsulaDeleter(object):
 
     def __init__(self, insula_config: InsulaApiConfig):
         super().__init__()
         self.__insula_api_config = insula_config
@@ -14,9 +15,9 @@
         for step_result in step_results:
             self.delete_file(step_result)
 
     def delete_file(self, step_result: StepResult):
         file_to_delete = self.__insula_api_config.get_delete_platform_file(step_result.get('id'))
         run_request = requests.delete(file_to_delete,
                                       headers=self.__insula_api_config.authorization_header)
-        # print(f'deleted file: {file_to_delete} status code: {run_request.status_code}')
+        # logger.info(f'deleted file: {file_to_delete} status code: {run_request.status_code}')
         sleep(self.__insula_api_config.delete_interval)
```

## insulaClient/job_runner.py

```diff
@@ -1,12 +1,13 @@
 import requests
 from time import sleep
 from .InsulaApiConfig import InsulaApiConfig
 from .job_params import InsulaJobParams
 from .job_status import InsulaJobStatus
+from .logger import logger
 
 
 class InsulaRunner(object):
     def __init__(self, insula_config: InsulaApiConfig):
         super().__init__()
         self.__insula_api_config = insula_config
         self.__status_attempts = 0
@@ -52,15 +53,15 @@
         url_status = self.__insula_api_config.get_job_status_api_path(job_id)
         status = requests.get(url_status, headers=self.__insula_api_config.headers)
 
         if status.status_code != 200:
             if self.__status_attempts >= 3:
                 raise Exception(f'Cant get status job: {job_id}')
             else:
-                print(f'Cant get status job: {job_id} at attempt {self.__status_attempts}')
+                logger.info(f'Cant get status job: {job_id} at attempt {self.__status_attempts}')
                 self.__status_attempts += 1
                 return 'RUNNING'
 
         self.__status_attempts = 0
 
         url_status_dict = status.json()
```

## insulaClient/placeholders.py

```diff
@@ -1,12 +1,12 @@
 from re import findall
 from snakenest import Poisoned
 from .step_result import StepResult
 from .WorkflowDataManager import WorkflowData
-from .results_manager import ResultsManager
+from .results_manager import ResultManager
 
 
 class LinePlaceholder(object):
     __pattern = '\\${(.*?)}'
 
     def __init__(self, line):
         super().__init__()
@@ -117,15 +117,15 @@
     def get_result(self) -> str:
         if len(self.__results) > 0:
             return self.__results[0].get('default')
         return ''
 
     # @staticmethod
     @Poisoned()
-    def __placeholders(self, line: str, workflow_data: WorkflowData, result_manager: ResultsManager) -> list[
+    def __placeholders(self, line: str, workflow_data: WorkflowData, result_manager: ResultManager) -> list[
         StepResult]:
         lp = LinePlaceholder(line)
 
         if not lp.has_matches:
             return [StepResult(default=line, value=line, type='placeholder')]
 
         match = lp.get_matches()
```

## insulaClient/results_manager.py

```diff
@@ -1,24 +1,51 @@
+from abc import ABC, abstractmethod
 from snakenest import Snake
 
 
-@Snake(name='memory_results_manager')
-class ResultsManager(object):
+class ResultManager(ABC):
+
+    @abstractmethod
+    def get_result_steps(self, identifier) -> list:
+        pass
+
+    @abstractmethod
+    def add_result_step(self, identifier, step):
+        pass
+
+    @abstractmethod
+    def delete(self, identifier):
+        pass
+
+    @abstractmethod
+    def name(self):
+        pass
+
+
+@Snake(having={'${insulaclient.result_manager.snake:memory}': 'memory'})
+class MemoryResultsManager(ResultManager):
+
+    def delete(self, identifier):
+        if identifier in self.__step_results:
+            del self.__step_results[identifier]
+
+    def name(self):
+        return 'MemoryResultsManager'
 
     def __init__(self):
         super().__init__()
         self.__step_results = {}
 
     def get_result_steps(self, identifier) -> list:
         """
         Returns a COPY list of dictionaries with the result of the workflow steps
         :return: List of COPY dictionaries with the result of the workflow steps
         """
         if identifier in self.__step_results:
-            return self.__step_results[identifier]
+            return self.__step_results[identifier].copy()
 
         return []
 
     def add_result_step(self, identifier, step):
 
         if identifier not in self.__step_results:
             self.__step_results[identifier] = []
```

## insulaClient/s3.py

```diff
@@ -1,9 +1,10 @@
 import boto3
 import boto3.session
+from .logger import logger
 
 
 class S3Client:
 
     def __init__(self, **kwargs):
         self.s3_resource = boto3.resource('s3',
                                           aws_access_key_id=kwargs['access_key'],
@@ -37,18 +38,18 @@
             exit(0)
 
         if kwargs['action'] not in mule:
             exit(1)
 
         for rule in kwargs['files'].split(","):
             rule_split = rule.split(':')
-            print(f"{kwargs['action']} start of: {rule_split[0]}, {rule_split[1]}...")
+            logger.info(f"{kwargs['action']} start of: {rule_split[0]}, {rule_split[1]}...")
             try:
                 mule[kwargs['action']](rule_split[0], rule_split[1])
             except Exception as e:
-                print(f"{kwargs['action']} failed")
+                logger.info(f"{kwargs['action']} failed")
             finally:
-                print('done')
+                logger.info('done')
 
 
 if __name__ == '__main__':
     S3Client.s3_mule()
```

## insulaClient/workflow_manager.py

 * *Ordering differences only*

```diff
@@ -1 +1 @@
-import yamlimport uuidfrom abc import ABC, abstractmethodfrom threading import Lockfrom .s3 import S3Clientfrom snakenest import Snakefrom .WorkflowDataManager import WorkflowDatafrom .placeholders import Placeholderclass WorkflowManager(ABC):    @abstractmethod    def parse(self, workflow_definition: str, external_params: dict) -> WorkflowData:        pass# @Snake(name='cwl_workflow_manager')# class CwlWorkflowManager(WorkflowManager):#     def __init__(self):#         super().__init__()##     def parse(self, workflow: dict, external_params: dict) -> WorkflowData:#         raise Exception('CWL Not implemented yet')@Snake(name='native_workflow_manager')class NativeWorkflowManager(WorkflowManager):    def __init__(self):        super().__init__()        self.__lock: Lock = Lock()        self.__counter_workflow = 0    def parse(self, workflow_definition: str, external_params: dict = None) -> WorkflowData:        workflow = yaml.safe_load(workflow_definition)        with self.__lock:            self.__counter_workflow += 2            wd = WorkflowData(f'{str(uuid.uuid4())}-{self.__counter_workflow}')            wd.name = workflow.get('name', 'UnName')            wd.version = workflow.get('version', None)            wd.type = workflow.get('type', None)            wd.parameters = NativeWorkflowManager.__init_parameters(workflow, external_params)            wd.requirements['connections'] = NativeWorkflowManager.__init_connection_requirements(workflow, wd)            wd.requirements['jobs'] = NativeWorkflowManager.__init_jobs_requirements(workflow)            for job in wd.requirements['jobs']:                job['id'] = Placeholder(str(job['id']), wd).get_result()            wd.config = NativeWorkflowManager.__init_config(workflow)            wd.templates = NativeWorkflowManager.__load_templates(workflow)            wd.steps = NativeWorkflowManager.__init_steps(workflow)            NativeWorkflowManager.__update_steps_with_templates(wd.steps, wd.templates)            return wd    @staticmethod    def __init_steps(workflow: dict) -> list:        return workflow.get('steps', []).copy()    @staticmethod    def __load_templates(workflow: dict) -> dict:        templates = {}        if 'templates' in workflow:            for template in workflow['templates']:                if 'name' in template:                    templates[template['name']] = template        return templates    @staticmethod    def __init_parameters(workflow: dict, external_params: dict) -> dict:        res = workflow.get('parameters')        if res:            if external_params is not None and isinstance(external_params, dict):                for key, value in external_params.items():                    res[key] = value            return res.copy()        return {}    @staticmethod    def __init_config(workflow: dict) -> dict:        if 'configuration' not in workflow:            return {'continue_on_error': False, 'max_parallel_jobs': 3, 'delete_workflow_log': False}        return {'continue_on_error': workflow['configuration'].get('continue_on_error', False),                'max_parallel_jobs': int(workflow['configuration'].get('max_parallel_jobs', 3)),                'delete_workflow_log': workflow['configuration'].get('delete_workflow_log', False)}    @staticmethod    def __init_jobs_requirements(workflow: dict) -> list:        if 'requirements' in workflow and 'jobs' in workflow['requirements']:            return workflow['requirements']['jobs']        return []    @staticmethod    def __init_connection_requirements(workflow, workflow_data: WorkflowData) -> dict:        connection_requirements = {}        if 'requirements' in workflow and 'connections' in workflow['requirements']:            for conn in workflow['requirements']['connections']:                if 'type' not in conn or 'name' not in conn:                    raise Exception('The connection must have a type and name.')                connection = {                    'name': conn['name'],                    'type': conn['type'],                    'connection': None                }                if conn['type'] == 's3':                    access_key = Placeholder(conn['params']['access_key'], workflow_data).get_result()                    secret_key = Placeholder(conn['params']['secret_key'], workflow_data).get_result()                    endpoint = Placeholder(conn['params']['endpoint'], workflow_data).get_result()                    bucket = Placeholder(conn['params']['bucket'], workflow_data).get_result()                    connection['connection'] = S3Client(access_key=access_key, secret_key=secret_key, endpoint=endpoint,                                                        bucket=bucket)                    connection_requirements[conn['name']] = connection                else:                    raise Exception(f"Connection type {conn['type']} not supported.")        return connection_requirements    @staticmethod    def __update_existing_param(template_param: list, step_param: list):        for template in template_param:            template_name = template['name']            find_param = False            for step in step_param:                step_name = step['name']                if template_name == step_name:                    find_param = True                    break            if not find_param:                step_param.append(template)    @staticmethod    def __update_steps_with_templates(stepss: list, templates: dict):        to_jump = ['name']        for steps in stepss:            for step in steps:                if 'template' in step:                    template_name = step['template']                    if template_name in templates:                        for key, value in templates[template_name].items():                            if key not in to_jump:                                if key not in step:                                    step[key] = value                                else:                                    if key == 'params':                                        NativeWorkflowManager.__update_existing_param(value, step[key])                    else:                        raise Exception(f'Template {template_name} not found')
+import yamlimport uuidfrom abc import ABC, abstractmethodfrom threading import Lockfrom .s3 import S3Clientfrom snakenest import Snakefrom .WorkflowDataManager import WorkflowDatafrom .placeholders import Placeholderclass WorkflowManager(ABC):    @abstractmethod    def parse(self, workflow_definition: str, external_params: dict = None) -> WorkflowData:        pass@Snake(having={'${insulaclient.workflow_manager.snake:native}': 'cwl'})class CwlWorkflowManager(WorkflowManager):    def __init__(self):        super().__init__()    def parse(self, workflow: dict, external_params: dict = None) -> WorkflowData:        raise Exception('CWL Not implemented yet')@Snake(having={'${insulaclient.workflow_manager.snake:native}': 'native'})class NativeWorkflowManager(WorkflowManager):    def __init__(self):        super().__init__()        self.__lock: Lock = Lock()        self.__counter_workflow = 0    def parse(self, workflow_definition: str, external_params: dict = None) -> WorkflowData:        workflow = yaml.safe_load(workflow_definition)        with self.__lock:            self.__counter_workflow += 2            wd = WorkflowData(f'{str(uuid.uuid4())}-{self.__counter_workflow}')            wd.name = workflow.get('name', 'UnName')            wd.version = workflow.get('version', None)            wd.type = workflow.get('type', None)            wd.parameters = NativeWorkflowManager.__init_parameters(workflow, external_params)            wd.requirements['connections'] = NativeWorkflowManager.__init_connection_requirements(workflow, wd)            wd.requirements['jobs'] = NativeWorkflowManager.__init_jobs_requirements(workflow)            for job in wd.requirements['jobs']:                job['id'] = Placeholder(str(job['id']), wd).get_result()            wd.config = NativeWorkflowManager.__init_config(workflow)            wd.templates = NativeWorkflowManager.__load_templates(workflow)            wd.steps = NativeWorkflowManager.__init_steps(workflow)            NativeWorkflowManager.__update_steps_with_templates(wd.steps, wd.templates)            return wd    @staticmethod    def __init_steps(workflow: dict) -> list:        return workflow.get('steps', []).copy()    @staticmethod    def __load_templates(workflow: dict) -> dict:        templates = {}        if 'templates' in workflow:            for template in workflow['templates']:                if 'name' in template:                    templates[template['name']] = template        return templates    @staticmethod    def __init_parameters(workflow: dict, external_params: dict) -> dict:        res = workflow.get('parameters')        if res:            if external_params is not None and isinstance(external_params, dict):                for key, value in external_params.items():                    res[key] = value            return res.copy()        return {}    @staticmethod    def __init_config(workflow: dict) -> dict:        if 'configuration' not in workflow:            return {'continue_on_error': False, 'max_parallel_jobs': 3, 'delete_workflow_log': False}        return {'continue_on_error': workflow['configuration'].get('continue_on_error', False),                'max_parallel_jobs': int(workflow['configuration'].get('max_parallel_jobs', 3)),                'delete_workflow_log': workflow['configuration'].get('delete_workflow_log', False)}    @staticmethod    def __init_jobs_requirements(workflow: dict) -> list:        if 'requirements' in workflow and 'jobs' in workflow['requirements']:            return workflow['requirements']['jobs']        return []    @staticmethod    def __init_connection_requirements(workflow, workflow_data: WorkflowData) -> dict:        connection_requirements = {}        if 'requirements' in workflow and 'connections' in workflow['requirements']:            for conn in workflow['requirements']['connections']:                if 'type' not in conn or 'name' not in conn:                    raise Exception('The connection must have a type and name.')                connection = {                    'name': conn['name'],                    'type': conn['type'],                    'connection': None                }                if conn['type'] == 's3':                    access_key = Placeholder(conn['params']['access_key'], workflow_data).get_result()                    secret_key = Placeholder(conn['params']['secret_key'], workflow_data).get_result()                    endpoint = Placeholder(conn['params']['endpoint'], workflow_data).get_result()                    bucket = Placeholder(conn['params']['bucket'], workflow_data).get_result()                    connection['connection'] = S3Client(access_key=access_key, secret_key=secret_key, endpoint=endpoint,                                                        bucket=bucket)                    connection_requirements[conn['name']] = connection                else:                    raise Exception(f"Connection type {conn['type']} not supported.")        return connection_requirements    @staticmethod    def __update_existing_param(template_param: list, step_param: list):        for template in template_param:            template_name = template['name']            find_param = False            for step in step_param:                step_name = step['name']                if template_name == step_name:                    find_param = True                    break            if not find_param:                step_param.append(template)    @staticmethod    def __update_steps_with_templates(stepss: list, templates: dict):        to_jump = ['name']        for steps in stepss:            for step in steps:                if 'template' in step:                    template_name = step['template']                    if template_name in templates:                        for key, value in templates[template_name].items():                            if key not in to_jump:                                if key not in step:                                    step[key] = value                                else:                                    if key == 'params':                                        NativeWorkflowManager.__update_existing_param(value, step[key])                    else:                        raise Exception(f'Template {template_name} not found')
```

## insulaClient/workflow_step_runner.py

```diff
@@ -9,26 +9,27 @@
 from .job_logs import InsulaJobLogs
 from .files_job_result import InsulaFilesJobResult
 from .downloadJob_results import InsulaDownloadJobResults
 from .utils import InsulaUtils
 from .step_result import StepResult
 from .job_status import InsulaJobStatus
 from .WorkflowDataManager import WorkflowData
-from .results_manager import ResultsManager
+from .results_manager import ResultManager
 from .placeholders import Placeholder
 from .delete import InsulaDeleter
+from .logger import logger
 
 
 class InsulaWorkflowStepRunner(object):
     @Poisoned()
     def __init__(self,
                  insula_config: InsulaApiConfig,
                  steps: InsulaWorkflowStep,
                  workflow_data_manager: WorkflowData,
-                 result_manager: ResultsManager,
+                 result_manager: ResultManager,
                  ):
 
         super().__init__()
         self.__insula_api_config = insula_config
         self.__steps = steps
         self.__workflow_data_manager = workflow_data_manager
         self.__result_manager = result_manager
@@ -48,15 +49,15 @@
         attempt = 0
         run = {
             'name': step['name'],
             'service_id': self.__insula_api_config.get_platform_service_url_api_path(step['service_id'])
         }
 
         while attempt < self.__insula_api_config.max_processor_attempts:
-            print(f'Attempt: {attempt}\n\tstep: {step}')
+            logger.info(f'Attempt: {attempt}\n\tstep: {step}')
 
             insula_job_params = InsulaJobParams(run['service_id'])
             for param in step['params']:
                 params_arr = []
                 for _ in self.__translate_values(param):
                     params_arr.append(_.get('default'))
 
@@ -66,15 +67,15 @@
 
             run['status'] = insula_status.get_status()
 
             # TODO: sta cosa e' orrenda
             if run['status']['status'] != 'COMPLETED':
                 attempt += 1
 
-                print(run['status'])
+                logger.info(run['status'])
 
                 insula_logs = InsulaJobLogs(self.__insula_api_config)
 
                 logs = insula_logs.get_logs(insula_status.get_job_id())
                 if logs is None:
                     run['logs'] = {}
                 else:
@@ -226,15 +227,15 @@
                     file_name = basename(file.get('default'))
                     try:
                         s3_connections['connection'].download(file.get('default'), join(save_in, file_name))
                     except Exception as e:
                         if not continue_on_error:
                             status.set_job_error('FAILED', e)
                             run['status'] = status.get_status()
-                            print(e)
+                            logger.info(e)
                             return run
         elif step['action'] == 'push':
             for param in step['params']:
                 if 'save_in' in param:
                     for file in self.__translate_values(param):
                         try:
                             # TODO: da sistemare!
```

## Comparing `insulaclient-0.6.0.dist-info/METADATA` & `insulaclient-0.6.1.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,22 +1,23 @@
 Metadata-Version: 2.3
 Name: InsulaClient
-Version: 0.6.0
+Version: 0.6.1
 Summary: Insula CLient
 Author-email: Roberto Di Rienzo <roberto.dirienzo@codelithic.com>, roberto.dirienzo@cgi.com
 Maintainer-email: Roberto Di Rienzo <roberto.dirienzo@codelithic.com>
 License-File: LICENSE.txt
 Keywords: Italia,cgi,client,insula
 Classifier: Development Status :: 4 - Beta
 Classifier: Programming Language :: Python
 Requires-Python: >=3.9
 Requires-Dist: boto3
+Requires-Dist: pydantic
 Requires-Dist: pyyaml
 Requires-Dist: requests
-Requires-Dist: snakenest==0.1.5
+Requires-Dist: snakenest==0.2.1
 Description-Content-Type: text/markdown
 
 # Insula Client
 
 ## Example
 
 ```yaml
```

## Comparing `insulaclient-0.6.0.dist-info/RECORD` & `insulaclient-0.6.1.dist-info/RECORD`

 * *Files 11% similar despite different names*

```diff
@@ -1,28 +1,29 @@
 insulaClient/InsulaApiConfig.py,sha256=2gQKNnz6ktnu-9PTfEMiN0Bn5x4UwFbeZGEO2FSaZ2U,2765
 insulaClient/InsulaClient.py,sha256=hivprK3yPfOADOX-meKZ5s_n51P-myrOfyiPQR7S8vE,565
 insulaClient/InsulaQuery.py,sha256=RsZWeGUcjk9CozAhU2wWgqbmtyR_iqKxMSEp7DJrBE0,625
 insulaClient/InsulaSearch.py,sha256=YqCod1FW1hV8E3FKB5sGl-7OJpiEFwF0w3TNJh0DWLs,1365
 insulaClient/SingletonMemoryManager.py,sha256=wOmeRFkgQU0i2DvtwFrAl4tqZBYbFfWJntLxhF8CUJo,1389
 insulaClient/WorkflowDataManager.py,sha256=3HvaylItS-X2RPTrt_89AQEjWK7Bk4bVsq-cGIpFpqs,1667
-insulaClient/__init__.py,sha256=hRUcx_ZwQXU55kdtqfl09YCp8T5Qr4MWWGjVAGoBrx0,374
-insulaClient/delete.py,sha256=uPvUFmC_6iffma0YLzxvicDQMnLcpmtrJYahv70q9jM,894
+insulaClient/__init__.py,sha256=uJUVn_7kD_h3Qw142hmi2rtGp5Il5pjDntmvenFT1dM,390
+insulaClient/delete.py,sha256=neltLbWM91_bY89csLqWLo736nLC0BxjlgklKs09ANI,928
 insulaClient/downloadJob_results.py,sha256=Be22O34og3lUwxRUdrml-vNC_rjXf5ycH38B3NkvVOw,1933
 insulaClient/files_job_result.py,sha256=ESOzAy4_yi2IzMUGlgW3WPrtUbEScloPPyxulDnGXE8,1495
 insulaClient/job_logs.py,sha256=47iqfiCeEAiZv91zpVr9IeGQCZirGeIoG3gDPycnmi8,881
 insulaClient/job_params.py,sha256=E2bAHXJLkcl9mABUrdrQqtq9SsH6CA5QH-EDHx8bQSU,785
-insulaClient/job_runner.py,sha256=fER6BCFlK5MIslPNbJJje9l0a2n5-SZy_dEl78Npw5g,3525
+insulaClient/job_runner.py,sha256=YmZTN0LRVXXsN7h5QOVvvf8cYWFrwNOy5LkQOT1w-x0,3558
 insulaClient/job_status.py,sha256=2p70J77OjY9XSVXlxlGUgOfD4OUIgcob61hzK5f1uv4,3153
-insulaClient/placeholders.py,sha256=BryNMfblJvDyY7vw6IfzIIzhsrY029l8TFQMk099dvg,4619
-insulaClient/results_manager.py,sha256=dgZDVYD1ZXCpHtVy90ZMFeOE2tEJtEu8yNZDNADQkZA,743
-insulaClient/s3.py,sha256=7rrgow9OCTj63yr83719IzB-6J5fQNW-vsJex_RiHJw,1849
+insulaClient/logger.py,sha256=SyGGFciQATh-JOzBKW_a_WW8ukZkhJimQwgvaL7taRE,262
+insulaClient/placeholders.py,sha256=FZANExqFNVs5SaOqDnflEUcrpOmzWPhKpJCw78E3LaE,4617
+insulaClient/results_manager.py,sha256=jAnnM6fv8S3oP1PT_6A1cPN2db7ExcRPYAOpaSaYHUs,1341
+insulaClient/s3.py,sha256=H5O5NbkWI58Q0KQqyBmiI2gJT8yfe2qTvU67E6-9aOY,1894
 insulaClient/step_result.py,sha256=yX2RINUxlsqxYxfm9sUx69M_YAY0EM2SZBd2SxqXfRo,725
 insulaClient/utils.py,sha256=3iDY90A8vlc52KKLukNHVEg6bhWfiGSKjkRXVueO5W8,929
 insulaClient/workflow.py,sha256=jh5Yu5RioDQHt7Hqv5C7tZCzMFnLiC0jXqTx4VopYPE,4630
-insulaClient/workflow_manager.py,sha256=HmQF9sI_lRIpfLIV6Xwl29VHM4HgSHOm-jAD0SZeRCg,6376
+insulaClient/workflow_manager.py,sha256=MsCTMBCwrLVorTyooX80ACusQJZ9ky3afx5wUcozKFM,6449
 insulaClient/workflow_step.py,sha256=BllZzKLeOuNbB4aUtyIESqPOpPjDDVo-_YkSSjl27-0,818
-insulaClient/workflow_step_runner.py,sha256=2TXk2lqwSPoS5p9ImV-f0MePOGPS021dlB9ytWGTnLs,14584
-insulaclient-0.6.0.dist-info/METADATA,sha256=4epFFXiuNU6JxYDisiMntqt94dCgEVjk5kNAXBfuva8,9960
-insulaclient-0.6.0.dist-info/WHEEL,sha256=bq9SyP5NxIRA9EpQgMCd-9RmPHWvbH-4lTDGwxgIR64,87
-insulaclient-0.6.0.dist-info/entry_points.txt,sha256=XmoJBOq6Rxy9modIBGlEqhdnWgRWiKRZxJOVnoDoW8A,58
-insulaclient-0.6.0.dist-info/licenses/LICENSE.txt,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-insulaclient-0.6.0.dist-info/RECORD,,
+insulaClient/workflow_step_runner.py,sha256=836FXIMLwpsPHWbiWknQVIZl5WAOX4sNugt14lqy9zw,14627
+insulaclient-0.6.1.dist-info/METADATA,sha256=Xf0d7OQZoXLSi1L3xCb1tgnPSXHKYE6zkB2z3H_YKO8,9984
+insulaclient-0.6.1.dist-info/WHEEL,sha256=as-1oFTWSeWBgyzh0O_qF439xqBe6AbBgt4MfYe5zwY,87
+insulaclient-0.6.1.dist-info/entry_points.txt,sha256=XmoJBOq6Rxy9modIBGlEqhdnWgRWiKRZxJOVnoDoW8A,58
+insulaclient-0.6.1.dist-info/licenses/LICENSE.txt,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+insulaclient-0.6.1.dist-info/RECORD,,
```

