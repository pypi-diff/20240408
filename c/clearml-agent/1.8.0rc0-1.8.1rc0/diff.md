# Comparing `tmp/clearml_agent-1.8.0rc0-py3-none-any.whl.zip` & `tmp/clearml_agent-1.8.1rc0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,139 +1,139 @@
-Zip file size: 423062 bytes, number of entries: 137
--rw-r--r--  2.0 unx       50 b- defN 24-Mar-05 16:11 clearml_agent/__init__.py
--rw-r--r--  2.0 unx     2891 b- defN 24-Mar-05 16:11 clearml_agent/__main__.py
--rw-r--r--  2.0 unx     2410 b- defN 24-Mar-05 16:11 clearml_agent/complete.py
--rw-r--r--  2.0 unx      736 b- defN 24-Mar-05 16:11 clearml_agent/config.py
--rw-r--r--  2.0 unx    11938 b- defN 24-Mar-05 16:11 clearml_agent/definitions.py
--rw-r--r--  2.0 unx     2826 b- defN 24-Mar-05 16:11 clearml_agent/errors.py
--rw-r--r--  2.0 unx    16765 b- defN 24-Mar-05 16:11 clearml_agent/session.py
--rw-r--r--  2.0 unx       25 b- defN 24-Mar-05 16:11 clearml_agent/version.py
--rw-r--r--  2.0 unx      123 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/__init__.py
--rw-r--r--  2.0 unx     4786 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/utils.py
--rw-r--r--  2.0 unx      561 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/config/__init__.py
--rw-r--r--  2.0 unx    21950 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/config/default/agent.conf
--rw-r--r--  2.0 unx     1796 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/config/default/api.conf
--rw-r--r--  2.0 unx       92 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/config/default/logging.conf
--rw-r--r--  2.0 unx     6865 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/config/default/sdk.conf
--rw-r--r--  2.0 unx        0 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/schema/__init__.py
--rw-r--r--  2.0 unx     1295 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/schema/action.py
--rw-r--r--  2.0 unx     6824 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/schema/service.py
--rw-r--r--  2.0 unx      282 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_4/__init__.py
--rw-r--r--  2.0 unx    17434 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_4/auth.py
--rw-r--r--  2.0 unx     4029 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_4/debug.py
--rw-r--r--  2.0 unx    89217 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_4/events.py
--rw-r--r--  2.0 unx    90805 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_4/models.py
--rw-r--r--  2.0 unx    66636 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_4/queues.py
--rw-r--r--  2.0 unx   218713 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_4/tasks.py
--rw-r--r--  2.0 unx    77983 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_4/workers.py
--rw-r--r--  2.0 unx        0 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_5/__init__.py
--rw-r--r--  2.0 unx    17434 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_5/auth.py
--rw-r--r--  2.0 unx     4029 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_5/debug.py
--rw-r--r--  2.0 unx    90043 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_5/events.py
--rw-r--r--  2.0 unx    90805 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_5/models.py
--rw-r--r--  2.0 unx    66636 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_5/queues.py
--rw-r--r--  2.0 unx   234295 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_5/tasks.py
--rw-r--r--  2.0 unx    77996 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/services/v2_5/workers.py
--rw-r--r--  2.0 unx      338 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/__init__.py
--rw-r--r--  2.0 unx      156 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/apimodel.py
--rw-r--r--  2.0 unx     5233 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/callresult.py
--rw-r--r--  2.0 unx     4598 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/datamodel.py
--rw-r--r--  2.0 unx     1981 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/defs.py
--rw-r--r--  2.0 unx      345 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/errors.py
--rw-r--r--  2.0 unx     2817 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/request.py
--rw-r--r--  2.0 unx     1932 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/response.py
--rw-r--r--  2.0 unx    28540 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/session.py
--rw-r--r--  2.0 unx     4200 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/token_manager.py
--rw-r--r--  2.0 unx       55 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/client/__init__.py
--rw-r--r--  2.0 unx    16055 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/client/client.py
--rw-r--r--  2.0 unx      175 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/jsonmodels/__init__.py
--rw-r--r--  2.0 unx     6397 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/jsonmodels/builders.py
--rw-r--r--  2.0 unx      552 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/jsonmodels/collections.py
--rw-r--r--  2.0 unx      145 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/jsonmodels/errors.py
--rw-r--r--  2.0 unx    13503 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/jsonmodels/fields.py
--rw-r--r--  2.0 unx     4738 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/jsonmodels/models.py
--rw-r--r--  2.0 unx     2993 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/jsonmodels/parsers.py
--rw-r--r--  2.0 unx     4006 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/jsonmodels/utilities.py
--rw-r--r--  2.0 unx     6294 b- defN 24-Mar-05 16:11 clearml_agent/backend_api/session/jsonmodels/validators.py
--rw-r--r--  2.0 unx      109 b- defN 24-Mar-05 16:11 clearml_agent/backend_config/__init__.py
--rw-r--r--  2.0 unx    12445 b- defN 24-Mar-05 16:11 clearml_agent/backend_config/config.py
--rw-r--r--  2.0 unx      164 b- defN 24-Mar-05 16:11 clearml_agent/backend_config/converters.py
--rw-r--r--  2.0 unx     1776 b- defN 24-Mar-05 16:11 clearml_agent/backend_config/defs.py
--rw-r--r--  2.0 unx      100 b- defN 24-Mar-05 16:11 clearml_agent/backend_config/entry.py
--rw-r--r--  2.0 unx     1657 b- defN 24-Mar-05 16:11 clearml_agent/backend_config/environment.py
--rw-r--r--  2.0 unx      186 b- defN 24-Mar-05 16:11 clearml_agent/backend_config/errors.py
--rw-r--r--  2.0 unx      851 b- defN 24-Mar-05 16:11 clearml_agent/backend_config/log.py
--rw-r--r--  2.0 unx     4264 b- defN 24-Mar-05 16:11 clearml_agent/backend_config/utils.py
--rw-r--r--  2.0 unx       99 b- defN 24-Mar-05 16:11 clearml_agent/commands/__init__.py
--rw-r--r--  2.0 unx    15160 b- defN 24-Mar-05 16:11 clearml_agent/commands/base.py
--rw-r--r--  2.0 unx      536 b- defN 24-Mar-05 16:11 clearml_agent/commands/check_config.py
--rw-r--r--  2.0 unx    17027 b- defN 24-Mar-05 16:11 clearml_agent/commands/config.py
--rw-r--r--  2.0 unx     4488 b- defN 24-Mar-05 16:11 clearml_agent/commands/events.py
--rw-r--r--  2.0 unx     6552 b- defN 24-Mar-05 16:11 clearml_agent/commands/resolver.py
--rw-r--r--  2.0 unx   200640 b- defN 24-Mar-05 16:11 clearml_agent/commands/worker.py
--rw-r--r--  2.0 unx        0 b- defN 24-Mar-05 16:11 clearml_agent/external/__init__.py
--rw-r--r--  2.0 unx      256 b- defN 24-Mar-05 16:11 clearml_agent/external/pyhocon/__init__.py
--rw-r--r--  2.0 unx    32918 b- defN 24-Mar-05 16:11 clearml_agent/external/pyhocon/config_parser.py
--rw-r--r--  2.0 unx    22532 b- defN 24-Mar-05 16:11 clearml_agent/external/pyhocon/config_tree.py
--rw-r--r--  2.0 unx    13100 b- defN 24-Mar-05 16:11 clearml_agent/external/pyhocon/converter.py
--rw-r--r--  2.0 unx      352 b- defN 24-Mar-05 16:11 clearml_agent/external/pyhocon/exceptions.py
--rw-r--r--  2.0 unx      353 b- defN 24-Mar-05 16:11 clearml_agent/external/requirements_parser/__init__.py
--rw-r--r--  2.0 unx     1298 b- defN 24-Mar-05 16:11 clearml_agent/external/requirements_parser/fragment.py
--rw-r--r--  2.0 unx     2368 b- defN 24-Mar-05 16:11 clearml_agent/external/requirements_parser/parser.py
--rw-r--r--  2.0 unx     9362 b- defN 24-Mar-05 16:11 clearml_agent/external/requirements_parser/requirement.py
--rw-r--r--  2.0 unx      405 b- defN 24-Mar-05 16:11 clearml_agent/external/requirements_parser/vcs.py
--rw-r--r--  2.0 unx        1 b- defN 24-Mar-05 16:11 clearml_agent/glue/__init__.py
--rw-r--r--  2.0 unx      358 b- defN 24-Mar-05 16:11 clearml_agent/glue/daemon.py
--rw-r--r--  2.0 unx      665 b- defN 24-Mar-05 16:11 clearml_agent/glue/definitions.py
--rw-r--r--  2.0 unx      130 b- defN 24-Mar-05 16:11 clearml_agent/glue/errors.py
--rw-r--r--  2.0 unx    49967 b- defN 24-Mar-05 16:11 clearml_agent/glue/k8s.py
--rw-r--r--  2.0 unx    10396 b- defN 24-Mar-05 16:11 clearml_agent/glue/pending_pods_daemon.py
--rw-r--r--  2.0 unx      452 b- defN 24-Mar-05 16:11 clearml_agent/glue/utilities.py
--rw-r--r--  2.0 unx        0 b- defN 24-Mar-05 16:11 clearml_agent/helper/__init__.py
--rw-r--r--  2.0 unx    18798 b- defN 24-Mar-05 16:11 clearml_agent/helper/base.py
--rw-r--r--  2.0 unx     2200 b- defN 24-Mar-05 16:11 clearml_agent/helper/check_update.py
--rw-r--r--  2.0 unx     3650 b- defN 24-Mar-05 16:11 clearml_agent/helper/console.py
--rw-r--r--  2.0 unx      828 b- defN 24-Mar-05 16:11 clearml_agent/helper/dicts.py
--rw-r--r--  2.0 unx     6299 b- defN 24-Mar-05 16:11 clearml_agent/helper/docker_args.py
--rw-r--r--  2.0 unx    16242 b- defN 24-Mar-05 16:11 clearml_agent/helper/process.py
--rw-r--r--  2.0 unx    34018 b- defN 24-Mar-05 16:11 clearml_agent/helper/repo.py
--rw-r--r--  2.0 unx    12222 b- defN 24-Mar-05 16:11 clearml_agent/helper/resource_monitor.py
--rw-r--r--  2.0 unx     5470 b- defN 24-Mar-05 16:11 clearml_agent/helper/runtime_verification.py
--rw-r--r--  2.0 unx     6697 b- defN 24-Mar-05 16:11 clearml_agent/helper/singleton.py
--rw-r--r--  2.0 unx     4759 b- defN 24-Mar-05 16:11 clearml_agent/helper/trace.py
--rw-r--r--  2.0 unx      125 b- defN 24-Mar-05 16:11 clearml_agent/helper/environment/__init__.py
--rw-r--r--  2.0 unx     2215 b- defN 24-Mar-05 16:11 clearml_agent/helper/environment/converters.py
--rw-r--r--  2.0 unx     4063 b- defN 24-Mar-05 16:11 clearml_agent/helper/environment/entry.py
--rw-r--r--  2.0 unx      738 b- defN 24-Mar-05 16:11 clearml_agent/helper/environment/environment.py
--rw-r--r--  2.0 unx        0 b- defN 24-Mar-05 16:11 clearml_agent/helper/gpu/__init__.py
--rw-r--r--  2.0 unx    15079 b- defN 24-Mar-05 16:11 clearml_agent/helper/gpu/gpustat.py
--rw-r--r--  2.0 unx   166328 b- defN 24-Mar-05 16:11 clearml_agent/helper/gpu/pynvml.py
--rw-r--r--  2.0 unx        0 b- defN 24-Mar-05 16:11 clearml_agent/helper/os/__init__.py
--rw-r--r--  2.0 unx     2949 b- defN 24-Mar-05 16:11 clearml_agent/helper/os/daemonize.py
--rw-r--r--  2.0 unx     9919 b- defN 24-Mar-05 16:11 clearml_agent/helper/os/folder_cache.py
--rw-r--r--  2.0 unx     7134 b- defN 24-Mar-05 16:11 clearml_agent/helper/os/locks.py
--rw-r--r--  2.0 unx     7204 b- defN 24-Mar-05 16:11 clearml_agent/helper/os/portalocker.py
--rw-r--r--  2.0 unx        0 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/__init__.py
--rw-r--r--  2.0 unx    11889 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/base.py
--rw-r--r--  2.0 unx    32285 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/conda_api.py
--rw-r--r--  2.0 unx     8224 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/external_req.py
--rw-r--r--  2.0 unx     7110 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/poetry_api.py
--rw-r--r--  2.0 unx     1764 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/post_req.py
--rw-r--r--  2.0 unx     4761 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/priority_req.py
--rw-r--r--  2.0 unx    41760 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/pytorch.py
--rw-r--r--  2.0 unx    31340 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/requirements.py
--rw-r--r--  2.0 unx     3452 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/translator.py
--rw-r--r--  2.0 unx     3401 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/venv_update_api.py
--rw-r--r--  2.0 unx        0 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/pip_api/__init__.py
--rw-r--r--  2.0 unx     3913 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/pip_api/system.py
--rw-r--r--  2.0 unx     2951 b- defN 24-Mar-05 16:11 clearml_agent/helper/package/pip_api/venv.py
--rw-r--r--  2.0 unx     1244 b- defN 24-Mar-05 16:11 clearml_agent/interface/__init__.py
--rw-r--r--  2.0 unx    15036 b- defN 24-Mar-05 16:11 clearml_agent/interface/base.py
--rw-r--r--  2.0 unx     9937 b- defN 24-Mar-05 16:11 clearml_agent/interface/worker.py
--rw-r--r--  2.0 unx    11340 b- defN 24-Mar-05 16:11 clearml_agent-1.8.0rc0.dist-info/LICENSE
--rw-r--r--  2.0 unx    17980 b- defN 24-Mar-05 16:11 clearml_agent-1.8.0rc0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Mar-05 16:11 clearml_agent-1.8.0rc0.dist-info/WHEEL
--rw-r--r--  2.0 unx       63 b- defN 24-Mar-05 16:11 clearml_agent-1.8.0rc0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       14 b- defN 24-Mar-05 16:11 clearml_agent-1.8.0rc0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    13375 b- defN 24-Mar-05 16:11 clearml_agent-1.8.0rc0.dist-info/RECORD
-137 files, 2293158 bytes uncompressed, 401330 bytes compressed:  82.5%
+Zip file size: 429952 bytes, number of entries: 137
+-rw-r--r--  2.0 unx       50 b- defN 24-Apr-08 08:44 clearml_agent/__init__.py
+-rw-r--r--  2.0 unx     2891 b- defN 24-Apr-08 08:44 clearml_agent/__main__.py
+-rw-r--r--  2.0 unx     2410 b- defN 24-Apr-08 08:44 clearml_agent/complete.py
+-rw-r--r--  2.0 unx      736 b- defN 24-Apr-08 08:44 clearml_agent/config.py
+-rw-r--r--  2.0 unx    12008 b- defN 24-Apr-08 08:44 clearml_agent/definitions.py
+-rw-r--r--  2.0 unx     2826 b- defN 24-Apr-08 08:44 clearml_agent/errors.py
+-rw-r--r--  2.0 unx    16765 b- defN 24-Apr-08 08:44 clearml_agent/session.py
+-rw-r--r--  2.0 unx       25 b- defN 24-Apr-08 08:44 clearml_agent/version.py
+-rw-r--r--  2.0 unx      123 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/__init__.py
+-rw-r--r--  2.0 unx     4786 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/utils.py
+-rw-r--r--  2.0 unx      561 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/config/__init__.py
+-rw-r--r--  2.0 unx    21960 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/config/default/agent.conf
+-rw-r--r--  2.0 unx     1796 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/config/default/api.conf
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/config/default/logging.conf
+-rw-r--r--  2.0 unx     6855 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/config/default/sdk.conf
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/schema/__init__.py
+-rw-r--r--  2.0 unx     1295 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/schema/action.py
+-rw-r--r--  2.0 unx     6824 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/schema/service.py
+-rw-r--r--  2.0 unx      282 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_4/__init__.py
+-rw-r--r--  2.0 unx    17434 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_4/auth.py
+-rw-r--r--  2.0 unx     4029 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_4/debug.py
+-rw-r--r--  2.0 unx    89217 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_4/events.py
+-rw-r--r--  2.0 unx    90805 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_4/models.py
+-rw-r--r--  2.0 unx    66636 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_4/queues.py
+-rw-r--r--  2.0 unx   218713 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_4/tasks.py
+-rw-r--r--  2.0 unx    77983 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_4/workers.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_5/__init__.py
+-rw-r--r--  2.0 unx    17434 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_5/auth.py
+-rw-r--r--  2.0 unx     4029 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_5/debug.py
+-rw-r--r--  2.0 unx    90043 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_5/events.py
+-rw-r--r--  2.0 unx    90805 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_5/models.py
+-rw-r--r--  2.0 unx    66636 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_5/queues.py
+-rw-r--r--  2.0 unx   234295 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_5/tasks.py
+-rw-r--r--  2.0 unx    77996 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/services/v2_5/workers.py
+-rw-r--r--  2.0 unx      338 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/__init__.py
+-rw-r--r--  2.0 unx      156 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/apimodel.py
+-rw-r--r--  2.0 unx     5233 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/callresult.py
+-rw-r--r--  2.0 unx     4598 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/datamodel.py
+-rw-r--r--  2.0 unx     2056 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/defs.py
+-rw-r--r--  2.0 unx      345 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/errors.py
+-rw-r--r--  2.0 unx     2817 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/request.py
+-rw-r--r--  2.0 unx     1932 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/response.py
+-rw-r--r--  2.0 unx    28540 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/session.py
+-rw-r--r--  2.0 unx     4200 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/token_manager.py
+-rw-r--r--  2.0 unx       55 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/client/__init__.py
+-rw-r--r--  2.0 unx    16055 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/client/client.py
+-rw-r--r--  2.0 unx      175 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/jsonmodels/__init__.py
+-rw-r--r--  2.0 unx     6397 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/jsonmodels/builders.py
+-rw-r--r--  2.0 unx      552 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/jsonmodels/collections.py
+-rw-r--r--  2.0 unx      145 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/jsonmodels/errors.py
+-rw-r--r--  2.0 unx    13503 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/jsonmodels/fields.py
+-rw-r--r--  2.0 unx     4738 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/jsonmodels/models.py
+-rw-r--r--  2.0 unx     2993 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/jsonmodels/parsers.py
+-rw-r--r--  2.0 unx     4006 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/jsonmodels/utilities.py
+-rw-r--r--  2.0 unx     6294 b- defN 24-Apr-08 08:44 clearml_agent/backend_api/session/jsonmodels/validators.py
+-rw-r--r--  2.0 unx      109 b- defN 24-Apr-08 08:44 clearml_agent/backend_config/__init__.py
+-rw-r--r--  2.0 unx    12445 b- defN 24-Apr-08 08:44 clearml_agent/backend_config/config.py
+-rw-r--r--  2.0 unx      164 b- defN 24-Apr-08 08:44 clearml_agent/backend_config/converters.py
+-rw-r--r--  2.0 unx     1776 b- defN 24-Apr-08 08:44 clearml_agent/backend_config/defs.py
+-rw-r--r--  2.0 unx      100 b- defN 24-Apr-08 08:44 clearml_agent/backend_config/entry.py
+-rw-r--r--  2.0 unx     1657 b- defN 24-Apr-08 08:44 clearml_agent/backend_config/environment.py
+-rw-r--r--  2.0 unx      186 b- defN 24-Apr-08 08:44 clearml_agent/backend_config/errors.py
+-rw-r--r--  2.0 unx      851 b- defN 24-Apr-08 08:44 clearml_agent/backend_config/log.py
+-rw-r--r--  2.0 unx     4264 b- defN 24-Apr-08 08:44 clearml_agent/backend_config/utils.py
+-rw-r--r--  2.0 unx       99 b- defN 24-Apr-08 08:44 clearml_agent/commands/__init__.py
+-rw-r--r--  2.0 unx    15160 b- defN 24-Apr-08 08:44 clearml_agent/commands/base.py
+-rw-r--r--  2.0 unx      536 b- defN 24-Apr-08 08:44 clearml_agent/commands/check_config.py
+-rw-r--r--  2.0 unx    17027 b- defN 24-Apr-08 08:44 clearml_agent/commands/config.py
+-rw-r--r--  2.0 unx     4488 b- defN 24-Apr-08 08:44 clearml_agent/commands/events.py
+-rw-r--r--  2.0 unx     6552 b- defN 24-Apr-08 08:44 clearml_agent/commands/resolver.py
+-rw-r--r--  2.0 unx   201544 b- defN 24-Apr-08 08:44 clearml_agent/commands/worker.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 08:44 clearml_agent/external/__init__.py
+-rw-r--r--  2.0 unx      256 b- defN 24-Apr-08 08:44 clearml_agent/external/pyhocon/__init__.py
+-rw-r--r--  2.0 unx    32918 b- defN 24-Apr-08 08:44 clearml_agent/external/pyhocon/config_parser.py
+-rw-r--r--  2.0 unx    22532 b- defN 24-Apr-08 08:44 clearml_agent/external/pyhocon/config_tree.py
+-rw-r--r--  2.0 unx    13100 b- defN 24-Apr-08 08:44 clearml_agent/external/pyhocon/converter.py
+-rw-r--r--  2.0 unx      352 b- defN 24-Apr-08 08:44 clearml_agent/external/pyhocon/exceptions.py
+-rw-r--r--  2.0 unx      353 b- defN 24-Apr-08 08:44 clearml_agent/external/requirements_parser/__init__.py
+-rw-r--r--  2.0 unx     1298 b- defN 24-Apr-08 08:44 clearml_agent/external/requirements_parser/fragment.py
+-rw-r--r--  2.0 unx     2368 b- defN 24-Apr-08 08:44 clearml_agent/external/requirements_parser/parser.py
+-rw-r--r--  2.0 unx     9457 b- defN 24-Apr-08 08:44 clearml_agent/external/requirements_parser/requirement.py
+-rw-r--r--  2.0 unx      405 b- defN 24-Apr-08 08:44 clearml_agent/external/requirements_parser/vcs.py
+-rw-r--r--  2.0 unx        1 b- defN 24-Apr-08 08:44 clearml_agent/glue/__init__.py
+-rw-r--r--  2.0 unx      358 b- defN 24-Apr-08 08:44 clearml_agent/glue/daemon.py
+-rw-r--r--  2.0 unx      665 b- defN 24-Apr-08 08:44 clearml_agent/glue/definitions.py
+-rw-r--r--  2.0 unx      130 b- defN 24-Apr-08 08:44 clearml_agent/glue/errors.py
+-rw-r--r--  2.0 unx    49985 b- defN 24-Apr-08 08:44 clearml_agent/glue/k8s.py
+-rw-r--r--  2.0 unx    10646 b- defN 24-Apr-08 08:44 clearml_agent/glue/pending_pods_daemon.py
+-rw-r--r--  2.0 unx      452 b- defN 24-Apr-08 08:44 clearml_agent/glue/utilities.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 08:44 clearml_agent/helper/__init__.py
+-rw-r--r--  2.0 unx    18798 b- defN 24-Apr-08 08:44 clearml_agent/helper/base.py
+-rw-r--r--  2.0 unx     2200 b- defN 24-Apr-08 08:44 clearml_agent/helper/check_update.py
+-rw-r--r--  2.0 unx     3650 b- defN 24-Apr-08 08:44 clearml_agent/helper/console.py
+-rw-r--r--  2.0 unx      828 b- defN 24-Apr-08 08:44 clearml_agent/helper/dicts.py
+-rw-r--r--  2.0 unx     6299 b- defN 24-Apr-08 08:44 clearml_agent/helper/docker_args.py
+-rw-r--r--  2.0 unx    16242 b- defN 24-Apr-08 08:44 clearml_agent/helper/process.py
+-rw-r--r--  2.0 unx    34018 b- defN 24-Apr-08 08:44 clearml_agent/helper/repo.py
+-rw-r--r--  2.0 unx    21636 b- defN 24-Apr-08 08:44 clearml_agent/helper/resource_monitor.py
+-rw-r--r--  2.0 unx     5470 b- defN 24-Apr-08 08:44 clearml_agent/helper/runtime_verification.py
+-rw-r--r--  2.0 unx     6697 b- defN 24-Apr-08 08:44 clearml_agent/helper/singleton.py
+-rw-r--r--  2.0 unx     4759 b- defN 24-Apr-08 08:44 clearml_agent/helper/trace.py
+-rw-r--r--  2.0 unx      125 b- defN 24-Apr-08 08:44 clearml_agent/helper/environment/__init__.py
+-rw-r--r--  2.0 unx     2215 b- defN 24-Apr-08 08:44 clearml_agent/helper/environment/converters.py
+-rw-r--r--  2.0 unx     4063 b- defN 24-Apr-08 08:44 clearml_agent/helper/environment/entry.py
+-rw-r--r--  2.0 unx      738 b- defN 24-Apr-08 08:44 clearml_agent/helper/environment/environment.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 08:44 clearml_agent/helper/gpu/__init__.py
+-rw-r--r--  2.0 unx    16829 b- defN 24-Apr-08 08:44 clearml_agent/helper/gpu/gpustat.py
+-rw-r--r--  2.0 unx   184408 b- defN 24-Apr-08 08:44 clearml_agent/helper/gpu/pynvml.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 08:44 clearml_agent/helper/os/__init__.py
+-rw-r--r--  2.0 unx     2949 b- defN 24-Apr-08 08:44 clearml_agent/helper/os/daemonize.py
+-rw-r--r--  2.0 unx     9919 b- defN 24-Apr-08 08:44 clearml_agent/helper/os/folder_cache.py
+-rw-r--r--  2.0 unx     7134 b- defN 24-Apr-08 08:44 clearml_agent/helper/os/locks.py
+-rw-r--r--  2.0 unx     7204 b- defN 24-Apr-08 08:44 clearml_agent/helper/os/portalocker.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/__init__.py
+-rw-r--r--  2.0 unx    11889 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/base.py
+-rw-r--r--  2.0 unx    35879 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/conda_api.py
+-rw-r--r--  2.0 unx     8224 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/external_req.py
+-rw-r--r--  2.0 unx     7406 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/poetry_api.py
+-rw-r--r--  2.0 unx     1764 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/post_req.py
+-rw-r--r--  2.0 unx     4761 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/priority_req.py
+-rw-r--r--  2.0 unx    41760 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/pytorch.py
+-rw-r--r--  2.0 unx    31340 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/requirements.py
+-rw-r--r--  2.0 unx     3452 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/translator.py
+-rw-r--r--  2.0 unx     3401 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/venv_update_api.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/pip_api/__init__.py
+-rw-r--r--  2.0 unx     3913 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/pip_api/system.py
+-rw-r--r--  2.0 unx     2951 b- defN 24-Apr-08 08:44 clearml_agent/helper/package/pip_api/venv.py
+-rw-r--r--  2.0 unx     1244 b- defN 24-Apr-08 08:44 clearml_agent/interface/__init__.py
+-rw-r--r--  2.0 unx    15036 b- defN 24-Apr-08 08:44 clearml_agent/interface/base.py
+-rw-r--r--  2.0 unx     9937 b- defN 24-Apr-08 08:44 clearml_agent/interface/worker.py
+-rw-r--r--  2.0 unx    11340 b- defN 24-Apr-08 08:45 clearml_agent-1.8.1rc0.dist-info/LICENSE
+-rw-r--r--  2.0 unx    18967 b- defN 24-Apr-08 08:45 clearml_agent-1.8.1rc0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-08 08:45 clearml_agent-1.8.1rc0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       63 b- defN 24-Apr-08 08:45 clearml_agent-1.8.1rc0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       14 b- defN 24-Apr-08 08:45 clearml_agent-1.8.1rc0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    13375 b- defN 24-Apr-08 08:45 clearml_agent-1.8.1rc0.dist-info/RECORD
+137 files, 2328691 bytes uncompressed, 408220 bytes compressed:  82.5%
```

## zipnote {}

```diff
@@ -387,26 +387,26 @@
 
 Filename: clearml_agent/interface/base.py
 Comment: 
 
 Filename: clearml_agent/interface/worker.py
 Comment: 
 
-Filename: clearml_agent-1.8.0rc0.dist-info/LICENSE
+Filename: clearml_agent-1.8.1rc0.dist-info/LICENSE
 Comment: 
 
-Filename: clearml_agent-1.8.0rc0.dist-info/METADATA
+Filename: clearml_agent-1.8.1rc0.dist-info/METADATA
 Comment: 
 
-Filename: clearml_agent-1.8.0rc0.dist-info/WHEEL
+Filename: clearml_agent-1.8.1rc0.dist-info/WHEEL
 Comment: 
 
-Filename: clearml_agent-1.8.0rc0.dist-info/entry_points.txt
+Filename: clearml_agent-1.8.1rc0.dist-info/entry_points.txt
 Comment: 
 
-Filename: clearml_agent-1.8.0rc0.dist-info/top_level.txt
+Filename: clearml_agent-1.8.1rc0.dist-info/top_level.txt
 Comment: 
 
-Filename: clearml_agent-1.8.0rc0.dist-info/RECORD
+Filename: clearml_agent-1.8.1rc0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## clearml_agent/definitions.py

```diff
@@ -244,14 +244,16 @@
 
 ENV_PACKAGE_PYTORCH_RESOLVE = EnvironmentConfig("CLEARML_AGENT_PACKAGE_PYTORCH_RESOLVE")
 
 ENV_TEMP_STDOUT_FILE_DIR = EnvironmentConfig("CLEARML_AGENT_TEMP_STDOUT_FILE_DIR")
 
 ENV_GIT_CLONE_VERBOSE = EnvironmentConfig("CLEARML_AGENT_GIT_CLONE_VERBOSE", type=bool)
 
+ENV_GPU_FRACTIONS = EnvironmentConfig("CLEARML_AGENT_GPU_FRACTIONS")
+
 
 class FileBuffering(IntEnum):
     """
     File buffering options:
     - UNSET: follows the defaults for the type of file,
         line-buffered for interactive (tty) text files and with a default chunk size otherwise
     - UNBUFFERED: no buffering at all
```

## clearml_agent/version.py

```diff
@@ -1 +1 @@
-__version__ = '1.8.0rc0'
+__version__ = '1.8.1rc0'
```

## clearml_agent/backend_api/config/default/agent.conf

```diff
@@ -88,15 +88,15 @@
         # and matching the automatically detected cuda version with the required pytorch wheel.
         # if the exact cuda version is not found for the required pytorch wheel, it will try
         # a lower cuda version until a match is found
         # "none": No resolver used, install pytorch like any other package
         # pytorch_resolve: "pip"
 
         # additional conda channels to use when installing with conda package manager
-        conda_channels: ["pytorch", "conda-forge", "defaults", ]
+        conda_channels: ["pytorch", "conda-forge", "nvidia", "defaults", ]
 
         # If set to true, Task's "installed packages" are ignored,
         # and the repository's "requirements.txt" is used instead
         # force_repo_requirements_txt: false
 
         # set the priority packages to be installed before the rest of the required packages
         # Note: this only controls the installation order of existing requirement packages (and does not add additional packages)
```

## clearml_agent/backend_api/config/default/sdk.conf

```diff
@@ -136,15 +136,15 @@
         # dev task reuse window
         task_reuse_time_window_in_hours: 72.0
 
         # Run VCS repository detection asynchronously
         vcs_repo_detect_async: true
 
         # Store uncommitted git/hg source code diff in experiment manifest when training in development mode
-        # This stores "git diff" or "hg diff" into the experiment's "script.requirements.diff" section
+        # This stores "git diff" or into the experiment's "script.requirements.diff" section
         store_uncommitted_code_diff: true
 
         # Support stopping an experiment in case it was externally stopped, status was changed or task was reset
         support_stopping: true
 
         # Default Task output_uri. if output_uri is not provided to Task.init, default_output_uri will be used instead.
         default_output_uri: ""
```

## clearml_agent/backend_api/session/defs.py

```diff
@@ -7,14 +7,15 @@
 ENV_FILES_HOST = EnvEntry("CLEARML_FILES_HOST", "TRAINS_FILES_HOST")
 ENV_ACCESS_KEY = EnvEntry("CLEARML_API_ACCESS_KEY", "TRAINS_API_ACCESS_KEY")
 ENV_SECRET_KEY = EnvEntry("CLEARML_API_SECRET_KEY", "TRAINS_API_SECRET_KEY")
 ENV_AUTH_TOKEN = EnvEntry("CLEARML_AUTH_TOKEN")
 ENV_VERBOSE = EnvEntry("CLEARML_API_VERBOSE", "TRAINS_API_VERBOSE", type=bool, default=False)
 ENV_HOST_VERIFY_CERT = EnvEntry("CLEARML_API_HOST_VERIFY_CERT", "TRAINS_API_HOST_VERIFY_CERT", type=bool, default=True)
 ENV_CONDA_ENV_PACKAGE = EnvEntry("CLEARML_CONDA_ENV_PACKAGE", "TRAINS_CONDA_ENV_PACKAGE")
+ENV_USE_CONDA_BASE_ENV = EnvEntry("CLEARML_USE_CONDA_BASE_ENV", type=bool)
 ENV_NO_DEFAULT_SERVER = EnvEntry("CLEARML_NO_DEFAULT_SERVER", "TRAINS_NO_DEFAULT_SERVER", type=bool, default=True)
 ENV_DISABLE_VAULT_SUPPORT = EnvEntry('CLEARML_AGENT_DISABLE_VAULT_SUPPORT', type=bool)
 ENV_ENABLE_ENV_CONFIG_SECTION = EnvEntry('CLEARML_AGENT_ENABLE_ENV_CONFIG_SECTION', type=bool)
 ENV_ENABLE_FILES_CONFIG_SECTION = EnvEntry('CLEARML_AGENT_ENABLE_FILES_CONFIG_SECTION', type=bool)
 ENV_VENV_CONFIGURED = EnvEntry('VIRTUAL_ENV', type=str)
 ENV_PROPAGATE_EXITCODE = EnvEntry("CLEARML_AGENT_PROPAGATE_EXITCODE", type=bool, default=False)
 ENV_INITIAL_CONNECT_RETRY_OVERRIDE = EnvEntry(
```

## clearml_agent/commands/worker.py

```diff
@@ -1392,15 +1392,15 @@
         available_gpus = list(set(gpu_indexes) - set(gpus))
 
         return available_gpus
 
     def _setup_dynamic_gpus(self, gpu_queues):
         available_gpus = self.get_runtime_properties()
         if available_gpus is None:
-            raise ValueError("Dynamic GPU allocation is not supported by the ClearML-server")
+            raise ValueError("Dynamic GPU allocation is not supported by your ClearML-server")
         available_gpus = [prop["value"] for prop in available_gpus if prop["key"] == 'available_gpus']
         if available_gpus:
             gpus = []
             for g in available_gpus[-1].split(','):
                 try:
                     # verify "int.int"
                     gpus += [str(g).strip()] if float(g.strip()) >= 0 else []
@@ -1409,15 +1409,17 @@
             available_gpus = gpus
 
         if not isinstance(gpu_queues, dict):
             gpu_queues = dict(gpu_queues)
 
         if not self.set_runtime_properties(
                 key='available_gpus', value=','.join(str(g) for g in available_gpus)):
-            raise ValueError("Dynamic GPU allocation is not supported by the ClearML-server")
+            raise ValueError("Dynamic GPU allocation is not supported by your ClearML-server")
+
+        self.cluster_report_monitor(available_gpus=available_gpus, gpu_queues=gpu_queues)
 
         return available_gpus, gpu_queues
 
     def get_worker_properties(self, queue_ids):
         queue_tags = {
             q.id: {'name': q.name, 'tags': q.tags}
             for q in self._session.send_api(
@@ -1805,23 +1807,30 @@
         return dynamic_gpus, gpu_indexes, queues
 
     def _register_dynamic_gpus(self, gpu_indexes):
         # test server support
         available_gpus = self._dynamic_gpu_get_available(gpu_indexes)
         if not self.set_runtime_properties(
                 key='available_gpus', value=','.join(str(g) for g in available_gpus)):
-            raise ValueError("Dynamic GPU allocation is not supported by the ClearML-server")
+            raise ValueError("Dynamic GPU allocation is not supported by your ClearML-server")
 
     def report_monitor(self, report):
         if not self.monitor:
             self.new_monitor(report=report)
         else:
             self.monitor.set_report(report)
         self.monitor.send_report()
 
+    def cluster_report_monitor(self, available_gpus, gpu_queues):
+        if not self.monitor:
+            self.new_monitor()
+        self.monitor.setup_cluster_report(
+            worker_id=self.worker_id, available_gpus=available_gpus, gpu_queues=gpu_queues
+        )
+
     def stop_monitor(self):
         if self.monitor:
             self.monitor.stop()
             self.monitor = None
 
     def new_monitor(self, report=None):
         self.stop_monitor()
@@ -2057,14 +2066,15 @@
         log_control_end_msg = self._task_logging_pass_control_message.format(task_id)
         filter_lines = printed_lines if not service_mode_internal_agent_started else []
         for i, line in enumerate(printed_lines):
             if not service_mode_internal_agent_started and line.startswith(log_start_msg):
                 service_mode_internal_agent_started = True
                 filter_lines = printed_lines[:i+1]
             elif line.startswith(log_control_end_msg):
+                service_mode_internal_agent_started = True
                 return filter_lines, service_mode_internal_agent_started, 0
 
         return filter_lines, service_mode_internal_agent_started, None
 
     def send_logs(self, task_id, lines, level="DEBUG", session=None):
         """
         Send output lines as log events to backend
@@ -3361,15 +3371,22 @@
             self.log.debug("Searching for {}".format(executable))
             if find_executable(executable):
                 try:
                     output = Argv(executable, "--version").get_output(
                         stderr=subprocess.STDOUT
                     )
                 except subprocess.CalledProcessError as ex:
-                    self.log.warning("error getting %s version: %s", executable, ex)
+                    # Windows returns 9009 code and suggests to install Python from Windows Store
+                    if is_windows_platform() and ex.returncode == 9009:
+                        self.log.debug("version not found: {}".format(ex))
+                    else:
+                        self.log.warning("error getting %s version: %s", executable, ex)
+                    continue
+                except FileNotFoundError as ex:
+                    self.log.debug("version not found: {}".format(ex))
                     continue
 
                 if not default_python:
                     match = re.search(r"Python ({}(?:\.\d+)*)".format(r"\d+"), output)
                     default_python = (
                         match.group(1),
                         version if version and '.' in version else '.'.join(match.group(1).split('.')[:2]),
@@ -3558,16 +3575,16 @@
                                          Text(self._session.config.get("agent.default_python", None)) or \
                                          '{}.{}'.format(sys.version_info.major, sys.version_info.minor)
                     print('Warning: could not locate requested Python version {}, reverting to version {}'.format(
                         requested_python_version, def_python_version))
                     executable_version, executable_version_suffix, executable_name = \
                         self.find_python_executable_for_version(def_python_version)
 
-                self._session.config.put("agent.default_python", executable_version_suffix)
-                self._session.config.put("agent.python_binary", executable_name)
+            self._session.config.put("agent.default_python", executable_version_suffix)
+            self._session.config.put("agent.python_binary", executable_name)
 
         venv_dir = Path(venv_dir) if venv_dir else \
             Path(self._session.config["agent.venvs_dir"], executable_version_suffix)
         venv_dir = Path(os.path.expanduser(os.path.expandvars(venv_dir.as_posix())))
 
         first_time = not standalone_mode and (
             is_windows_platform()
@@ -4268,15 +4285,16 @@
         if host_git_credentials:
             for git_credentials in host_git_credentials:
                 base_cmd += ['-v', '{}:/root/{}'.format(git_credentials, Path(git_credentials).name)]
 
         if docker_bash_setup_script and docker_bash_setup_script.strip('\n '):
             extra_shell_script = (extra_shell_script or '') + \
                 ' ; '.join(line.strip()
-                           for line in docker_bash_setup_script.split('\n') if line.strip()) + \
+                           for line in docker_bash_setup_script.split('\n')
+                           if line.strip() and not line.lstrip().startswith("#")) + \
                 ' ; '
 
         self.debug(
             "Adding mounts: host_ssh_cache={}, host_apt_cache={}, host_pip_cache={}, host_poetry_cache={}, "
             "host_pip_dl={}, host_cache={}, host_vcs_cache={}, host_venvs_cache={}".format(
                 host_ssh_cache, host_apt_cache, host_pip_cache, host_poetry_cache, host_pip_dl, host_cache,
                 host_vcs_cache, host_venvs_cache,
```

## clearml_agent/external/requirements_parser/requirement.py

```diff
@@ -35,15 +35,15 @@
     r'(?P<path>[^#]+)' +
     r'(#(?P<fragment>\S+))?'
 )
 
 
 class Requirement(object):
     """
-    Represents a single requirementfrom clearml_agent.external.requirements_parser.requirement import Requirement
+    Represents a single requirement from clearml_agent.external.requirements_parser.requirement import Requirement
 
     Typically instances of this class are created with ``Requirement.parse``.
     For local file requirements, there's no verification that the file
     exists. This class attempts to be *dict-like*.
 
     See: http://www.pip-installer.org/en/latest/logic.html
 
@@ -210,27 +210,28 @@
             req.specs = pkg_req.specs
         return req
 
     @classmethod
     def parse(cls, line):
         """
         Parses a Requirement from a line of a requirement file.
+        This is the main entry point for parsing a single requirements line (not parse_line!)
 
         :param line: a line of a requirement file
         :returns: a Requirement instance for the given line
         :raises: ValueError on an invalid requirement
         """
         line = line.lstrip()
         if line.startswith('-e') or line.startswith('--editable'):
             # Editable installs are either a local project path
             # or a VCS project URI
             return cls.parse_editable(
                 re.sub(r'^(-e|--editable=?)\s*', '', line))
         elif '@' in line and ('#' not in line or line.index('#') > line.index('@')):
-            # Allegro bug fix: support 'name @ git+' entries
+            # ClearML bug fix: support 'name @ git+' entries
             name, uri = line.split('@', 1)
             name = name.strip()
             uri = uri.strip()
             # noinspection PyBroadException
             try:
                 # check if the name is valid & parsed
                 Req.parse(name)
```

## clearml_agent/glue/k8s.py

```diff
@@ -566,15 +566,15 @@
 
         if self.ports_mode:
             print("Kubernetes scheduling task id={} on pod={} (pod_count={})".format(task_id, pod_number, pod_count))
         else:
             print("Kubernetes scheduling task id={}".format(task_id))
 
         try:
-            template = self._resolve_template(task_session, task_data, queue)
+            template = self._resolve_template(task_session, task_data, queue, task_id)
         except Exception as ex:
             print("ERROR: Failed resolving template (skipping): {}".format(ex))
             return
 
         try:
             namespace = template['metadata']['namespace'] or self.namespace
         except (KeyError, TypeError, AttributeError):
@@ -1102,15 +1102,15 @@
         )
 
     def _get_next_task(self, queue, get_task_info):
         return get_next_task(
             self._session, queue=queue, get_task_info=get_task_info
         )
 
-    def _resolve_template(self, task_session, task_data, queue):
+    def _resolve_template(self, task_session, task_data, queue, task_id):
         if self.template_dict:
             return deepcopy(self.template_dict)
 
     @classmethod
     def get_ssh_server_bash(cls, ssh_port_number):
         return ' ; '.join(line.format(port=ssh_port_number) for line in cls.BASH_INSTALL_SSH_CMD)
```

## clearml_agent/glue/pending_pods_daemon.py

```diff
@@ -13,24 +13,24 @@
 
 class PendingPodsDaemon(K8sDaemon):
     def __init__(self, polling_interval: float, agent):
         super(PendingPodsDaemon, self).__init__(agent=agent)
         self._polling_interval = polling_interval
         self._last_tasks_msgs = {}  # last msg updated for every task
 
-    def get_pods(self, pod_name=None):
+    def get_pods(self, pod_name=None, debug_msg="Detecting pending pods: {cmd}"):
         filters = ["status.phase=Pending"]
         if pod_name:
             filters.append(f"metadata.name={pod_name}")
 
         if self._agent.using_jobs:
             return self._agent.get_pods_for_jobs(
                 job_condition="status.active=1", pod_filters=filters, debug_msg="Detecting pending pods: {cmd}"
             )
-        return self._agent.get_pods(filters=filters, debug_msg="Detecting pending pods: {cmd}")
+        return self._agent.get_pods(filters=filters, debug_msg=debug_msg)
 
     def _get_pod_name(self, pod: dict):
         return get_path(pod, "metadata", "name")
 
     def _get_k8s_resource_name(self, pod: dict):
         if self._agent.using_jobs:
             return get_path(pod, "metadata", "labels", "job-name")
@@ -68,14 +68,19 @@
                     if not task_id:
                         continue
 
                     namespace = self._get_k8s_resource_namespace(pod)
                     if not namespace:
                         continue
 
+                    updated_pod = self.get_pods(pod_name=pod_name, debug_msg="Refreshing pod information: {cmd}")
+                    if not updated_pod:
+                        continue
+                    pod = updated_pod[0]
+
                     task_id_to_pod[task_id] = pod
 
                     msg = None
                     tags = []
 
                     waiting = get_path(pod, 'status', 'containerStatuses', 0, 'state', 'waiting')
                     if not waiting:
```

## clearml_agent/helper/resource_monitor.py

```diff
@@ -1,23 +1,24 @@
 from __future__ import unicode_literals, division
 
 import logging
-import os
+import re
 import shlex
 from collections import deque
 from itertools import starmap
 from threading import Thread, Event
 from time import time
-from typing import Text, Sequence
+from typing import Sequence, List, Union, Dict, Optional
 
 import attr
 import psutil
 from pathlib2 import Path
+
+from clearml_agent.definitions import ENV_WORKER_TAGS, ENV_GPU_FRACTIONS
 from clearml_agent.session import Session
-from clearml_agent.definitions import ENV_WORKER_TAGS
 
 try:
     from .gpu import gpustat
 except ImportError:
     gpustat = None
 
 log = logging.getLogger(__name__)
@@ -50,22 +51,30 @@
         def to_dict(self):
             return {
                 key: value
                 for key, value in attr.asdict(self).items()
                 if value is not None
             }
 
+    @attr.s
+    class ClusterReport:
+        cluster_key = attr.ib(type=str)
+        max_gpus = attr.ib(type=int, default=None)
+        max_workers = attr.ib(type=int, default=None)
+        max_cpus = attr.ib(type=int, default=None)
+        resource_groups = attr.ib(type=Sequence[str], factory=list)
+
     def __init__(
         self,
         session,  # type: Session
         worker_id,  # type: ResourceMonitor.StatusReport,
         sample_frequency_per_sec=2.0,
         report_frequency_sec=30.0,
         first_report_sec=None,
-        worker_tags=None,
+        worker_tags=None
     ):
         self.session = session
         self.queue = deque(maxlen=1)
         self.queue.appendleft(self.StatusReport())
         self._worker_id = worker_id
         self._sample_frequency = sample_frequency_per_sec
         self._report_frequency = report_frequency_sec
@@ -75,39 +84,45 @@
         self._previous_readouts = {}
         self._previous_readouts_ts = time()
         self._thread = None
         self._exit_event = Event()
         self._gpustat_fail = 0
         self._gpustat = gpustat
         self._active_gpus = None
-        self._gpu_fractions = os.getenv("CLEARML_AGENT_GPU_FRACTIONS", "").strip()
-        if self._gpu_fractions:
-            self._gpu_fractions = [
-                float(fraction.strip()) for fraction in self._gpu_fractions.split(",")
-            ]
+        self._default_gpu_utilization = session.config.get("agent.resource_monitoring.default_gpu_utilization", 100)
+        # allow default_gpu_utilization as null in the config, in which case we don't log anything
+        if self._default_gpu_utilization is not None:
+            self._default_gpu_utilization = int(self._default_gpu_utilization)
+        self._gpu_utilization_warning_sent = False
         self._disk_use_path = str(session.config.get("agent.resource_monitoring.disk_use_path", None) or Path.home())
+        self._fractions_handler = GpuFractionsHandler() if session.feature_set != "basic" else None
         if not worker_tags and ENV_WORKER_TAGS.get():
             worker_tags = shlex.split(ENV_WORKER_TAGS.get())
         self._worker_tags = worker_tags
         if Session.get_nvidia_visible_env() == 'none':
             # NVIDIA_VISIBLE_DEVICES set to none, marks cpu_only flag
             # active_gpus == False means no GPU reporting
             self._active_gpus = False
         elif not self._gpustat:
             log.warning('ClearML-Agent Resource Monitor: GPU monitoring is not available')
         else:
             # None means no filtering, report all gpus
             self._active_gpus = None
+            # noinspection PyBroadException
             try:
                 active_gpus = Session.get_nvidia_visible_env()
                 # None means no filtering, report all gpus
                 if active_gpus and active_gpus != "all":
                     self._active_gpus = [g.strip() for g in str(active_gpus).split(',')]
             except Exception:
                 pass
+        self._cluster_report_interval_sec = int(session.config.get(
+            "agent.resource_monitoring.cluster_report_interval_sec", 60
+        ))
+        self._cluster_report = None
 
     def set_report(self, report):
         # type: (ResourceMonitor.StatusReport) -> ()
         if report is not None:
             self.queue.appendleft(report)
 
     def get_report(self):
@@ -131,22 +146,92 @@
             timestamp=(int(time()) * 1000),
             worker=self._worker_id,
             tags=self._worker_tags,
             **self.get_report().to_dict()
         )
         log.debug("sending report: %s", report)
 
+        # noinspection PyBroadException
         try:
             self.session.get(service="workers", action="status_report", **report)
         except Exception:
             log.warning("Failed sending report: %s", report)
             return False
         return True
 
+    def send_cluster_report(self) -> bool:
+        if not self.session.feature_set == "basic":
+            return False
+
+        # noinspection PyBroadException
+        try:
+            properties = {
+                "max_cpus": self._cluster_report.max_cpus,
+                "max_gpus": self._cluster_report.max_gpus,
+                "max_workers": self._cluster_report.max_workers,
+            }
+            payload = {
+                "key": self._cluster_report.cluster_key,
+                "timestamp": int(time() * 1000),
+                "timeout": int(self._cluster_report_interval_sec * 2),
+                # "resource_groups": self._cluster_report.resource_groups,  # yet to be supported
+                "properties": {k: v for k, v in properties.items() if v is not None},
+            }
+            self.session.post(service="workers", action="cluster_report", **payload)
+        except Exception as ex:
+            log.warning("Failed sending cluster report: %s", ex)
+            return False
+        return True
+
+    def setup_cluster_report(self, available_gpus, gpu_queues, worker_id=None, cluster_key=None, resource_groups=None):
+        # type: (List[int], Dict[str, int], Optional[str], Optional[str], Optional[List[str]]) -> ()
+        """
+        Set up a cluster report for the enterprise server dashboard feature.
+        If a worker_id is provided, cluster_key and resource_groups are inferred from it.
+        """
+        if self.session.feature_set == "basic":
+            return
+
+        if not worker_id and not cluster_key:
+            print("Error: cannot set up dashboard reporting - worker_id or cluster key are required")
+            return
+
+        # noinspection PyBroadException
+        try:
+            if not cluster_key:
+                worker_id_parts = worker_id.split(":")
+                if len(worker_id_parts) < 3:
+                    cluster_key = self.session.config.get("agent.resource_dashboard.default_cluster_name", "onprem")
+                    resource_group = ":".join((cluster_key, worker_id_parts[0]))
+                    print(
+                        'WARNING: your worker ID "{}" is not suitable for proper resource dashboard reporting, please '
+                        'set up agent.worker_name to be at least two colon-separated parts (i.e. "<category>:<name>"). '
+                        'Using "{}" as the resource dashboard category and "{}" as the resource group.'.format(
+                            worker_id, cluster_key, resource_group
+                        )
+                    )
+                else:
+                    cluster_key = worker_id_parts[0]
+                    resource_group = ":".join((worker_id_parts[:2]))
+
+                resource_groups = [resource_group]
+
+            self._cluster_report = ResourceMonitor.ClusterReport(
+                cluster_key=cluster_key,
+                max_gpus=len(available_gpus),
+                max_workers=len(available_gpus) // min(x for x, _ in gpu_queues.values()),
+                resource_groups=resource_groups
+            )
+
+            self.send_cluster_report()
+        except Exception as ex:
+            print("Error: failed setting cluster report: {}".format(ex))
+
     def _daemon(self):
+        last_cluster_report = 0
         seconds_since_started = 0
         reported = 0
         try:
             while True:
                 last_report = time()
                 current_report_frequency = (
                     self._report_frequency if reported != 0 else self._first_report_sec
@@ -155,15 +240,15 @@
                     # wait for self._sample_frequency seconds, if event set quit
                     if self._exit_event.wait(1 / self._sample_frequency):
                         return
                     # noinspection PyBroadException
                     try:
                         self._update_readouts()
                     except Exception as ex:
-                        log.warning("failed getting machine stats: %s", report_error(ex))
+                        log.error("failed getting machine stats: %s", report_error(ex))
                         self._failure()
 
                 seconds_since_started += int(round(time() - last_report))
                 # check if we do not report any metric (so it means the last iteration will not be changed)
 
                 # if we do not have last_iteration, we just use seconds as iteration
 
@@ -178,14 +263,23 @@
                 # send actual report
                 if self.send_report(stats):
                     # clear readouts if this is update was sent
                     self._clear_readouts()
 
                 # count reported iterations
                 reported += 1
+
+                if (
+                    self._cluster_report and
+                    self._cluster_report_interval_sec
+                    and time() - last_cluster_report > self._cluster_report_interval_sec
+                ):
+                    if self.send_cluster_report():
+                        last_cluster_report = time()
+
         except Exception as ex:
             log.exception("Error reporting monitoring info: %s", str(ex))
 
     def _update_readouts(self):
         readouts = self._machine_stats()
         elapsed = time() - self._previous_readouts_ts
         self._previous_readouts_ts = time()
@@ -262,43 +356,59 @@
         net_stats = psutil.net_io_counters()
         stats["network_tx_mbs"] = BytesSizes.megabytes(net_stats.bytes_sent)
         stats["network_rx_mbs"] = BytesSizes.megabytes(net_stats.bytes_recv)
         io_stats = psutil.disk_io_counters()
         stats["io_read_mbs"] = BytesSizes.megabytes(io_stats.read_bytes)
         stats["io_write_mbs"] = BytesSizes.megabytes(io_stats.write_bytes)
 
-        fractions = self._gpu_fractions
-
         # check if we need to monitor gpus and if we can access the gpu statistics
         if self._active_gpus is not False and self._gpustat:
             try:
                 gpu_stat = self._gpustat.new_query()
+                report_index = 0
                 for i, g in enumerate(gpu_stat.gpus):
                     # only monitor the active gpu's, if none were selected, monitor everything
                     if self._active_gpus:
                         uuid = getattr(g, "uuid", None)
-                        if str(i) not in self._active_gpus and (not uuid or uuid not in self._active_gpus):
+                        mig_uuid = getattr(g, "mig_uuid", None)
+                        if (
+                            str(g.index) not in self._active_gpus
+                            and (not uuid or uuid not in self._active_gpus)
+                            and (not mig_uuid or mig_uuid not in self._active_gpus)
+                        ):
                             continue
-                    stats["gpu_temperature_{:d}".format(i)] = g["temperature.gpu"]
-                    stats["gpu_utilization_{:d}".format(i)] = g["utilization.gpu"]
-                    stats["gpu_mem_usage_{:d}".format(i)] = (
+                    stats["gpu_temperature_{}".format(report_index)] = g["temperature.gpu"]
+
+                    if g["utilization.gpu"] is not None:
+                        stats["gpu_utilization_{}".format(report_index)] = g["utilization.gpu"]
+                    elif self._default_gpu_utilization is not None:
+                        stats["gpu_utilization_{}".format(report_index)] = self._default_gpu_utilization
+                        if getattr(g, "mig_index", None) is None and not self._gpu_utilization_warning_sent:
+                            # this shouldn't happen for non-MIGs, warn the user about it
+                            log.error("Failed fetching GPU utilization")
+                            self._gpu_utilization_warning_sent = True
+
+                    stats["gpu_mem_usage_{}".format(report_index)] = (
                         100.0 * g["memory.used"] / g["memory.total"]
                     )
                     # already in MBs
-                    stats["gpu_mem_free_{:d}".format(i)] = (
+                    stats["gpu_mem_free_{}".format(report_index)] = (
                         g["memory.total"] - g["memory.used"]
                     )
-                    stats["gpu_mem_used_%d" % i] = g["memory.used"]
 
-                    stats["gpu_fraction_%d" % i] = \
-                        (fractions[i] if i < len(fractions) else fractions[-1]) if fractions else 1.0
+                    stats["gpu_mem_used_{}".format(report_index)] = g["memory.used"] or 0
+
+                    if self._fractions_handler:
+                        fractions = self._fractions_handler.fractions
+                        stats["gpu_fraction_{}".format(report_index)] = \
+                            (fractions[i] if i < len(fractions) else fractions[-1]) if fractions else 1.0
 
             except Exception as ex:
                 # something happened and we can't use gpu stats,
-                log.warning("failed getting machine stats: %s", report_error(ex))
+                log.error("failed getting machine stats: %s", report_error(ex))
                 self._failure()
 
         return stats
 
     def _failure(self):
         self._gpustat_fail += 1
         if self._gpustat_fail >= 3:
@@ -321,9 +431,124 @@
         "gpu_mem_used_*": "gpu_memory_used",
         "gpu_mem_free_*": "gpu_memory_free",
         "gpu_utilization_*": "gpu_usage",
         "gpu_fraction_*": "gpu_fraction"
     }
 
 
+class GpuFractionsHandler:
+    _number_re = re.compile(r"^clear\.ml/fraction(-\d+)?$")
+    _mig_re = re.compile(r"^nvidia\.com/mig-(?P<compute>[0-9]+)g\.(?P<memory>[0-9]+)gb$")
+
+    _gpu_name_to_memory_gb = {
+        "A30": 24,
+        "NVIDIA A30": 24,
+        "A100-SXM4-40GB": 40,
+        "NVIDIA-A100-40GB-PCIe": 40,
+        "NVIDIA A100-40GB-PCIe": 40,
+        "NVIDIA-A100-SXM4-40GB": 40,
+        "NVIDIA A100-SXM4-40GB": 40,
+        "NVIDIA-A100-SXM4-80GB": 79,
+        "NVIDIA A100-SXM4-80GB": 79,
+        "NVIDIA-A100-80GB-PCIe": 79,
+        "NVIDIA A100-80GB-PCIe": 79,
+    }
+
+    def __init__(self):
+        self._total_memory_gb = [
+            self._gpu_name_to_memory_gb.get(name, 0)
+            for name in (self._get_gpu_names() or [])
+        ]
+        self._fractions = self._get_fractions()
+
+    @property
+    def fractions(self) -> List[float]:
+        return self._fractions
+
+    def _get_fractions(self) -> List[float]:
+        if not self._total_memory_gb:
+            # Can't compute
+            return [1.0]
+
+        fractions = (ENV_GPU_FRACTIONS.get() or "").strip()
+        if not fractions:
+            # No fractions
+            return [1.0]
+
+        decoded_fractions = self.decode_fractions(fractions)
+
+        if isinstance(decoded_fractions, list):
+            return decoded_fractions
+
+        totals = []
+        for i, (fraction, count) in enumerate(decoded_fractions.items()):
+            m = self._mig_re.match(fraction)
+            if not m:
+                continue
+            try:
+                total_gb = self._total_memory_gb[i] if i < len(self._total_memory_gb) else self._total_memory_gb[-1]
+                if not total_gb:
+                    continue
+                totals.append((int(m.group("memory")) * count) / total_gb)
+            except ValueError:
+                pass
+
+        if not totals:
+            log.warning("Fractions count is empty for {}".format(fractions))
+            return [1.0]
+
+        return totals
+
+    @classmethod
+    def extract_custom_limits(cls, limits: dict):
+        for k, v in list((limits or {}).items()):
+            if cls._number_re.match(k):
+                limits.pop(k, None)
+
+    @classmethod
+    def get_simple_fractions_total(cls, limits: dict) -> float:
+        try:
+            if any(cls._number_re.match(x) for x in limits):
+                return sum(float(v) for k, v in limits.items() if cls._number_re.match(k))
+        except Exception as ex:
+            log.error("Failed summing up fractions from {}: {}".format(limits, ex))
+        return 0
+
+    @classmethod
+    def encode_fractions(cls, limits: dict) -> str:
+        if any(cls._number_re.match(x) for x in (limits or {})):
+            return ",".join(str(v) for k, v in sorted(limits.items()) if cls._number_re.match(k))
+        return ",".join(("{}:{}".format(k, v) for k, v in (limits or {}).items() if cls._mig_re.match(k)))
+
+    @staticmethod
+    def decode_fractions(fractions: str) -> Union[List[float], Dict[str, int]]:
+        try:
+            items = [f.strip() for f in fractions.strip().split(",")]
+            tuples = [(k.strip(), v.strip()) for k, v in (f.partition(":")[::2] for f in items)]
+            if all(not v for _, v in tuples):
+                # comma-separated float fractions
+                return [float(k) for k, _ in tuples]
+            # comma-separated slice:count items
+            return {
+                k.strip(): int(v.strip())
+                for k, v in tuples
+            }
+        except Exception as ex:
+            log.error("Failed decoding GPU fractions '{}': {}".format(fractions, ex))
+        return {}
+
+    @staticmethod
+    def _get_gpu_names():
+        # noinspection PyBroadException
+        try:
+            gpus = gpustat.new_query().gpus
+            names = [g["name"] for g in gpus]
+
+            print("GPU names: {}".format(names))
+
+            return names
+        except Exception as ex:
+            log.error("Failed getting GPU names: {}".format(ex))
+
+
 def report_error(ex):
     return "{}: {}".format(type(ex).__name__, ex)
```

## clearml_agent/helper/gpu/gpustat.py

```diff
@@ -54,14 +54,29 @@
         """
         Returns the uuid returned by nvidia-smi,
         e.g. GPU-12345678-abcd-abcd-uuid-123456abcdef
         """
         return self.entry['uuid']
 
     @property
+    def mig_index(self):
+        """
+        Returns the index of the MIG partition (as in nvidia-smi).
+        """
+        return self.entry.get("mig_index")
+
+    @property
+    def mig_uuid(self):
+        """
+        Returns the uuid of the MIG partition returned by nvidia-smi when running in MIG mode,
+        e.g. MIG-12345678-abcd-abcd-uuid-123456abcdef
+        """
+        return self.entry.get("mig_uuid")
+
+    @property
     def name(self):
         """
         Returns the name of GPU card (e.g. Geforce Titan X)
         """
         return self.entry['name']
 
     @property
@@ -157,14 +172,15 @@
 
 
 class GPUStatCollection(object):
     global_processes = {}
     _initialized = False
     _device_count = None
     _gpu_device_info = {}
+    _mig_device_info = {}
 
     def __init__(self, gpu_list, driver_version=None, driver_cuda_version=None):
         self.gpus = gpu_list
 
         # attach additional system information
         self.hostname = platform.node()
         self.query_time = datetime.now()
@@ -187,15 +203,15 @@
             initialized = True
 
         def _decode(b):
             if isinstance(b, bytes):
                 return b.decode()  # for python3, to unicode
             return b
 
-        def get_gpu_info(index, handle):
+        def get_gpu_info(index, handle, is_mig=False):
             """Get one GPU information specified by nvml handle"""
 
             def get_process_info(nv_process):
                 """Get the process information of specific pid"""
                 process = {}
                 if nv_process.pid not in GPUStatCollection.global_processes:
                     GPUStatCollection.global_processes[nv_process.pid] = \
@@ -223,20 +239,22 @@
                     # Bytes to MBytes
                     process['gpu_memory_usage'] = nv_process.usedGpuMemory // MB
                 except Exception:
                     # insufficient permissions
                     pass
                 return process
 
-            if not GPUStatCollection._gpu_device_info.get(index):
+            device_info = GPUStatCollection._mig_device_info if is_mig else GPUStatCollection._gpu_device_info
+
+            if not device_info.get(index):
                 name = _decode(N.nvmlDeviceGetName(handle))
                 uuid = _decode(N.nvmlDeviceGetUUID(handle))
-                GPUStatCollection._gpu_device_info[index] = (name, uuid)
+                device_info[index] = (name, uuid)
 
-            name, uuid = GPUStatCollection._gpu_device_info[index]
+            name, uuid = device_info[index]
 
             try:
                 temperature = N.nvmlDeviceGetTemperature(
                     handle, N.NVML_TEMPERATURE_GPU
                 )
             except N.NVMLError:
                 temperature = None  # Not supported
@@ -324,16 +342,44 @@
         gpu_list = []
         if GPUStatCollection._device_count is None:
             GPUStatCollection._device_count = N.nvmlDeviceGetCount()
 
         for index in range(GPUStatCollection._device_count):
             handle = N.nvmlDeviceGetHandleByIndex(index)
             gpu_info = get_gpu_info(index, handle)
-            gpu_stat = GPUStat(gpu_info)
-            gpu_list.append(gpu_stat)
+            mig_cnt = 0
+            # noinspection PyBroadException
+            try:
+                mig_cnt = N.nvmlDeviceGetMaxMigDeviceCount(handle)
+            except Exception:
+                pass
+
+            if mig_cnt <= 0:
+                gpu_list.append(GPUStat(gpu_info))
+                continue
+
+            got_mig_info = False
+            for mig_index in range(mig_cnt):
+                try:
+                    mig_handle = N.nvmlDeviceGetMigDeviceHandleByIndex(handle, mig_index)
+                    mig_info = get_gpu_info(mig_index, mig_handle, is_mig=True)
+                    mig_info["mig_name"] = mig_info["name"]
+                    mig_info["name"] = gpu_info["name"]
+                    mig_info["mig_index"] = mig_info["index"]
+                    mig_info["mig_uuid"] = mig_info["uuid"]
+                    mig_info["index"] = gpu_info["index"]
+                    mig_info["uuid"] = gpu_info["uuid"]
+                    mig_info["temperature.gpu"] = gpu_info["temperature.gpu"]
+                    mig_info["fan.speed"] = gpu_info["fan.speed"]
+                    gpu_list.append(GPUStat(mig_info))
+                    got_mig_info = True
+                except Exception as e:
+                    pass
+            if not got_mig_info:
+                gpu_list.append(GPUStat(gpu_info))
 
         # 2. additional info (driver version, etc).
         if get_driver_info:
             try:
                 driver_version = _decode(N.nvmlSystemGetDriverVersion())
             except N.NVMLError:
                 driver_version = None  # N/A
```

## clearml_agent/helper/gpu/pynvml.py

```diff
@@ -1,9 +1,9 @@
 #####
-# Copyright (c) 2011-2023, NVIDIA Corporation.  All rights reserved.
+# Copyright (c) 2011-2022, NVIDIA Corporation.  All rights reserved.
 #
 # Redistribution and use in source and binary forms, with or without
 # modification, are permitted provided that the following conditions are met:
 #
 #    * Redistributions of source code must retain the above copyright notice,
 #      this list of conditions and the following disclaimer.
 #    * Redistributions in binary form must reproduce the above copyright
@@ -21,75 +21,74 @@
 # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 # THE POSSIBILITY OF SUCH DAMAGE.
 #####
-# flake8: noqa
-# This is only to ignore F405 errors
 
 ##
 # Python bindings for the NVML library
 ##
-from ctypes import *  # noqa: F403
-from ctypes.util import find_library  # noqa
+from ctypes import *
+from ctypes.util import find_library
 from functools import wraps
 import sys
 import os
 import threading
 import string
 
 ## C Type mappings ##
 ## Enums
 _nvmlEnableState_t = c_uint
-NVML_FEATURE_DISABLED = 0
-NVML_FEATURE_ENABLED = 1
+NVML_FEATURE_DISABLED    = 0
+NVML_FEATURE_ENABLED     = 1
 
 _nvmlBrandType_t = c_uint
-NVML_BRAND_UNKNOWN = 0
-NVML_BRAND_QUADRO = 1
-NVML_BRAND_TESLA = 2
-NVML_BRAND_NVS = 3
-NVML_BRAND_GRID = 4  # Deprecated from API reporting. Keeping definition for backward compatibility.
-NVML_BRAND_GEFORCE = 5
-NVML_BRAND_TITAN = 6
-NVML_BRAND_NVIDIA_VAPPS = 7  # NVIDIA Virtual Applications
-NVML_BRAND_NVIDIA_VPC = 8  # NVIDIA Virtual PC
-NVML_BRAND_NVIDIA_VCS = 9  # NVIDIA Virtual Compute Server
-NVML_BRAND_NVIDIA_VWS = 10  # NVIDIA RTX Virtual Workstation
+NVML_BRAND_UNKNOWN             = 0
+NVML_BRAND_QUADRO              = 1
+NVML_BRAND_TESLA               = 2
+NVML_BRAND_NVS                 = 3
+NVML_BRAND_GRID                = 4   # Deprecated from API reporting. Keeping definition for backward compatibility.
+NVML_BRAND_GEFORCE             = 5
+NVML_BRAND_TITAN               = 6
+NVML_BRAND_NVIDIA_VAPPS        = 7   # NVIDIA Virtual Applications
+NVML_BRAND_NVIDIA_VPC          = 8   # NVIDIA Virtual PC
+NVML_BRAND_NVIDIA_VCS          = 9   # NVIDIA Virtual Compute Server
+NVML_BRAND_NVIDIA_VWS          = 10  # NVIDIA RTX Virtual Workstation
 NVML_BRAND_NVIDIA_CLOUD_GAMING = 11  # NVIDIA Cloud Gaming
-NVML_BRAND_NVIDIA_VGAMING = NVML_BRAND_NVIDIA_CLOUD_GAMING  # Deprecated from API reporting. Keeping definition for backward compatibility.
-NVML_BRAND_QUADRO_RTX = 12
-NVML_BRAND_NVIDIA_RTX = 13
-NVML_BRAND_NVIDIA = 14
-NVML_BRAND_GEFORCE_RTX = 15  # Unused
-NVML_BRAND_TITAN_RTX = 16  # Unused
-NVML_BRAND_COUNT = 17
+NVML_BRAND_NVIDIA_VGAMING      = NVML_BRAND_NVIDIA_CLOUD_GAMING # Deprecated from API reporting. Keeping definition for backward compatibility.
+NVML_BRAND_QUADRO_RTX          = 12
+NVML_BRAND_NVIDIA_RTX          = 13
+NVML_BRAND_NVIDIA              = 14
+NVML_BRAND_GEFORCE_RTX         = 15  # Unused
+NVML_BRAND_TITAN_RTX           = 16  # Unused
+NVML_BRAND_COUNT               = 17
 
 _nvmlTemperatureThresholds_t = c_uint
-NVML_TEMPERATURE_THRESHOLD_SHUTDOWN = 0
-NVML_TEMPERATURE_THRESHOLD_SLOWDOWN = 1
-NVML_TEMPERATURE_THRESHOLD_MEM_MAX = 2
-NVML_TEMPERATURE_THRESHOLD_GPU_MAX = 3
-NVML_TEMPERATURE_THRESHOLD_ACOUSTIC_MIN = 4
+NVML_TEMPERATURE_THRESHOLD_SHUTDOWN      = 0
+NVML_TEMPERATURE_THRESHOLD_SLOWDOWN      = 1
+NVML_TEMPERATURE_THRESHOLD_MEM_MAX       = 2
+NVML_TEMPERATURE_THRESHOLD_GPU_MAX       = 3
+NVML_TEMPERATURE_THRESHOLD_ACOUSTIC_MIN  = 4
 NVML_TEMPERATURE_THRESHOLD_ACOUSTIC_CURR = 5
-NVML_TEMPERATURE_THRESHOLD_ACOUSTIC_MAX = 6
-NVML_TEMPERATURE_THRESHOLD_COUNT = 7
+NVML_TEMPERATURE_THRESHOLD_ACOUSTIC_MAX  = 6
+NVML_TEMPERATURE_THRESHOLD_COUNT         = 7
 
 _nvmlTemperatureSensors_t = c_uint
-NVML_TEMPERATURE_GPU = 0
-NVML_TEMPERATURE_COUNT = 1
+NVML_TEMPERATURE_GPU     = 0
+NVML_TEMPERATURE_COUNT   = 1
+
 
 _nvmlComputeMode_t = c_uint
-NVML_COMPUTEMODE_DEFAULT = 0
-NVML_COMPUTEMODE_EXCLUSIVE_THREAD = 1  ## Support Removed
-NVML_COMPUTEMODE_PROHIBITED = 2
+NVML_COMPUTEMODE_DEFAULT           = 0
+NVML_COMPUTEMODE_EXCLUSIVE_THREAD  = 1  ## Support Removed
+NVML_COMPUTEMODE_PROHIBITED        = 2
 NVML_COMPUTEMODE_EXCLUSIVE_PROCESS = 3
-NVML_COMPUTEMODE_COUNT = 4
+NVML_COMPUTEMODE_COUNT             = 4
 
 _nvmlMemoryLocation_t = c_uint
 NVML_MEMORY_LOCATION_L1_CACHE = 0
 NVML_MEMORY_LOCATION_L2_CACHE = 1
 NVML_MEMORY_LOCATION_DEVICE_MEMORY = 2
 NVML_MEMORY_LOCATION_DRAM = 2
 NVML_MEMORY_LOCATION_REGISTER_FILE = 3
@@ -118,175 +117,177 @@
 NVML_NVLINK_ERROR_DL_ECC_LANE2 = 2
 NVML_NVLINK_ERROR_DL_ECC_LANE3 = 3
 NVML_NVLINK_ERROR_DL_ECC_COUNT = 5
 
 _nvmlNvLinkCapability_t = c_uint
 NVML_NVLINK_CAP_P2P_SUPPORTED = 0
 NVML_NVLINK_CAP_SYSMEM_ACCESS = 1
-NVML_NVLINK_CAP_P2P_ATOMICS = 2
-NVML_NVLINK_CAP_SYSMEM_ATOMICS = 3
-NVML_NVLINK_CAP_SLI_BRIDGE = 4
-NVML_NVLINK_CAP_VALID = 5
-NVML_NVLINK_CAP_COUNT = 6
+NVML_NVLINK_CAP_P2P_ATOMICS   = 2
+NVML_NVLINK_CAP_SYSMEM_ATOMICS= 3
+NVML_NVLINK_CAP_SLI_BRIDGE    = 4
+NVML_NVLINK_CAP_VALID         = 5
+NVML_NVLINK_CAP_COUNT         = 6
 
 _nvmlNvLinkUtilizationCountPktTypes_t = c_uint
-NVML_NVLINK_COUNTER_PKTFILTER_NOP = 0x1
-NVML_NVLINK_COUNTER_PKTFILTER_READ = 0x2
-NVML_NVLINK_COUNTER_PKTFILTER_WRITE = 0x4
-NVML_NVLINK_COUNTER_PKTFILTER_RATOM = 0x8
-NVML_NVLINK_COUNTER_PKTFILTER_NRATOM = 0x10
-NVML_NVLINK_COUNTER_PKTFILTER_FLUSH = 0x20
-NVML_NVLINK_COUNTER_PKTFILTER_RESPDATA = 0x40
+NVML_NVLINK_COUNTER_PKTFILTER_NOP        = 0x1
+NVML_NVLINK_COUNTER_PKTFILTER_READ       = 0x2
+NVML_NVLINK_COUNTER_PKTFILTER_WRITE      = 0x4
+NVML_NVLINK_COUNTER_PKTFILTER_RATOM      = 0x8
+NVML_NVLINK_COUNTER_PKTFILTER_NRATOM     = 0x10
+NVML_NVLINK_COUNTER_PKTFILTER_FLUSH      = 0x20
+NVML_NVLINK_COUNTER_PKTFILTER_RESPDATA   = 0x40
 NVML_NVLINK_COUNTER_PKTFILTER_RESPNODATA = 0x80
-NVML_NVLINK_COUNTER_PKTFILTER_ALL = 0xFF
+NVML_NVLINK_COUNTER_PKTFILTER_ALL        = 0xFF
 
 _nvmlNvLinkUtilizationCountUnits_t = c_uint
-NVML_NVLINK_COUNTER_UNIT_CYCLES = 0
-NVML_NVLINK_COUNTER_UNIT_PACKETS = 1
-NVML_NVLINK_COUNTER_UNIT_BYTES = 2
+NVML_NVLINK_COUNTER_UNIT_CYCLES   = 0
+NVML_NVLINK_COUNTER_UNIT_PACKETS  = 1
+NVML_NVLINK_COUNTER_UNIT_BYTES    = 2
 NVML_NVLINK_COUNTER_UNIT_RESERVED = 3
-NVML_NVLINK_COUNTER_UNIT_COUNT = 4
+NVML_NVLINK_COUNTER_UNIT_COUNT    = 4
 
 _nvmlNvLinkDeviceType_t = c_uint
-NVML_NVLINK_DEVICE_TYPE_GPU = 0x00
-NVML_NVLINK_DEVICE_TYPE_IBMNPU = 0x01
-NVML_NVLINK_DEVICE_TYPE_SWITCH = 0x02
+NVML_NVLINK_DEVICE_TYPE_GPU     = 0x00
+NVML_NVLINK_DEVICE_TYPE_IBMNPU  = 0x01
+NVML_NVLINK_DEVICE_TYPE_SWITCH  = 0x02
 NVML_NVLINK_DEVICE_TYPE_UNKNOWN = 0xFF
 
 # These are deprecated, instead use _nvmlMemoryErrorType_t
 _nvmlEccBitType_t = c_uint
-NVML_SINGLE_BIT_ECC = 0
-NVML_DOUBLE_BIT_ECC = 1
+NVML_SINGLE_BIT_ECC    = 0
+NVML_DOUBLE_BIT_ECC    = 1
 NVML_ECC_ERROR_TYPE_COUNT = 2
 
 _nvmlEccCounterType_t = c_uint
-NVML_VOLATILE_ECC = 0
-NVML_AGGREGATE_ECC = 1
+NVML_VOLATILE_ECC      = 0
+NVML_AGGREGATE_ECC     = 1
 NVML_ECC_COUNTER_TYPE_COUNT = 2
 
 _nvmlMemoryErrorType_t = c_uint
-NVML_MEMORY_ERROR_TYPE_CORRECTED = 0
+NVML_MEMORY_ERROR_TYPE_CORRECTED   = 0
 NVML_MEMORY_ERROR_TYPE_UNCORRECTED = 1
-NVML_MEMORY_ERROR_TYPE_COUNT = 2
+NVML_MEMORY_ERROR_TYPE_COUNT       = 2
 
 _nvmlClockType_t = c_uint
-NVML_CLOCK_GRAPHICS = 0
-NVML_CLOCK_SM = 1
-NVML_CLOCK_MEM = 2
-NVML_CLOCK_VIDEO = 3
-NVML_CLOCK_COUNT = 4
+NVML_CLOCK_GRAPHICS  = 0
+NVML_CLOCK_SM        = 1
+NVML_CLOCK_MEM       = 2
+NVML_CLOCK_VIDEO     = 3
+NVML_CLOCK_COUNT     = 4
 
 _nvmlClockId_t = c_uint
-NVML_CLOCK_ID_CURRENT = 0
-NVML_CLOCK_ID_APP_CLOCK_TARGET = 1
-NVML_CLOCK_ID_APP_CLOCK_DEFAULT = 2
+NVML_CLOCK_ID_CURRENT            = 0
+NVML_CLOCK_ID_APP_CLOCK_TARGET   = 1
+NVML_CLOCK_ID_APP_CLOCK_DEFAULT  = 2
 NVML_CLOCK_ID_CUSTOMER_BOOST_MAX = 3
-NVML_CLOCK_ID_COUNT = 4
+NVML_CLOCK_ID_COUNT              = 4
 
 _nvmlDriverModel_t = c_uint
-NVML_DRIVER_WDDM = 0
-NVML_DRIVER_WDM = 1
-NVML_DRIVER_MCDM = 2
+NVML_DRIVER_WDDM       = 0
+NVML_DRIVER_WDM        = 1
+NVML_DRIVER_MCDM       = 2
 
 NVML_MAX_GPU_PERF_PSTATES = 16
 
 _nvmlPstates_t = c_uint
-NVML_PSTATE_0 = 0
-NVML_PSTATE_1 = 1
-NVML_PSTATE_2 = 2
-NVML_PSTATE_3 = 3
-NVML_PSTATE_4 = 4
-NVML_PSTATE_5 = 5
-NVML_PSTATE_6 = 6
-NVML_PSTATE_7 = 7
-NVML_PSTATE_8 = 8
-NVML_PSTATE_9 = 9
-NVML_PSTATE_10 = 10
-NVML_PSTATE_11 = 11
-NVML_PSTATE_12 = 12
-NVML_PSTATE_13 = 13
-NVML_PSTATE_14 = 14
-NVML_PSTATE_15 = 15
-NVML_PSTATE_UNKNOWN = 32
+NVML_PSTATE_0               = 0
+NVML_PSTATE_1               = 1
+NVML_PSTATE_2               = 2
+NVML_PSTATE_3               = 3
+NVML_PSTATE_4               = 4
+NVML_PSTATE_5               = 5
+NVML_PSTATE_6               = 6
+NVML_PSTATE_7               = 7
+NVML_PSTATE_8               = 8
+NVML_PSTATE_9               = 9
+NVML_PSTATE_10              = 10
+NVML_PSTATE_11              = 11
+NVML_PSTATE_12              = 12
+NVML_PSTATE_13              = 13
+NVML_PSTATE_14              = 14
+NVML_PSTATE_15              = 15
+NVML_PSTATE_UNKNOWN         = 32
 
 _nvmlInforomObject_t = c_uint
-NVML_INFOROM_OEM = 0
-NVML_INFOROM_ECC = 1
-NVML_INFOROM_POWER = 2
-NVML_INFOROM_COUNT = 3
+NVML_INFOROM_OEM            = 0
+NVML_INFOROM_ECC            = 1
+NVML_INFOROM_POWER          = 2
+NVML_INFOROM_COUNT          = 3
 
 _nvmlReturn_t = c_uint
-NVML_SUCCESS = 0
-NVML_ERROR_UNINITIALIZED = 1
-NVML_ERROR_INVALID_ARGUMENT = 2
-NVML_ERROR_NOT_SUPPORTED = 3
-NVML_ERROR_NO_PERMISSION = 4
-NVML_ERROR_ALREADY_INITIALIZED = 5
-NVML_ERROR_NOT_FOUND = 6
-NVML_ERROR_INSUFFICIENT_SIZE = 7
-NVML_ERROR_INSUFFICIENT_POWER = 8
-NVML_ERROR_DRIVER_NOT_LOADED = 9
-NVML_ERROR_TIMEOUT = 10
-NVML_ERROR_IRQ_ISSUE = 11
-NVML_ERROR_LIBRARY_NOT_FOUND = 12
-NVML_ERROR_FUNCTION_NOT_FOUND = 13
-NVML_ERROR_CORRUPTED_INFOROM = 14
-NVML_ERROR_GPU_IS_LOST = 15
-NVML_ERROR_RESET_REQUIRED = 16
-NVML_ERROR_OPERATING_SYSTEM = 17
-NVML_ERROR_LIB_RM_VERSION_MISMATCH = 18
-NVML_ERROR_IN_USE = 19
-NVML_ERROR_MEMORY = 20
-NVML_ERROR_NO_DATA = 21
-NVML_ERROR_VGPU_ECC_NOT_SUPPORTED = 22
-NVML_ERROR_INSUFFICIENT_RESOURCES = 23
-NVML_ERROR_FREQ_NOT_SUPPORTED = 24
+NVML_SUCCESS                         = 0
+NVML_ERROR_UNINITIALIZED             = 1
+NVML_ERROR_INVALID_ARGUMENT          = 2
+NVML_ERROR_NOT_SUPPORTED             = 3
+NVML_ERROR_NO_PERMISSION             = 4
+NVML_ERROR_ALREADY_INITIALIZED       = 5
+NVML_ERROR_NOT_FOUND                 = 6
+NVML_ERROR_INSUFFICIENT_SIZE         = 7
+NVML_ERROR_INSUFFICIENT_POWER        = 8
+NVML_ERROR_DRIVER_NOT_LOADED         = 9
+NVML_ERROR_TIMEOUT                   = 10
+NVML_ERROR_IRQ_ISSUE                 = 11
+NVML_ERROR_LIBRARY_NOT_FOUND         = 12
+NVML_ERROR_FUNCTION_NOT_FOUND        = 13
+NVML_ERROR_CORRUPTED_INFOROM         = 14
+NVML_ERROR_GPU_IS_LOST               = 15
+NVML_ERROR_RESET_REQUIRED            = 16
+NVML_ERROR_OPERATING_SYSTEM          = 17
+NVML_ERROR_LIB_RM_VERSION_MISMATCH   = 18
+NVML_ERROR_IN_USE                    = 19
+NVML_ERROR_MEMORY                    = 20
+NVML_ERROR_NO_DATA                   = 21
+NVML_ERROR_VGPU_ECC_NOT_SUPPORTED    = 22
+NVML_ERROR_INSUFFICIENT_RESOURCES    = 23
+NVML_ERROR_FREQ_NOT_SUPPORTED        = 24
 NVML_ERROR_ARGUMENT_VERSION_MISMATCH = 25
-NVML_ERROR_DEPRECATED = 26
-NVML_ERROR_UNKNOWN = 999
+NVML_ERROR_DEPRECATED                = 26
+NVML_ERROR_NOT_READY                 = 27
+NVML_ERROR_UNKNOWN                   = 999
 
 _nvmlFanState_t = c_uint
-NVML_FAN_NORMAL = 0
-NVML_FAN_FAILED = 1
+NVML_FAN_NORMAL             = 0
+NVML_FAN_FAILED             = 1
 
 _nvmlFanControlPolicy_t = c_uint
 NVML_FAN_POLICY_TEMPERATURE_CONTINOUS_SW = 0
-NVML_FAN_POLICY_MANUAL = 1
+NVML_FAN_POLICY_MANUAL                   = 1
 
 _nvmlLedColor_t = c_uint
-NVML_LED_COLOR_GREEN = 0
-NVML_LED_COLOR_AMBER = 1
+NVML_LED_COLOR_GREEN        = 0
+NVML_LED_COLOR_AMBER        = 1
 
 _nvmlGpuOperationMode_t = c_uint
-NVML_GOM_ALL_ON = 0
-NVML_GOM_COMPUTE = 1
-NVML_GOM_LOW_DP = 2
+NVML_GOM_ALL_ON                 = 0
+NVML_GOM_COMPUTE                = 1
+NVML_GOM_LOW_DP                 = 2
 
 _nvmlPageRetirementCause_t = c_uint
 NVML_PAGE_RETIREMENT_CAUSE_MULTIPLE_SINGLE_BIT_ECC_ERRORS = 0
-NVML_PAGE_RETIREMENT_CAUSE_DOUBLE_BIT_ECC_ERROR = 1
-NVML_PAGE_RETIREMENT_CAUSE_COUNT = 2
+NVML_PAGE_RETIREMENT_CAUSE_DOUBLE_BIT_ECC_ERROR           = 1
+NVML_PAGE_RETIREMENT_CAUSE_COUNT                          = 2
 
 _nvmlRestrictedAPI_t = c_uint
-NVML_RESTRICTED_API_SET_APPLICATION_CLOCKS = 0
-NVML_RESTRICTED_API_SET_AUTO_BOOSTED_CLOCKS = 1
-NVML_RESTRICTED_API_COUNT = 2
+NVML_RESTRICTED_API_SET_APPLICATION_CLOCKS                = 0
+NVML_RESTRICTED_API_SET_AUTO_BOOSTED_CLOCKS               = 1
+NVML_RESTRICTED_API_COUNT                                 = 2
 
 _nvmlBridgeChipType_t = c_uint
 NVML_BRIDGE_CHIP_PLX = 0
 NVML_BRIDGE_CHIP_BRO4 = 1
 NVML_MAX_PHYSICAL_BRIDGE = 128
 
 _nvmlValueType_t = c_uint
 NVML_VALUE_TYPE_DOUBLE = 0
 NVML_VALUE_TYPE_UNSIGNED_INT = 1
 NVML_VALUE_TYPE_UNSIGNED_LONG = 2
 NVML_VALUE_TYPE_UNSIGNED_LONG_LONG = 3
 NVML_VALUE_TYPE_SIGNED_LONG_LONG = 4
-NVML_VALUE_TYPE_COUNT = 5
+NVML_VALUE_TYPE_SIGNED_INT = 5
+NVML_VALUE_TYPE_COUNT = 6
 
 _nvmlPerfPolicyType_t = c_uint
 NVML_PERF_POLICY_POWER = 0
 NVML_PERF_POLICY_THERMAL = 1
 NVML_PERF_POLICY_SYNC_BOOST = 2
 NVML_PERF_POLICY_BOARD_LIMIT = 3
 NVML_PERF_POLICY_LOW_UTILIZATION = 4
@@ -294,14 +295,16 @@
 NVML_PERF_POLICY_TOTAL_APP_CLOCKS = 10
 NVML_PERF_POLICY_TOTAL_BASE_CLOCKS = 11
 NVML_PERF_POLICY_COUNT = 12
 
 _nvmlEncoderQueryType_t = c_uint
 NVML_ENCODER_QUERY_H264 = 0
 NVML_ENCODER_QUERY_HEVC = 1
+NVML_ENCODER_QUERY_AV1 = 2
+NVML_ENCODER_QUERY_UNKNOWN = 255
 
 _nvmlFBCSessionType_t = c_uint
 NVML_FBC_SESSION_TYPE_UNKNOWN = 0
 NVML_FBC_SESSION_TYPE_TOSYS = 1
 NVML_FBC_SESSION_TYPE_CUDA = 2
 NVML_FBC_SESSION_TYPE_VID = 3
 NVML_FBC_SESSION_TYPE_HWENC = 4
@@ -318,15 +321,16 @@
 NVML_TOTAL_POWER_SAMPLES = 0
 NVML_GPU_UTILIZATION_SAMPLES = 1
 NVML_MEMORY_UTILIZATION_SAMPLES = 2
 NVML_ENC_UTILIZATION_SAMPLES = 3
 NVML_DEC_UTILIZATION_SAMPLES = 4
 NVML_PROCESSOR_CLK_SAMPLES = 5
 NVML_MEMORY_CLK_SAMPLES = 6
-NVML_SAMPLINGTYPE_COUNT = 7
+NVML_MODULE_POWER_SAMPLES = 7
+NVML_SAMPLINGTYPE_COUNT = 8
 
 _nvmlPcieUtilCounter_t = c_uint
 NVML_PCIE_UTIL_TX_BYTES = 0
 NVML_PCIE_UTIL_RX_BYTES = 1
 NVML_PCIE_UTIL_COUNT = 2
 
 _nvmlGpuTopologyLevel_t = c_uint
@@ -335,483 +339,538 @@
 NVML_TOPOLOGY_MULTIPLE = 20
 NVML_TOPOLOGY_HOSTBRIDGE = 30
 NVML_TOPOLOGY_NODE = 40
 NVML_TOPOLOGY_CPU = NVML_TOPOLOGY_NODE
 NVML_TOPOLOGY_SYSTEM = 50
 
 _nvmlGpuP2PCapsIndex_t = c_uint
-NVML_P2P_CAPS_INDEX_READ = 0
+NVML_P2P_CAPS_INDEX_READ = 0,
 NVML_P2P_CAPS_INDEX_WRITE = 1
-NVML_P2P_CAPS_INDEX_NVLINK = 2
+NVML_P2P_CAPS_INDEX_NVLINK =2
 NVML_P2P_CAPS_INDEX_ATOMICS = 3
 NVML_P2P_CAPS_INDEX_PROP = 4
 NVML_P2P_CAPS_INDEX_LOOPBACK = 5
 NVML_P2P_CAPS_INDEX_UNKNOWN = 6
 
 _nvmlGpuP2PStatus_t = c_uint
-NVML_P2P_STATUS_OK = 0
+NVML_P2P_STATUS_OK     = 0
 NVML_P2P_STATUS_CHIPSET_NOT_SUPPORED = 1
+NVML_P2P_STATUS_CHIPSET_NOT_SUPPORTED = NVML_P2P_STATUS_CHIPSET_NOT_SUPPORED
 NVML_P2P_STATUS_GPU_NOT_SUPPORTED = 2
-NVML_P2P_STATUS_IOH_TOPOLOGY_NOT_SUPPORTED = 3
-NVML_P2P_STATUS_DISABLED_BY_REGKEY = 4
-NVML_P2P_STATUS_NOT_SUPPORTED = 5
-NVML_P2P_STATUS_UNKNOWN = 6
+NVML_P2P_STATUS_IOH_TOPOLOGY_NOT_SUPPORTED =3
+NVML_P2P_STATUS_DISABLED_BY_REGKEY =4
+NVML_P2P_STATUS_NOT_SUPPORTED =5
+NVML_P2P_STATUS_UNKNOWN =6
 
 _nvmlDeviceArchitecture_t = c_uint
-NVML_DEVICE_ARCH_KEPLER = 2
-NVML_DEVICE_ARCH_MAXWELL = 3
-NVML_DEVICE_ARCH_PASCAL = 4
-NVML_DEVICE_ARCH_VOLTA = 5
-NVML_DEVICE_ARCH_TURING = 6
-NVML_DEVICE_ARCH_AMPERE = 7
-NVML_DEVICE_ARCH_ADA = 8
-NVML_DEVICE_ARCH_HOPPER = 9
-NVML_DEVICE_ARCH_UNKNOWN = 0xffffffff
+NVML_DEVICE_ARCH_KEPLER   = 2
+NVML_DEVICE_ARCH_MAXWELL  = 3
+NVML_DEVICE_ARCH_PASCAL   = 4
+NVML_DEVICE_ARCH_VOLTA    = 5
+NVML_DEVICE_ARCH_TURING   = 6
+NVML_DEVICE_ARCH_AMPERE   = 7
+NVML_DEVICE_ARCH_ADA      = 8
+NVML_DEVICE_ARCH_HOPPER   = 9
+NVML_DEVICE_ARCH_UNKNOWN  = 0xffffffff
 
 # PCI bus Types
 _nvmlBusType_t = c_uint
 NVML_BUS_TYPE_UNKNOWN = 0
-NVML_BUS_TYPE_PCI = 1
-NVML_BUS_TYPE_PCIE = 2
-NVML_BUS_TYPE_FPCI = 3
-NVML_BUS_TYPE_AGP = 4
+NVML_BUS_TYPE_PCI     = 1
+NVML_BUS_TYPE_PCIE    = 2
+NVML_BUS_TYPE_FPCI    = 3
+NVML_BUS_TYPE_AGP     = 4
 
 _nvmlPowerSource_t = c_uint
-NVML_POWER_SOURCE_AC = 0x00000000
-NVML_POWER_SOURCE_BATTERY = 0x00000001
+NVML_POWER_SOURCE_AC         = 0x00000000
+NVML_POWER_SOURCE_BATTERY    = 0x00000001
+NVML_POWER_SOURCE_UNDERSIZED = 0x00000002
 
 _nvmlAdaptiveClockInfoStatus_t = c_uint
 NVML_ADAPTIVE_CLOCKING_INFO_STATUS_DISABLED = 0x00000000
 NVML_ADAPTIVE_CLOCKING_INFO_STATUS_ENABLED = 0x00000001
 
 _nvmlClockLimitId_t = c_uint
 NVML_CLOCK_LIMIT_ID_RANGE_START = 0xffffff00
-NVML_CLOCK_LIMIT_ID_TDP = 0xffffff01
-NVML_CLOCK_LIMIT_ID_UNLIMITED = 0xffffff02
+NVML_CLOCK_LIMIT_ID_TDP         = 0xffffff01
+NVML_CLOCK_LIMIT_ID_UNLIMITED   = 0xffffff02
 
 _nvmlPcieLinkMaxSpeed_t = c_uint
-NVML_PCIE_LINK_MAX_SPEED_INVALID = 0x00000000
-NVML_PCIE_LINK_MAX_SPEED_2500MBPS = 0x00000001
-NVML_PCIE_LINK_MAX_SPEED_5000MBPS = 0x00000002
-NVML_PCIE_LINK_MAX_SPEED_8000MBPS = 0x00000003
+NVML_PCIE_LINK_MAX_SPEED_INVALID   = 0x00000000
+NVML_PCIE_LINK_MAX_SPEED_2500MBPS  = 0x00000001
+NVML_PCIE_LINK_MAX_SPEED_5000MBPS  = 0x00000002
+NVML_PCIE_LINK_MAX_SPEED_8000MBPS  = 0x00000003
 NVML_PCIE_LINK_MAX_SPEED_16000MBPS = 0x00000004
 NVML_PCIE_LINK_MAX_SPEED_32000MBPS = 0x00000005
 NVML_PCIE_LINK_MAX_SPEED_64000MBPS = 0x00000006
 
 _nvmlAffinityScope_t = c_uint
-NVML_AFFINITY_SCOPE_NODE = 0
+NVML_AFFINITY_SCOPE_NODE   = 0
 NVML_AFFINITY_SCOPE_SOCKET = 1
 
 # C preprocessor defined values
-nvmlFlagDefault = 0
-nvmlFlagForce = 1
-NVML_INIT_FLAG_NO_GPUS = 1
-NVML_INIT_FLAG_NO_ATTACH = 2
+nvmlFlagDefault             = 0
+nvmlFlagForce               = 1
+NVML_INIT_FLAG_NO_GPUS      = 1
+NVML_INIT_FLAG_NO_ATTACH    = 2
 
-NVML_MAX_GPC_COUNT = 32
+NVML_MAX_GPC_COUNT          = 32
 
 # buffer size
-NVML_DEVICE_INFOROM_VERSION_BUFFER_SIZE = 16
-NVML_DEVICE_UUID_BUFFER_SIZE = 80
-NVML_DEVICE_UUID_V2_BUFFER_SIZE = 96
-NVML_SYSTEM_DRIVER_VERSION_BUFFER_SIZE = 80
-NVML_SYSTEM_NVML_VERSION_BUFFER_SIZE = 80
-NVML_DEVICE_NAME_BUFFER_SIZE = 64
-NVML_DEVICE_NAME_V2_BUFFER_SIZE = 96
-NVML_DEVICE_SERIAL_BUFFER_SIZE = 30
-NVML_DEVICE_PART_NUMBER_BUFFER_SIZE = 80
-NVML_DEVICE_GPU_PART_NUMBER_BUFFER_SIZE = 80
-NVML_DEVICE_VBIOS_VERSION_BUFFER_SIZE = 32
-NVML_DEVICE_PCI_BUS_ID_BUFFER_SIZE = 32
-NVML_DEVICE_PCI_BUS_ID_BUFFER_V2_SIZE = 16
-NVML_GRID_LICENSE_BUFFER_SIZE = 128
-NVML_VGPU_NAME_BUFFER_SIZE = 64
-NVML_GRID_LICENSE_FEATURE_MAX_COUNT = 3
-NVML_VGPU_METADATA_OPAQUE_DATA_SIZE = sizeof(c_uint) + 256
-NVML_VGPU_PGPU_METADATA_OPAQUE_DATA_SIZE = 256
+NVML_DEVICE_INFOROM_VERSION_BUFFER_SIZE      = 16
+NVML_DEVICE_UUID_BUFFER_SIZE                 = 80
+NVML_DEVICE_UUID_V2_BUFFER_SIZE              = 96
+NVML_SYSTEM_DRIVER_VERSION_BUFFER_SIZE       = 80
+NVML_SYSTEM_NVML_VERSION_BUFFER_SIZE         = 80
+NVML_DEVICE_NAME_BUFFER_SIZE                 = 64
+NVML_DEVICE_NAME_V2_BUFFER_SIZE              = 96
+NVML_DEVICE_SERIAL_BUFFER_SIZE               = 30
+NVML_DEVICE_PART_NUMBER_BUFFER_SIZE          = 80
+NVML_DEVICE_GPU_PART_NUMBER_BUFFER_SIZE      = 80
+NVML_DEVICE_VBIOS_VERSION_BUFFER_SIZE        = 32
+NVML_DEVICE_PCI_BUS_ID_BUFFER_SIZE           = 32
+NVML_DEVICE_PCI_BUS_ID_BUFFER_V2_SIZE        = 16
+NVML_GRID_LICENSE_BUFFER_SIZE                = 128
+NVML_VGPU_NAME_BUFFER_SIZE                   = 64
+NVML_GRID_LICENSE_FEATURE_MAX_COUNT          = 3
+NVML_VGPU_METADATA_OPAQUE_DATA_SIZE          = sizeof(c_uint) + 256
+NVML_VGPU_PGPU_METADATA_OPAQUE_DATA_SIZE     = 256
+NVML_DEVICE_GPU_FRU_PART_NUMBER_BUFFER_SIZE  = 0x14 # NV2080_GPU_MAX_PRODUCT_PART_NUMBER_LENGTH
 
 # Format strings
-NVML_DEVICE_PCI_BUS_ID_LEGACY_FMT = "%04X:%02X:%02X.0"
-NVML_DEVICE_PCI_BUS_ID_FMT = "%08X:%02X:%02X.0"
+NVML_DEVICE_PCI_BUS_ID_LEGACY_FMT   = "%04X:%02X:%02X.0"
+NVML_DEVICE_PCI_BUS_ID_FMT          = "%08X:%02X:%02X.0"
 
 NVML_VALUE_NOT_AVAILABLE_ulonglong = c_ulonglong(-1)
 NVML_VALUE_NOT_AVAILABLE_uint = c_uint(-1)
 
 '''
  Field Identifiers.
 
  All Identifiers pertain to a device. Each ID is only used once and is guaranteed never to change.
 '''
-NVML_FI_DEV_ECC_CURRENT = 1  # Current ECC mode. 1=Active. 0=Inactive
-NVML_FI_DEV_ECC_PENDING = 2  # Pending ECC mode. 1=Active. 0=Inactive
+NVML_FI_DEV_ECC_CURRENT          = 1   # Current ECC mode. 1=Active. 0=Inactive
+NVML_FI_DEV_ECC_PENDING          = 2   # Pending ECC mode. 1=Active. 0=Inactive
 
-# ECC Count Totals
-NVML_FI_DEV_ECC_SBE_VOL_TOTAL = 3  # Total single bit volatile ECC errors
-NVML_FI_DEV_ECC_DBE_VOL_TOTAL = 4  # Total double bit volatile ECC errors
-NVML_FI_DEV_ECC_SBE_AGG_TOTAL = 5  # Total single bit aggregate (persistent) ECC errors
-NVML_FI_DEV_ECC_DBE_AGG_TOTAL = 6  # Total double bit aggregate (persistent) ECC errors
-# Individual ECC locations
-NVML_FI_DEV_ECC_SBE_VOL_L1 = 7  # L1 cache single bit volatile ECC errors
-NVML_FI_DEV_ECC_DBE_VOL_L1 = 8  # L1 cache double bit volatile ECC errors
-NVML_FI_DEV_ECC_SBE_VOL_L2 = 9  # L2 cache single bit volatile ECC errors
-NVML_FI_DEV_ECC_DBE_VOL_L2 = 10  # L2 cache double bit volatile ECC errors
-NVML_FI_DEV_ECC_SBE_VOL_DEV = 11  # Device memory single bit volatile ECC errors
-NVML_FI_DEV_ECC_DBE_VOL_DEV = 12  # Device memory double bit volatile ECC errors
-NVML_FI_DEV_ECC_SBE_VOL_REG = 13  # Register file single bit volatile ECC errors
-NVML_FI_DEV_ECC_DBE_VOL_REG = 14  # Register file double bit volatile ECC errors
-NVML_FI_DEV_ECC_SBE_VOL_TEX = 15  # Texture memory single bit volatile ECC errors
-NVML_FI_DEV_ECC_DBE_VOL_TEX = 16  # Texture memory double bit volatile ECC errors
-NVML_FI_DEV_ECC_DBE_VOL_CBU = 17  # CBU double bit volatile ECC errors
-NVML_FI_DEV_ECC_SBE_AGG_L1 = 18  # L1 cache single bit aggregate (persistent) ECC errors
-NVML_FI_DEV_ECC_DBE_AGG_L1 = 19  # L1 cache double bit aggregate (persistent) ECC errors
-NVML_FI_DEV_ECC_SBE_AGG_L2 = 20  # L2 cache single bit aggregate (persistent) ECC errors
-NVML_FI_DEV_ECC_DBE_AGG_L2 = 21  # L2 cache double bit aggregate (persistent) ECC errors
-NVML_FI_DEV_ECC_SBE_AGG_DEV = 22  # Device memory single bit aggregate (persistent) ECC errors
-NVML_FI_DEV_ECC_DBE_AGG_DEV = 23  # Device memory double bit aggregate (persistent) ECC errors
-NVML_FI_DEV_ECC_SBE_AGG_REG = 24  # Register File single bit aggregate (persistent) ECC errors
-NVML_FI_DEV_ECC_DBE_AGG_REG = 25  # Register File double bit aggregate (persistent) ECC errors
-NVML_FI_DEV_ECC_SBE_AGG_TEX = 26  # Texture memory single bit aggregate (persistent) ECC errors
-NVML_FI_DEV_ECC_DBE_AGG_TEX = 27  # Texture memory double bit aggregate (persistent) ECC errors
-NVML_FI_DEV_ECC_DBE_AGG_CBU = 28  # CBU double bit aggregate ECC errors
+#ECC Count Totals
+NVML_FI_DEV_ECC_SBE_VOL_TOTAL    = 3   # Total single bit volatile ECC errors
+NVML_FI_DEV_ECC_DBE_VOL_TOTAL    = 4   # Total double bit volatile ECC errors
+NVML_FI_DEV_ECC_SBE_AGG_TOTAL    = 5   # Total single bit aggregate (persistent) ECC errors
+NVML_FI_DEV_ECC_DBE_AGG_TOTAL    = 6   # Total double bit aggregate (persistent) ECC errors
+#Individual ECC locations
+NVML_FI_DEV_ECC_SBE_VOL_L1       = 7   # L1 cache single bit volatile ECC errors
+NVML_FI_DEV_ECC_DBE_VOL_L1       = 8   # L1 cache double bit volatile ECC errors
+NVML_FI_DEV_ECC_SBE_VOL_L2       = 9   # L2 cache single bit volatile ECC errors
+NVML_FI_DEV_ECC_DBE_VOL_L2       = 10  # L2 cache double bit volatile ECC errors
+NVML_FI_DEV_ECC_SBE_VOL_DEV      = 11  # Device memory single bit volatile ECC errors
+NVML_FI_DEV_ECC_DBE_VOL_DEV      = 12  # Device memory double bit volatile ECC errors
+NVML_FI_DEV_ECC_SBE_VOL_REG      = 13  # Register file single bit volatile ECC errors
+NVML_FI_DEV_ECC_DBE_VOL_REG      = 14  # Register file double bit volatile ECC errors
+NVML_FI_DEV_ECC_SBE_VOL_TEX      = 15  # Texture memory single bit volatile ECC errors
+NVML_FI_DEV_ECC_DBE_VOL_TEX      = 16  # Texture memory double bit volatile ECC errors
+NVML_FI_DEV_ECC_DBE_VOL_CBU      = 17  # CBU double bit volatile ECC errors
+NVML_FI_DEV_ECC_SBE_AGG_L1       = 18  # L1 cache single bit aggregate (persistent) ECC errors
+NVML_FI_DEV_ECC_DBE_AGG_L1       = 19  # L1 cache double bit aggregate (persistent) ECC errors
+NVML_FI_DEV_ECC_SBE_AGG_L2       = 20  # L2 cache single bit aggregate (persistent) ECC errors
+NVML_FI_DEV_ECC_DBE_AGG_L2       = 21  # L2 cache double bit aggregate (persistent) ECC errors
+NVML_FI_DEV_ECC_SBE_AGG_DEV      = 22  # Device memory single bit aggregate (persistent) ECC errors
+NVML_FI_DEV_ECC_DBE_AGG_DEV      = 23  # Device memory double bit aggregate (persistent) ECC errors
+NVML_FI_DEV_ECC_SBE_AGG_REG      = 24  # Register File single bit aggregate (persistent) ECC errors
+NVML_FI_DEV_ECC_DBE_AGG_REG      = 25  # Register File double bit aggregate (persistent) ECC errors
+NVML_FI_DEV_ECC_SBE_AGG_TEX      = 26  # Texture memory single bit aggregate (persistent) ECC errors
+NVML_FI_DEV_ECC_DBE_AGG_TEX      = 27  # Texture memory double bit aggregate (persistent) ECC errors
+NVML_FI_DEV_ECC_DBE_AGG_CBU      = 28  # CBU double bit aggregate ECC errors
 
 # Page Retirement
-NVML_FI_DEV_RETIRED_SBE = 29  # Number of retired pages because of single bit errors
-NVML_FI_DEV_RETIRED_DBE = 30  # Number of retired pages because of double bit errors
-NVML_FI_DEV_RETIRED_PENDING = 31  # If any pages are pending retirement. 1=yes. 0=no.
+NVML_FI_DEV_RETIRED_SBE          = 29  # Number of retired pages because of single bit errors
+NVML_FI_DEV_RETIRED_DBE          = 30  # Number of retired pages because of double bit errors
+NVML_FI_DEV_RETIRED_PENDING      = 31  # If any pages are pending retirement. 1=yes. 0=no.
 
 # NvLink Flit Error Counters
-NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L0 = 32  # NVLink flow control CRC  Error Counter for Lane 0
-NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L1 = 33  # NVLink flow control CRC  Error Counter for Lane 1
-NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L2 = 34  # NVLink flow control CRC  Error Counter for Lane 2
-NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L3 = 35  # NVLink flow control CRC  Error Counter for Lane 3
-NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L4 = 36  # NVLink flow control CRC  Error Counter for Lane 4
-NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L5 = 37  # NVLink flow control CRC  Error Counter for Lane 5
-NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_TOTAL = 38  # NVLink flow control CRC  Error Counter total for all Lanes
+NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L0   = 32 # NVLink flow control CRC  Error Counter for Lane 0
+NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L1   = 33 # NVLink flow control CRC  Error Counter for Lane 1
+NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L2   = 34 # NVLink flow control CRC  Error Counter for Lane 2
+NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L3   = 35 # NVLink flow control CRC  Error Counter for Lane 3
+NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L4   = 36 # NVLink flow control CRC  Error Counter for Lane 4
+NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L5   = 37 # NVLink flow control CRC  Error Counter for Lane 5
+NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_TOTAL = 38 # NVLink flow control CRC  Error Counter total for all Lanes
 
 # NvLink CRC Data Error Counters
-NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L0 = 39  # NVLink data CRC Error Counter for Lane 0
-NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L1 = 40  # NVLink data CRC Error Counter for Lane 1
-NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L2 = 41  # NVLink data CRC Error Counter for Lane 2
-NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L3 = 42  # NVLink data CRC Error Counter for Lane 3
-NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L4 = 43  # NVLink data CRC Error Counter for Lane 4
-NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L5 = 44  # NVLink data CRC Error Counter for Lane 5
-NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_TOTAL = 45  # NvLink data CRC Error Counter total for all Lanes
+NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L0   = 39 # NVLink data CRC Error Counter for Lane 0
+NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L1   = 40 # NVLink data CRC Error Counter for Lane 1
+NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L2   = 41 # NVLink data CRC Error Counter for Lane 2
+NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L3   = 42 # NVLink data CRC Error Counter for Lane 3
+NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L4   = 43 # NVLink data CRC Error Counter for Lane 4
+NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L5   = 44 # NVLink data CRC Error Counter for Lane 5
+NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_TOTAL = 45 # NvLink data CRC Error Counter total for all Lanes
 
 # NvLink Replay Error Counters
-NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L0 = 46  # NVLink Replay Error Counter for Lane 0
-NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L1 = 47  # NVLink Replay Error Counter for Lane 1
-NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L2 = 48  # NVLink Replay Error Counter for Lane 2
-NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L3 = 49  # NVLink Replay Error Counter for Lane 3
-NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L4 = 50  # NVLink Replay Error Counter for Lane 4
-NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L5 = 51  # NVLink Replay Error Counter for Lane 5
-NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_TOTAL = 52  # NVLink Replay Error Counter total for all Lanes
+NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L0     = 46 # NVLink Replay Error Counter for Lane 0
+NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L1     = 47 # NVLink Replay Error Counter for Lane 1
+NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L2     = 48 # NVLink Replay Error Counter for Lane 2
+NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L3     = 49 # NVLink Replay Error Counter for Lane 3
+NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L4     = 50 # NVLink Replay Error Counter for Lane 4
+NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L5     = 51 # NVLink Replay Error Counter for Lane 5
+NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_TOTAL  = 52 # NVLink Replay Error Counter total for all Lanes
 
 # NvLink Recovery Error Counters
-NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L0 = 53  # NVLink Recovery Error Counter for Lane 0
-NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L1 = 54  # NVLink Recovery Error Counter for Lane 1
-NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L2 = 55  # NVLink Recovery Error Counter for Lane 2
-NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L3 = 56  # NVLink Recovery Error Counter for Lane 3
-NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L4 = 57  # NVLink Recovery Error Counter for Lane 4
-NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L5 = 58  # NVLink Recovery Error Counter for Lane 5
-NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_TOTAL = 59  # NVLink Recovery Error Counter total for all Lanes
+NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L0   = 53 # NVLink Recovery Error Counter for Lane 0
+NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L1   = 54 # NVLink Recovery Error Counter for Lane 1
+NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L2   = 55 # NVLink Recovery Error Counter for Lane 2
+NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L3   = 56 # NVLink Recovery Error Counter for Lane 3
+NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L4   = 57 # NVLink Recovery Error Counter for Lane 4
+NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L5   = 58 # NVLink Recovery Error Counter for Lane 5
+NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_TOTAL = 59 # NVLink Recovery Error Counter total for all Lanes
 
 # NvLink Bandwidth Counters
-NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L0 = 60  # NVLink Bandwidth Counter for Counter Set 0, Lane 0
-NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L1 = 61  # NVLink Bandwidth Counter for Counter Set 0, Lane 1
-NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L2 = 62  # NVLink Bandwidth Counter for Counter Set 0, Lane 2
-NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L3 = 63  # NVLink Bandwidth Counter for Counter Set 0, Lane 3
-NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L4 = 64  # NVLink Bandwidth Counter for Counter Set 0, Lane 4
-NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L5 = 65  # NVLink Bandwidth Counter for Counter Set 0, Lane 5
-NVML_FI_DEV_NVLINK_BANDWIDTH_C0_TOTAL = 66  # NVLink Bandwidth Counter Total for Counter Set 0, All Lanes
+NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L0    = 60 # NVLink Bandwidth Counter for Counter Set 0, Lane 0
+NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L1    = 61 # NVLink Bandwidth Counter for Counter Set 0, Lane 1
+NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L2    = 62 # NVLink Bandwidth Counter for Counter Set 0, Lane 2
+NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L3    = 63 # NVLink Bandwidth Counter for Counter Set 0, Lane 3
+NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L4    = 64 # NVLink Bandwidth Counter for Counter Set 0, Lane 4
+NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L5    = 65 # NVLink Bandwidth Counter for Counter Set 0, Lane 5
+NVML_FI_DEV_NVLINK_BANDWIDTH_C0_TOTAL = 66 # NVLink Bandwidth Counter Total for Counter Set 0, All Lanes
 
 # NvLink Bandwidth Counters
-NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L0 = 67  # NVLink Bandwidth Counter for Counter Set 1, Lane 0
-NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L1 = 68  # NVLink Bandwidth Counter for Counter Set 1, Lane 1
-NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L2 = 69  # NVLink Bandwidth Counter for Counter Set 1, Lane 2
-NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L3 = 70  # NVLink Bandwidth Counter for Counter Set 1, Lane 3
-NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L4 = 71  # NVLink Bandwidth Counter for Counter Set 1, Lane 4
-NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L5 = 72  # NVLink Bandwidth Counter for Counter Set 1, Lane 5
-NVML_FI_DEV_NVLINK_BANDWIDTH_C1_TOTAL = 73  # NVLink Bandwidth Counter Total for Counter Set 1, All Lanes
+NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L0    = 67 # NVLink Bandwidth Counter for Counter Set 1, Lane 0
+NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L1    = 68 # NVLink Bandwidth Counter for Counter Set 1, Lane 1
+NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L2    = 69 # NVLink Bandwidth Counter for Counter Set 1, Lane 2
+NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L3    = 70 # NVLink Bandwidth Counter for Counter Set 1, Lane 3
+NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L4    = 71 # NVLink Bandwidth Counter for Counter Set 1, Lane 4
+NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L5    = 72 # NVLink Bandwidth Counter for Counter Set 1, Lane 5
+NVML_FI_DEV_NVLINK_BANDWIDTH_C1_TOTAL = 73 # NVLink Bandwidth Counter Total for Counter Set 1, All Lanes
 
 # Perf Policy Counters
-NVML_FI_DEV_PERF_POLICY_POWER = 74  # Perf Policy Counter for Power Policy
-NVML_FI_DEV_PERF_POLICY_THERMAL = 75  # Perf Policy Counter for Thermal Policy
-NVML_FI_DEV_PERF_POLICY_SYNC_BOOST = 76  # Perf Policy Counter for Sync boost Policy
-NVML_FI_DEV_PERF_POLICY_BOARD_LIMIT = 77  # Perf Policy Counter for Board Limit
-NVML_FI_DEV_PERF_POLICY_LOW_UTILIZATION = 78  # Perf Policy Counter for Low GPU Utilization Policy
-NVML_FI_DEV_PERF_POLICY_RELIABILITY = 79  # Perf Policy Counter for Reliability Policy
-NVML_FI_DEV_PERF_POLICY_TOTAL_APP_CLOCKS = 80  # Perf Policy Counter for Total App Clock Policy
-NVML_FI_DEV_PERF_POLICY_TOTAL_BASE_CLOCKS = 81  # Perf Policy Counter for Total Base Clocks Policy
+NVML_FI_DEV_PERF_POLICY_POWER             = 74   # Perf Policy Counter for Power Policy
+NVML_FI_DEV_PERF_POLICY_THERMAL           = 75   # Perf Policy Counter for Thermal Policy
+NVML_FI_DEV_PERF_POLICY_SYNC_BOOST        = 76   # Perf Policy Counter for Sync boost Policy
+NVML_FI_DEV_PERF_POLICY_BOARD_LIMIT       = 77   # Perf Policy Counter for Board Limit
+NVML_FI_DEV_PERF_POLICY_LOW_UTILIZATION   = 78   # Perf Policy Counter for Low GPU Utilization Policy
+NVML_FI_DEV_PERF_POLICY_RELIABILITY       = 79   # Perf Policy Counter for Reliability Policy
+NVML_FI_DEV_PERF_POLICY_TOTAL_APP_CLOCKS  = 80   # Perf Policy Counter for Total App Clock Policy
+NVML_FI_DEV_PERF_POLICY_TOTAL_BASE_CLOCKS = 81   # Perf Policy Counter for Total Base Clocks Policy
 
 # Memory temperatures
-NVML_FI_DEV_MEMORY_TEMP = 82  # Memory temperature for the device
+NVML_FI_DEV_MEMORY_TEMP  = 82 # Memory temperature for the device
 
 # Energy Counter
-NVML_FI_DEV_TOTAL_ENERGY_CONSUMPTION = 83  # Total energy consumption for the GPU in mJ since the driver was last reloaded
+NVML_FI_DEV_TOTAL_ENERGY_CONSUMPTION = 83 # Total energy consumption for the GPU in mJ since the driver was last reloaded
 
 # NVLink Speed
-NVML_FI_DEV_NVLINK_SPEED_MBPS_L0 = 84
-NVML_FI_DEV_NVLINK_SPEED_MBPS_L1 = 85
-NVML_FI_DEV_NVLINK_SPEED_MBPS_L2 = 86
-NVML_FI_DEV_NVLINK_SPEED_MBPS_L3 = 87
-NVML_FI_DEV_NVLINK_SPEED_MBPS_L4 = 88
-NVML_FI_DEV_NVLINK_SPEED_MBPS_L5 = 89
+NVML_FI_DEV_NVLINK_SPEED_MBPS_L0     = 84
+NVML_FI_DEV_NVLINK_SPEED_MBPS_L1     = 85
+NVML_FI_DEV_NVLINK_SPEED_MBPS_L2     = 86
+NVML_FI_DEV_NVLINK_SPEED_MBPS_L3     = 87
+NVML_FI_DEV_NVLINK_SPEED_MBPS_L4     = 88
+NVML_FI_DEV_NVLINK_SPEED_MBPS_L5     = 89
 NVML_FI_DEV_NVLINK_SPEED_MBPS_COMMON = 90
 
 # NVLink Link Count
 NVML_FI_DEV_NVLINK_LINK_COUNT = 91
 
 # Page Retirement pending fields
 NVML_FI_DEV_RETIRED_PENDING_SBE = 92
 NVML_FI_DEV_RETIRED_PENDING_DBE = 93
 
 # PCIe replay and replay rollover counters
 NVML_FI_DEV_PCIE_REPLAY_COUNTER = 94
 NVML_FI_DEV_PCIE_REPLAY_ROLLOVER_COUNTER = 95
 
 # NvLink Flit Error Counters
-NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L6 = 96  # NVLink flow control CRC  Error Counter for Lane 6
-NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L7 = 97  # NVLink flow control CRC  Error Counter for Lane 7
-NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L8 = 98  # NVLink flow control CRC  Error Counter for Lane 8
-NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L9 = 99  # NVLink flow control CRC  Error Counter for Lane 9
-NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L10 = 100  # NVLink flow control CRC  Error Counter for Lane 10
-NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L11 = 101  # NVLink flow control CRC  Error Counter for Lane 11
+NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L6   = 96 # NVLink flow control CRC  Error Counter for Lane 6
+NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L7   = 97 # NVLink flow control CRC  Error Counter for Lane 7
+NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L8   = 98 # NVLink flow control CRC  Error Counter for Lane 8
+NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L9   = 99 # NVLink flow control CRC  Error Counter for Lane 9
+NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L10  = 100 # NVLink flow control CRC  Error Counter for Lane 10
+NVML_FI_DEV_NVLINK_CRC_FLIT_ERROR_COUNT_L11  = 101 # NVLink flow control CRC  Error Counter for Lane 11
 
 # NvLink CRC Data Error Counters
-NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L6 = 102  # NVLink data CRC Error Counter for Lane 6
-NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L7 = 103  # NVLink data CRC Error Counter for Lane 7
-NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L8 = 104  # NVLink data CRC Error Counter for Lane 8
-NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L9 = 105  # NVLink data CRC Error Counter for Lane 9
-NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L10 = 106  # NVLink data CRC Error Counter for Lane 10
-NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L11 = 107  # NVLink data CRC Error Counter for Lane 11
+NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L6   = 102 # NVLink data CRC Error Counter for Lane 6
+NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L7   = 103 # NVLink data CRC Error Counter for Lane 7
+NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L8   = 104 # NVLink data CRC Error Counter for Lane 8
+NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L9   = 105 # NVLink data CRC Error Counter for Lane 9
+NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L10  = 106 # NVLink data CRC Error Counter for Lane 10
+NVML_FI_DEV_NVLINK_CRC_DATA_ERROR_COUNT_L11  = 107 # NVLink data CRC Error Counter for Lane 11
 
 # NvLink Replay Error Counters
-NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L6 = 108  # NVLink Replay Error Counter for Lane 6
-NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L7 = 109  # NVLink Replay Error Counter for Lane 7
-NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L8 = 110  # NVLink Replay Error Counter for Lane 8
-NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L9 = 111  # NVLink Replay Error Counter for Lane 9
-NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L10 = 112  # NVLink Replay Error Counter for Lane 10
-NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L11 = 113  # NVLink Replay Error Counter for Lane 11
+NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L6     = 108 # NVLink Replay Error Counter for Lane 6
+NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L7     = 109 # NVLink Replay Error Counter for Lane 7
+NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L8     = 110 # NVLink Replay Error Counter for Lane 8
+NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L9     = 111 # NVLink Replay Error Counter for Lane 9
+NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L10    = 112 # NVLink Replay Error Counter for Lane 10
+NVML_FI_DEV_NVLINK_REPLAY_ERROR_COUNT_L11    = 113 # NVLink Replay Error Counter for Lane 11
 
 # NvLink Recovery Error Counters
-NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L6 = 114  # NVLink Recovery Error Counter for Lane 6
-NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L7 = 115  # NVLink Recovery Error Counter for Lane 7
-NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L8 = 116  # NVLink Recovery Error Counter for Lane 8
-NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L9 = 117  # NVLink Recovery Error Counter for Lane 9
-NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L10 = 118  # NVLink Recovery Error Counter for Lane 10
-NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L11 = 119  # NVLink Recovery Error Counter for Lane 11
+NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L6   = 114 # NVLink Recovery Error Counter for Lane 6
+NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L7   = 115 # NVLink Recovery Error Counter for Lane 7
+NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L8   = 116 # NVLink Recovery Error Counter for Lane 8
+NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L9   = 117 # NVLink Recovery Error Counter for Lane 9
+NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L10  = 118 # NVLink Recovery Error Counter for Lane 10
+NVML_FI_DEV_NVLINK_RECOVERY_ERROR_COUNT_L11  = 119 # NVLink Recovery Error Counter for Lane 11
 
 # NvLink Bandwidth Counters
-NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L6 = 120  # NVLink Bandwidth Counter for Counter Set 0, Lane 6
-NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L7 = 121  # NVLink Bandwidth Counter for Counter Set 0, Lane 7
-NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L8 = 122  # NVLink Bandwidth Counter for Counter Set 0, Lane 8
-NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L9 = 123  # NVLink Bandwidth Counter for Counter Set 0, Lane 9
-NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L10 = 124  # NVLink Bandwidth Counter for Counter Set 0, Lane 10
-NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L11 = 125  # NVLink Bandwidth Counter for Counter Set 0, Lane 11
+NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L6    = 120 # NVLink Bandwidth Counter for Counter Set 0, Lane 6
+NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L7    = 121 # NVLink Bandwidth Counter for Counter Set 0, Lane 7
+NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L8    = 122 # NVLink Bandwidth Counter for Counter Set 0, Lane 8
+NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L9    = 123 # NVLink Bandwidth Counter for Counter Set 0, Lane 9
+NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L10   = 124 # NVLink Bandwidth Counter for Counter Set 0, Lane 10
+NVML_FI_DEV_NVLINK_BANDWIDTH_C0_L11   = 125 # NVLink Bandwidth Counter for Counter Set 0, Lane 11
 
 # NvLink Bandwidth Counters
-NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L6 = 126  # NVLink Bandwidth Counter for Counter Set 1, Lane 6
-NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L7 = 127  # NVLink Bandwidth Counter for Counter Set 1, Lane 7
-NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L8 = 128  # NVLink Bandwidth Counter for Counter Set 1, Lane 8
-NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L9 = 129  # NVLink Bandwidth Counter for Counter Set 1, Lane 9
-NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L10 = 130  # NVLink Bandwidth Counter for Counter Set 1, Lane 10
-NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L11 = 131  # NVLink Bandwidth Counter for Counter Set 1, Lane 11
+NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L6    = 126 # NVLink Bandwidth Counter for Counter Set 1, Lane 6
+NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L7    = 127 # NVLink Bandwidth Counter for Counter Set 1, Lane 7
+NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L8    = 128 # NVLink Bandwidth Counter for Counter Set 1, Lane 8
+NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L9    = 129 # NVLink Bandwidth Counter for Counter Set 1, Lane 9
+NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L10   = 130 # NVLink Bandwidth Counter for Counter Set 1, Lane 10
+NVML_FI_DEV_NVLINK_BANDWIDTH_C1_L11   = 131 # NVLink Bandwidth Counter for Counter Set 1, Lane 11
 
 # NVLink Speed
-NVML_FI_DEV_NVLINK_SPEED_MBPS_L6 = 132
-NVML_FI_DEV_NVLINK_SPEED_MBPS_L7 = 133
-NVML_FI_DEV_NVLINK_SPEED_MBPS_L8 = 134
-NVML_FI_DEV_NVLINK_SPEED_MBPS_L9 = 135
-NVML_FI_DEV_NVLINK_SPEED_MBPS_L10 = 136
-NVML_FI_DEV_NVLINK_SPEED_MBPS_L11 = 137
+NVML_FI_DEV_NVLINK_SPEED_MBPS_L6     = 132
+NVML_FI_DEV_NVLINK_SPEED_MBPS_L7     = 133
+NVML_FI_DEV_NVLINK_SPEED_MBPS_L8     = 134
+NVML_FI_DEV_NVLINK_SPEED_MBPS_L9     = 135
+NVML_FI_DEV_NVLINK_SPEED_MBPS_L10    = 136
+NVML_FI_DEV_NVLINK_SPEED_MBPS_L11    = 137
 
 # NVLink Throughput Counters
-NVML_FI_DEV_NVLINK_THROUGHPUT_DATA_TX = 138  # NVLink TX Data throughput in KiB
-NVML_FI_DEV_NVLINK_THROUGHPUT_DATA_RX = 139  # NVLink RX Data throughput in KiB
-NVML_FI_DEV_NVLINK_THROUGHPUT_RAW_TX = 140  # NVLink TX Data + protocol overhead in KiB
-NVML_FI_DEV_NVLINK_THROUGHPUT_RAW_RX = 141  # NVLink RX Data + protocol overhead in KiB
+NVML_FI_DEV_NVLINK_THROUGHPUT_DATA_TX = 138 # NVLink TX Data throughput in KiB
+NVML_FI_DEV_NVLINK_THROUGHPUT_DATA_RX = 139 # NVLink RX Data throughput in KiB
+NVML_FI_DEV_NVLINK_THROUGHPUT_RAW_TX  = 140 # NVLink TX Data + protocol overhead in KiB
+NVML_FI_DEV_NVLINK_THROUGHPUT_RAW_RX  = 141 # NVLink RX Data + protocol overhead in KiB
 
 # Row Remapper
-NVML_FI_DEV_REMAPPED_COR = 142
-NVML_FI_DEV_REMAPPED_UNC = 143
-NVML_FI_DEV_REMAPPED_PENDING = 144
-NVML_FI_DEV_REMAPPED_FAILURE = 145
+NVML_FI_DEV_REMAPPED_COR        = 142
+NVML_FI_DEV_REMAPPED_UNC        = 143
+NVML_FI_DEV_REMAPPED_PENDING    = 144
+NVML_FI_DEV_REMAPPED_FAILURE    = 145
 
-# Remote device NVLink ID
+#Remote device NVLink ID
 NVML_FI_DEV_NVLINK_REMOTE_NVLINK_ID = 146
 
 # Number of NVLinks connected to NVSwitch
 NVML_FI_DEV_NVSWITCH_CONNECTED_LINK_COUNT = 147
 
 # NvLink ECC Data Error Counters
-NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L0 = 148  # < NVLink data ECC Error Counter for Link 0
-NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L1 = 149  # < NVLink data ECC Error Counter for Link 1
-NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L2 = 150  # < NVLink data ECC Error Counter for Link 2
-NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L3 = 151  # < NVLink data ECC Error Counter for Link 3
-NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L4 = 152  # < NVLink data ECC Error Counter for Link 4
-NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L5 = 153  # < NVLink data ECC Error Counter for Link 5
-NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L6 = 154  # < NVLink data ECC Error Counter for Link 6
-NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L7 = 155  # < NVLink data ECC Error Counter for Link 7
-NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L8 = 156  # < NVLink data ECC Error Counter for Link 8
-NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L9 = 157  # < NVLink data ECC Error Counter for Link 9
-NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L10 = 158  # < NVLink data ECC Error Counter for Link 10
-NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L11 = 159  # < NVLink data ECC Error Counter for Link 11
-NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_TOTAL = 160  # < NvLink data ECC Error Counter total for all Links
-
-NVML_FI_DEV_NVLINK_ERROR_DL_REPLAY = 161
-NVML_FI_DEV_NVLINK_ERROR_DL_RECOVERY = 162
-NVML_FI_DEV_NVLINK_ERROR_DL_CRC = 163
-NVML_FI_DEV_NVLINK_GET_SPEED = 164
-NVML_FI_DEV_NVLINK_GET_STATE = 165
-NVML_FI_DEV_NVLINK_GET_VERSION = 166
-
-NVML_FI_DEV_NVLINK_GET_POWER_STATE = 167
-NVML_FI_DEV_NVLINK_GET_POWER_THRESHOLD = 168
+NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L0    = 148 #< NVLink data ECC Error Counter for Link 0
+NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L1    = 149 #< NVLink data ECC Error Counter for Link 1
+NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L2    = 150 #< NVLink data ECC Error Counter for Link 2
+NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L3    = 151 #< NVLink data ECC Error Counter for Link 3
+NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L4    = 152 #< NVLink data ECC Error Counter for Link 4
+NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L5    = 153 #< NVLink data ECC Error Counter for Link 5
+NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L6    = 154 #< NVLink data ECC Error Counter for Link 6
+NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L7    = 155 #< NVLink data ECC Error Counter for Link 7
+NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L8    = 156 #< NVLink data ECC Error Counter for Link 8
+NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L9    = 157 #< NVLink data ECC Error Counter for Link 9
+NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L10   = 158 #< NVLink data ECC Error Counter for Link 10
+NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_L11   = 159 #< NVLink data ECC Error Counter for Link 11
+NVML_FI_DEV_NVLINK_ECC_DATA_ERROR_COUNT_TOTAL = 160 #< NvLink data ECC Error Counter total for all Links
+
+NVML_FI_DEV_NVLINK_ERROR_DL_REPLAY            = 161
+NVML_FI_DEV_NVLINK_ERROR_DL_RECOVERY          = 162
+NVML_FI_DEV_NVLINK_ERROR_DL_CRC               = 163
+NVML_FI_DEV_NVLINK_GET_SPEED                  = 164
+NVML_FI_DEV_NVLINK_GET_STATE                  = 165
+NVML_FI_DEV_NVLINK_GET_VERSION                = 166
+
+NVML_FI_DEV_NVLINK_GET_POWER_STATE            = 167
+NVML_FI_DEV_NVLINK_GET_POWER_THRESHOLD        = 168
+
+NVML_FI_DEV_PCIE_L0_TO_RECOVERY_COUNTER       = 169
+
+NVML_FI_DEV_C2C_LINK_COUNT                    = 170
+NVML_FI_DEV_C2C_LINK_GET_STATUS               = 171
+NVML_FI_DEV_C2C_LINK_GET_MAX_BW               = 172
+
+NVML_FI_DEV_PCIE_COUNT_CORRECTABLE_ERRORS     = 173
+NVML_FI_DEV_PCIE_COUNT_NAKS_RECEIVED          = 174
+NVML_FI_DEV_PCIE_COUNT_RECEIVER_ERROR         = 175
+NVML_FI_DEV_PCIE_COUNT_BAD_TLP                = 176
+NVML_FI_DEV_PCIE_COUNT_NAKS_SENT              = 177
+NVML_FI_DEV_PCIE_COUNT_BAD_DLLP               = 178
+NVML_FI_DEV_PCIE_COUNT_NON_FATAL_ERROR        = 179
+NVML_FI_DEV_PCIE_COUNT_FATAL_ERROR            = 180
+NVML_FI_DEV_PCIE_COUNT_UNSUPPORTED_REQ        = 181
+NVML_FI_DEV_PCIE_COUNT_LCRC_ERROR             = 182
+NVML_FI_DEV_PCIE_COUNT_LANE_ERROR             = 183
+
+NVML_FI_DEV_IS_RESETLESS_MIG_SUPPORTED        = 184
+
+NVML_FI_DEV_POWER_AVERAGE                     = 185
+NVML_FI_DEV_POWER_INSTANT                     = 186
+NVML_FI_DEV_POWER_MIN_LIMIT                   = 187
+NVML_FI_DEV_POWER_MAX_LIMIT                   = 188
+NVML_FI_DEV_POWER_DEFAULT_LIMIT               = 189
+NVML_FI_DEV_POWER_CURRENT_LIMIT               = 190
+NVML_FI_DEV_ENERGY                            = 191
+NVML_FI_DEV_POWER_REQUESTED_LIMIT             = 192
+
+NVML_FI_DEV_TEMPERATURE_SHUTDOWN_TLIMIT       = 193
+NVML_FI_DEV_TEMPERATURE_SLOWDOWN_TLIMIT       = 194
+NVML_FI_DEV_TEMPERATURE_MEM_MAX_TLIMIT        = 195
+NVML_FI_DEV_TEMPERATURE_GPU_MAX_TLIMIT        = 196
 
-NVML_FI_DEV_PCIE_L0_TO_RECOVERY_COUNTER = 169
+NVML_FI_MAX = 197 # One greater than the largest field ID defined above
 
-NVML_FI_MAX = 170  # One greater than the largest field ID defined above
 
 ## Enums needed for the method nvmlDeviceGetVirtualizationMode and nvmlDeviceSetVirtualizationMode
-NVML_GPU_VIRTUALIZATION_MODE_NONE = 0  # Represents Bare Metal GPU
+NVML_GPU_VIRTUALIZATION_MODE_NONE        = 0  # Represents Bare Metal GPU
 NVML_GPU_VIRTUALIZATION_MODE_PASSTHROUGH = 1  # Device is associated with GPU-Passthorugh
-NVML_GPU_VIRTUALIZATION_MODE_VGPU = 2  # Device is associated with vGPU inside virtual machine.
-NVML_GPU_VIRTUALIZATION_MODE_HOST_VGPU = 3  # Device is associated with VGX hypervisor in vGPU mode
-NVML_GPU_VIRTUALIZATION_MODE_HOST_VSGA = 4  # Device is associated with VGX hypervisor in vSGA mode
+NVML_GPU_VIRTUALIZATION_MODE_VGPU        = 2  # Device is associated with vGPU inside virtual machine.
+NVML_GPU_VIRTUALIZATION_MODE_HOST_VGPU   = 3  # Device is associated with VGX hypervisor in vGPU mode
+NVML_GPU_VIRTUALIZATION_MODE_HOST_VSGA   = 4  # Device is associated with VGX hypervisor in vSGA mode
 
 ## Lib loading ##
 nvmlLib = None
 libLoadLock = threading.Lock()
-_nvmlLib_refcount = 0  # Incremented on each nvmlInit and decremented on nvmlShutdown
+_nvmlLib_refcount = 0 # Incremented on each nvmlInit and decremented on nvmlShutdown
 
 ## vGPU Management
-_nvmlVgpuTypeId_t = c_uint
+_nvmlVgpuTypeId_t   = c_uint
 _nvmlVgpuInstance_t = c_uint
 
 _nvmlVgpuVmIdType_t = c_uint
-NVML_VGPU_VM_ID_DOMAIN_ID = 0
-NVML_VGPU_VM_ID_UUID = 1
+NVML_VGPU_VM_ID_DOMAIN_ID    = 0
+NVML_VGPU_VM_ID_UUID         = 1
 
 _nvmlGridLicenseFeatureCode_t = c_uint
-NVML_GRID_LICENSE_FEATURE_CODE_UNKNOWN = 0
-NVML_GRID_LICENSE_FEATURE_CODE_VGPU = 1
-NVML_GRID_LICENSE_FEATURE_CODE_NVIDIA_RTX = 2
-NVML_GRID_LICENSE_FEATURE_CODE_VWORKSTATION = 2  # deprecated, use NVML_GRID_LICENSE_FEATURE_CODE_NVIDIA_RTX.
-NVML_GRID_LICENSE_FEATURE_CODE_GAMING = 3
-NVML_GRID_LICENSE_FEATURE_CODE_COMPUTE = 4
+NVML_GRID_LICENSE_FEATURE_CODE_UNKNOWN      = 0
+NVML_GRID_LICENSE_FEATURE_CODE_VGPU         = 1
+NVML_GRID_LICENSE_FEATURE_CODE_NVIDIA_RTX   = 2
+NVML_GRID_LICENSE_FEATURE_CODE_VWORKSTATION = 2 # deprecated, use NVML_GRID_LICENSE_FEATURE_CODE_NVIDIA_RTX.
+NVML_GRID_LICENSE_FEATURE_CODE_GAMING       = 3
+NVML_GRID_LICENSE_FEATURE_CODE_COMPUTE      = 4
 
 _nvmlGridLicenseExpiryStatus_t = c_uint8
-NVML_GRID_LICENSE_EXPIRY_NOT_AVAILABLE = 0  # Expiry information not available
-NVML_GRID_LICENSE_EXPIRY_INVALID = 1  # Invalid expiry or error fetching expiry
-NVML_GRID_LICENSE_EXPIRY_VALID = 2  # Valid expiry
-NVML_GRID_LICENSE_EXPIRY_NOT_APPLICABLE = 3  # Expiry not applicable
-NVML_GRID_LICENSE_EXPIRY_PERMANENT = 4  # Permanent expiry
+NVML_GRID_LICENSE_EXPIRY_NOT_AVAILABLE    = 0,   # Expiry information not available
+NVML_GRID_LICENSE_EXPIRY_INVALID          = 1,   # Invalid expiry or error fetching expiry
+NVML_GRID_LICENSE_EXPIRY_VALID            = 2,   # Valid expiry
+NVML_GRID_LICENSE_EXPIRY_NOT_APPLICABLE   = 3,   # Expiry not applicable
+NVML_GRID_LICENSE_EXPIRY_PERMANENT        = 4,   # Permanent expiry
 
 _nvmlVgpuCapability_t = c_uint
-NVML_VGPU_CAP_NVLINK_P2P = 0  # vGPU P2P over NVLink is supported
-NVML_VGPU_CAP_GPUDIRECT = 1  # GPUDirect capability is supported
-NVML_VGPU_CAP_MULTI_VGPU_EXCLUSIVE = 2  # vGPU profile cannot be mixed with other vGPU profiles in same VM
-NVML_VGPU_CAP_EXCLUSIVE_TYPE = 3  # vGPU profile cannot run on a GPU alongside other profiles of different type
-NVML_VGPU_CAP_EXCLUSIVE_SIZE = 4  # vGPU profile cannot run on a GPU alongside other profiles of different size
-NVML_VGPU_CAP_COUNT = 5
+NVML_VGPU_CAP_NVLINK_P2P                    = 0  # vGPU P2P over NVLink is supported
+NVML_VGPU_CAP_GPUDIRECT                     = 1  # GPUDirect capability is supported
+NVML_VGPU_CAP_MULTI_VGPU_EXCLUSIVE          = 2  # vGPU profile cannot be mixed with other vGPU profiles in same VM
+NVML_VGPU_CAP_EXCLUSIVE_TYPE                = 3  # vGPU profile cannot run on a GPU alongside other profiles of different type
+NVML_VGPU_CAP_EXCLUSIVE_SIZE                = 4  # vGPU profile cannot run on a GPU alongside other profiles of different size
+NVML_VGPU_CAP_COUNT                         = 5
 
 _nvmlVgpuDriverCapability_t = c_uint
-NVML_VGPU_DRIVER_CAP_HETEROGENEOUS_MULTI_VGPU = 0  # Supports mixing of different vGPU profiles within one guest VM
-NVML_VGPU_DRIVER_CAP_COUNT = 1
+NVML_VGPU_DRIVER_CAP_HETEROGENEOUS_MULTI_VGPU          = 0  # Supports mixing of different vGPU profiles within one guest VM
+NVML_VGPU_DRIVER_CAP_COUNT                             = 1
 
 _nvmlDeviceVgpuCapability_t = c_uint
-NVML_DEVICE_VGPU_CAP_FRACTIONAL_MULTI_VGPU = 0  # Fractional vGPU profiles on this GPU can be used in multi-vGPU configurations
-NVML_DEVICE_VGPU_CAP_HETEROGENEOUS_TIMESLICE_PROFILES = 1  # Supports concurrent execution of timesliced vGPU profiles of differing types
-NVML_DEVICE_VGPU_CAP_HETEROGENEOUS_TIMESLICE_SIZES = 2  # Supports concurrent execution of timesliced vGPU profiles of differing framebuffer sizes
-NVML_DEVICE_VGPU_CAP_READ_DEVICE_BUFFER_BW = 3  # GPU device's read_device_buffer expected bandwidth capacity in megabytes per second
-NVML_DEVICE_VGPU_CAP_WRITE_DEVICE_BUFFER_BW = 4  # GPU device's write_device_buffer expected bandwidth capacity in megabytes per second
-NVML_DEVICE_VGPU_CAP_COUNT = 5
+NVML_DEVICE_VGPU_CAP_FRACTIONAL_MULTI_VGPU             = 0  # Fractional vGPU profiles on this GPU can be used in multi-vGPU configurations
+NVML_DEVICE_VGPU_CAP_HETEROGENEOUS_TIMESLICE_PROFILES  = 1  # Supports concurrent execution of timesliced vGPU profiles of differing types
+NVML_DEVICE_VGPU_CAP_HETEROGENEOUS_TIMESLICE_SIZES     = 2  # Supports concurrent execution of timesliced vGPU profiles of differing framebuffer sizes
+NVML_DEVICE_VGPU_CAP_READ_DEVICE_BUFFER_BW             = 3  # GPU device's read_device_buffer expected bandwidth capacity in megabytes per second
+NVML_DEVICE_VGPU_CAP_WRITE_DEVICE_BUFFER_BW            = 4  # GPU device's write_device_buffer expected bandwidth capacity in megabytes per second
+NVML_DEVICE_VGPU_CAP_COUNT                             = 5
 
 _nvmlVgpuGuestInfoState_t = c_uint
 NVML_VGPU_INSTANCE_GUEST_INFO_STATE_UNINITIALIZED = 0
-NVML_VGPU_INSTANCE_GUEST_INFO_STATE_INITIALIZED = 1
+NVML_VGPU_INSTANCE_GUEST_INFO_STATE_INITIALIZED   = 1
 
 _nvmlVgpuVmCompatibility_t = c_uint
-NVML_VGPU_VM_COMPATIBILITY_NONE = 0x0
-NVML_VGPU_VM_COMPATIBILITY_COLD = 0x1
-NVML_VGPU_VM_COMPATIBILITY_HIBERNATE = 0x2
-NVML_VGPU_VM_COMPATIBILITY_SLEEP = 0x4
-NVML_VGPU_VM_COMPATIBILITY_LIVE = 0x8
+NVML_VGPU_VM_COMPATIBILITY_NONE         = 0x0
+NVML_VGPU_VM_COMPATIBILITY_COLD         = 0x1
+NVML_VGPU_VM_COMPATIBILITY_HIBERNATE    = 0x2
+NVML_VGPU_VM_COMPATIBILITY_SLEEP        = 0x4
+NVML_VGPU_VM_COMPATIBILITY_LIVE         = 0x8
 
 _nvmlVgpuPgpuCompatibilityLimitCode_t = c_uint
-NVML_VGPU_COMPATIBILITY_LIMIT_NONE = 0x0
-NVML_VGPU_COMPATIBILITY_LIMIT_HOST_DRIVER = 0x1
-NVML_VGPU_COMPATIBILITY_LIMIT_GUEST_DRIVER = 0x2
-NVML_VGPU_COMPATIBILITY_LIMIT_GPU = 0x4
-NVML_VGPU_COMPATIBILITY_LIMIT_OTHER = 0x80000000
+NVML_VGPU_COMPATIBILITY_LIMIT_NONE          = 0x0
+NVML_VGPU_COMPATIBILITY_LIMIT_HOST_DRIVER   = 0x1
+NVML_VGPU_COMPATIBILITY_LIMIT_GUEST_DRIVER  = 0x2
+NVML_VGPU_COMPATIBILITY_LIMIT_GPU           = 0x4
+NVML_VGPU_COMPATIBILITY_LIMIT_OTHER         = 0x80000000
 
 _nvmlHostVgpuMode_t = c_uint
-NVML_HOST_VGPU_MODE_NON_SRIOV = 0
-NVML_HOST_VGPU_MODE_SRIOV = 1
+NVML_HOST_VGPU_MODE_NON_SRIOV   = 0
+NVML_HOST_VGPU_MODE_SRIOV       = 1
+
+_nvmlConfComputeGpusReadyState_t = c_uint
+NVML_CC_ACCEPTING_CLIENT_REQUESTS_FALSE = 0
+NVML_CC_ACCEPTING_CLIENT_REQUESTS_TRUE = 1
+
+_nvmlConfComputeGpuCaps_t = c_uint
+NVML_CC_SYSTEM_GPUS_CC_NOT_CAPABLE = 0
+NVML_CC_SYSTEM_GPUS_CC_CAPABLE = 1
+
+_nvmlConfComputeCpuCaps_t = c_uint
+NVML_CC_SYSTEM_CPU_CAPS_NONE = 0
+NVML_CC_SYSTEM_CPU_CAPS_AMD_SEV = 1
+NVML_CC_SYSTEM_CPU_CAPS_INTEL_TDX = 2
+
+_nvmlConfComputeDevToolsMode_t = c_uint
+NVML_CC_SYSTEM_DEVTOOLS_MODE_OFF = 0
+NVML_CC_SYSTEM_DEVTOOLS_MODE_ON = 1
+ 
+NVML_CC_SYSTEM_ENVIRONMENT_UNAVAILABLE = 0
+NVML_CC_SYSTEM_ENVIRONMENT_SIM = 1
+NVML_CC_SYSTEM_ENVIRONMENT_PROD = 2
+ 
+_nvmlConfComputeCcFeature_t = c_uint
+NVML_CC_SYSTEM_FEATURE_DISABLED = 0
+NVML_CC_SYSTEM_FEATURE_ENABLED = 1
 
 # GSP firmware
 NVML_GSP_FIRMWARE_VERSION_BUF_SIZE = 0x40
 
-
 ## Error Checking ##
 class NVMLError(Exception):
     _valClassMapping = dict()
     # List of currently known error codes
     _errcode_to_string = {
-        NVML_ERROR_UNINITIALIZED: "Uninitialized",
-        NVML_ERROR_INVALID_ARGUMENT: "Invalid Argument",
-        NVML_ERROR_NOT_SUPPORTED: "Not Supported",
-        NVML_ERROR_NO_PERMISSION: "Insufficient Permissions",
+        NVML_ERROR_UNINITIALIZED:       "Uninitialized",
+        NVML_ERROR_INVALID_ARGUMENT:    "Invalid Argument",
+        NVML_ERROR_NOT_SUPPORTED:       "Not Supported",
+        NVML_ERROR_NO_PERMISSION:       "Insufficient Permissions",
         NVML_ERROR_ALREADY_INITIALIZED: "Already Initialized",
-        NVML_ERROR_NOT_FOUND: "Not Found",
-        NVML_ERROR_INSUFFICIENT_SIZE: "Insufficient Size",
-        NVML_ERROR_INSUFFICIENT_POWER: "Insufficient External Power",
-        NVML_ERROR_DRIVER_NOT_LOADED: "Driver Not Loaded",
-        NVML_ERROR_TIMEOUT: "Timeout",
-        NVML_ERROR_IRQ_ISSUE: "Interrupt Request Issue",
-        NVML_ERROR_LIBRARY_NOT_FOUND: "NVML Shared Library Not Found",
-        NVML_ERROR_FUNCTION_NOT_FOUND: "Function Not Found",
-        NVML_ERROR_CORRUPTED_INFOROM: "Corrupted infoROM",
-        NVML_ERROR_GPU_IS_LOST: "GPU is lost",
-        NVML_ERROR_RESET_REQUIRED: "GPU requires restart",
-        NVML_ERROR_OPERATING_SYSTEM: "The operating system has blocked the request.",
+        NVML_ERROR_NOT_FOUND:           "Not Found",
+        NVML_ERROR_INSUFFICIENT_SIZE:   "Insufficient Size",
+        NVML_ERROR_INSUFFICIENT_POWER:  "Insufficient External Power",
+        NVML_ERROR_DRIVER_NOT_LOADED:   "Driver Not Loaded",
+        NVML_ERROR_TIMEOUT:             "Timeout",
+        NVML_ERROR_IRQ_ISSUE:           "Interrupt Request Issue",
+        NVML_ERROR_LIBRARY_NOT_FOUND:   "NVML Shared Library Not Found",
+        NVML_ERROR_FUNCTION_NOT_FOUND:  "Function Not Found",
+        NVML_ERROR_CORRUPTED_INFOROM:   "Corrupted infoROM",
+        NVML_ERROR_GPU_IS_LOST:         "GPU is lost",
+        NVML_ERROR_RESET_REQUIRED:      "GPU requires restart",
+        NVML_ERROR_OPERATING_SYSTEM:    "The operating system has blocked the request.",
         NVML_ERROR_LIB_RM_VERSION_MISMATCH: "RM has detected an NVML/RM version mismatch.",
-        NVML_ERROR_MEMORY: "Insufficient Memory",
-        NVML_ERROR_UNKNOWN: "Unknown Error",
-    }
-
+        NVML_ERROR_MEMORY:              "Insufficient Memory",
+        NVML_ERROR_UNKNOWN:             "Unknown Error",
+        }
     def __new__(typ, value):
         '''
         Maps value to a proper subclass of NVMLError.
         See _extractNVMLErrorsAsClasses function for more details
         '''
         if typ == NVMLError:
             typ = NVMLError._valClassMapping.get(value, typ)
         obj = Exception.__new__(typ)
         obj.value = value
         return obj
-
     def __str__(self):
         try:
             if self.value not in NVMLError._errcode_to_string:
                 NVMLError._errcode_to_string[self.value] = str(nvmlErrorString(self.value))
             return NVMLError._errcode_to_string[self.value]
         except NVMLError:
             return "NVML Error with code %d" % self.value
-
     def __eq__(self, other):
         return self.value == other.value
 
-
 def nvmlExceptionClass(nvmlErrorCode):
     if nvmlErrorCode not in NVMLError._valClassMapping:
         raise ValueError('nvmlErrorCode %s is not valid' % nvmlErrorCode)
     return NVMLError._valClassMapping[nvmlErrorCode]
 
-
 def _extractNVMLErrorsAsClasses():
     '''
     Generates a hierarchy of classes on top of NVMLError class.
 
     Each NVML Error gets a new NVMLError subclass. This way try,except blocks can filter appropriate
     exceptions more easily.
 
@@ -820,107 +879,90 @@
     '''
     this_module = sys.modules[__name__]
     nvmlErrorsNames = [x for x in dir(this_module) if x.startswith("NVML_ERROR_")]
     for err_name in nvmlErrorsNames:
         # e.g. Turn NVML_ERROR_ALREADY_INITIALIZED into NVMLError_AlreadyInitialized
         class_name = "NVMLError_" + string.capwords(err_name.replace("NVML_ERROR_", ""), "_").replace("_", "")
         err_val = getattr(this_module, err_name)
-
         def gen_new(val):
             def new(typ):
                 obj = NVMLError.__new__(typ, val)
                 return obj
-
             return new
-
         new_error_class = type(class_name, (NVMLError,), {'__new__': gen_new(err_val)})
         new_error_class.__module__ = __name__
         setattr(this_module, class_name, new_error_class)
         NVMLError._valClassMapping[err_val] = new_error_class
-
-
 _extractNVMLErrorsAsClasses()
 
-
 def _nvmlCheckReturn(ret):
     if (ret != NVML_SUCCESS):
         raise NVMLError(ret)
     return ret
 
-
 ## Function access ##
-_nvmlGetFunctionPointer_cache = dict()  # function pointers are cached to prevent unnecessary libLoadLock locking
-
-
+_nvmlGetFunctionPointer_cache = dict() # function pointers are cached to prevent unnecessary libLoadLock locking
 def _nvmlGetFunctionPointer(name):
     global nvmlLib
 
     if name in _nvmlGetFunctionPointer_cache:
         return _nvmlGetFunctionPointer_cache[name]
 
     libLoadLock.acquire()
     try:
         # ensure library was loaded
-        if nvmlLib is None:
+        if (nvmlLib == None):
             raise NVMLError(NVML_ERROR_UNINITIALIZED)
         try:
             _nvmlGetFunctionPointer_cache[name] = getattr(nvmlLib, name)
             return _nvmlGetFunctionPointer_cache[name]
         except AttributeError:
             raise NVMLError(NVML_ERROR_FUNCTION_NOT_FOUND)
     finally:
         # lock is always freed
         libLoadLock.release()
 
-
 ## Alternative object
 # Allows the object to be printed
 # Allows mismatched types to be assigned
 #  - like None when the Structure variant requires c_uint
 class nvmlFriendlyObject(object):
     def __init__(self, dictionary):
         for x in dictionary:
             setattr(self, x, dictionary[x])
-
     def __str__(self):
         return self.__dict__.__str__()
 
-
 def nvmlStructToFriendlyObject(struct):
     d = {}
     for x in struct._fields_:
         key = x[0]
         value = getattr(struct, key)
         # only need to convert from bytes if bytes, no need to check python version.
         d[key] = value.decode() if isinstance(value, bytes) else value
     obj = nvmlFriendlyObject(d)
     return obj
 
-
 # pack the object so it can be passed to the NVML library
 def nvmlFriendlyObjectToStruct(obj, model):
     for x in model._fields_:
         key = x[0]
         value = obj.__dict__[key]
         # any c_char_p in python3 needs to be bytes, default encoding works fine.
         if sys.version_info >= (3,):
             setattr(model, key, value.encode())
         else:
             setattr(model, key, value)
     return model
 
-
 ## Unit structures
 class struct_c_nvmlUnit_t(Structure):
-    pass  # opaque handle
-
-
+    pass # opaque handle
 c_nvmlUnit_t = POINTER(struct_c_nvmlUnit_t)
 
-
 class _PrintableStructure(Structure):
     """
     Abstract class that produces nicer __str__ output than ctypes.Structure.
     e.g. instead of:
       >>> print str(obj)
       <class_name object at 0x7fdf82fef9e0>
     this class will print
@@ -933,27 +975,26 @@
     Default fomratting string for all fields can be set with key "<default>" like:
       _fmt_ = {"<default>" : "%d MHz"} # e.g all values are numbers in MHz.
     If not set it's assumed to be just "%s"
 
     Exact format of returned str from this class is subject to change in the future.
     """
     _fmt_ = {}
-
     def __str__(self):
         result = []
         for x in self._fields_:
             key = x[0]
             value = getattr(self, key)
             fmt = "%s"
             if key in self._fmt_:
                 fmt = self._fmt_[key]
             elif "<default>" in self._fmt_:
                 fmt = self._fmt_["<default>"]
             result.append(("%s: " + fmt) % (key, value))
-        return self.__class__.__name__ + "(" + ", ".join(result) + ")"
+        return self.__class__.__name__ + "(" +  ", ".join(result) + ")"
 
     def __getattribute__(self, name):
         res = super(_PrintableStructure, self).__getattribute__(name)
         # need to convert bytes to unicode for python3 don't need to for python2
         # Python 2 strings are of both str and bytes
         # Python 3 strings are not of type bytes
         # ctypes should convert everything to the correct values otherwise
@@ -966,62 +1007,53 @@
     def __setattr__(self, name, value):
         if isinstance(value, str):
             # encoding a python2 string returns the same value, since python2 strings are bytes already
             # bytes passed in python3 will be ignored.
             value = value.encode()
         super(_PrintableStructure, self).__setattr__(name, value)
 
-
 class c_nvmlUnitInfo_t(_PrintableStructure):
     _fields_ = [
         ('name', c_char * 96),
         ('id', c_char * 96),
         ('serial', c_char * 96),
         ('firmwareVersion', c_char * 96),
     ]
 
-
 class c_nvmlLedState_t(_PrintableStructure):
     _fields_ = [
         ('cause', c_char * 256),
         ('color', _nvmlLedColor_t),
     ]
 
-
 class c_nvmlPSUInfo_t(_PrintableStructure):
     _fields_ = [
         ('state', c_char * 256),
         ('current', c_uint),
         ('voltage', c_uint),
         ('power', c_uint),
     ]
 
-
 class c_nvmlUnitFanInfo_t(_PrintableStructure):
     _fields_ = [
         ('speed', c_uint),
         ('state', _nvmlFanState_t),
     ]
 
-
 class c_nvmlUnitFanSpeeds_t(_PrintableStructure):
     _fields_ = [
         ('fans', c_nvmlUnitFanInfo_t * 24),
         ('count', c_uint)
     ]
 
-
 ## Device structures
 class struct_c_nvmlDevice_t(Structure):
-    pass  # opaque handle
-
-
+    pass # opaque handle
 c_nvmlDevice_t = POINTER(struct_c_nvmlDevice_t)
 
-
 # Legacy pciInfo used for _v1 and _v2
 class nvmlPciInfo_v2_t(_PrintableStructure):
     _fields_ = [
         ('busId', c_char * NVML_DEVICE_PCI_BUS_ID_BUFFER_V2_SIZE),
         ('domain', c_uint),
         ('bus', c_uint),
         ('device', c_uint),
@@ -1031,21 +1063,20 @@
         ('pciSubSystemId', c_uint),
         ('reserved0', c_uint),
         ('reserved1', c_uint),
         ('reserved2', c_uint),
         ('reserved3', c_uint),
     ]
     _fmt_ = {
-        'domain': "0x%04X",
-        'bus': "0x%02X",
-        'device': "0x%02X",
-        'pciDeviceId': "0x%08X",
-        'pciSubSystemId': "0x%08X",
-    }
-
+            'domain'         : "0x%04X",
+            'bus'            : "0x%02X",
+            'device'         : "0x%02X",
+            'pciDeviceId'    : "0x%08X",
+            'pciSubSystemId' : "0x%08X",
+            }
 
 class nvmlPciInfo_t(_PrintableStructure):
     _fields_ = [
         # Moved to the new busId location below
         ('busIdLegacy', c_char * NVML_DEVICE_PCI_BUS_ID_BUFFER_V2_SIZE),
         ('domain', c_uint),
         ('bus', c_uint),
@@ -1055,543 +1086,559 @@
         # Added in 2.285
         ('pciSubSystemId', c_uint),
         # New busId replaced the long deprecated and reserved fields with a
         # field of the same size in 9.0
         ('busId', c_char * NVML_DEVICE_PCI_BUS_ID_BUFFER_SIZE),
     ]
     _fmt_ = {
-        'domain': "0x%08X",
-        'bus': "0x%02X",
-        'device': "0x%02X",
-        'pciDeviceId': "0x%08X",
-        'pciSubSystemId': "0x%08X",
-    }
-
+            'domain'         : "0x%08X",
+            'bus'            : "0x%02X",
+            'device'         : "0x%02X",
+            'pciDeviceId'    : "0x%08X",
+            'pciSubSystemId' : "0x%08X",
+            }
 
 class c_nvmlExcludedDeviceInfo_t(_PrintableStructure):
     _fields_ = [
         ('pci', nvmlPciInfo_t),
         ('uuid', c_char * NVML_DEVICE_UUID_BUFFER_SIZE)
     ]
 
-
 class nvmlNvLinkUtilizationControl_t(_PrintableStructure):
     _fields_ = [
         ('units', _nvmlNvLinkUtilizationCountUnits_t),
         ('pktfilter', _nvmlNvLinkUtilizationCountPktTypes_t),
     ]
 
-
 class c_nvmlMemory_t(_PrintableStructure):
     _fields_ = [
         ('total', c_ulonglong),
         ('free', c_ulonglong),
         ('used', c_ulonglong),
     ]
     _fmt_ = {'<default>': "%d B"}
 
-
 class c_nvmlMemory_v2_t(_PrintableStructure):
     _fields_ = [
         ('version', c_uint),
         ('total', c_ulonglong),
         ('reserved', c_ulonglong),
         ('free', c_ulonglong),
         ('used', c_ulonglong),
     ]
     _fmt_ = {'<default>': "%d B"}
 
-
 nvmlMemory_v2 = 0x02000028
 
-
 class c_nvmlBAR1Memory_t(_PrintableStructure):
     _fields_ = [
         ('bar1Total', c_ulonglong),
         ('bar1Free', c_ulonglong),
         ('bar1Used', c_ulonglong),
     ]
     _fmt_ = {'<default>': "%d B"}
 
-
 class nvmlClkMonFaultInfo_t(Structure):
     _fields_ = [("clkApiDomain", c_uint),
                 ("clkDomainFaultMask", c_uint)
-                ]
-
+    ]
 
 class nvmlClkMonStatus_t(Structure):
     _fields_ = [("bGlobalStatus", c_uint),
                 ("clkMonListSize", c_uint),
                 ("clkMonList", nvmlClkMonFaultInfo_t)
-                ]
-
+    ]
 
 # On Windows with the WDDM driver, usedGpuMemory is reported as None
 # Code that processes this structure should check for None, I.E.
 #
 # if (info.usedGpuMemory == None):
 #     # TODO handle the error
 #     pass
 # else:
 #    print("Using %d MiB of memory" % (info.usedGpuMemory / 1024 / 1024))
 # endif
 #
 # See NVML documentation for more information
-class c_nvmlProcessInfo_t(_PrintableStructure):
+class c_nvmlProcessInfo_v2_t(_PrintableStructure):
+    _fields_ = [
+        ('pid', c_uint),
+        ('usedGpuMemory', c_ulonglong),
+        ('gpuInstanceId', c_uint),
+        ('computeInstanceId', c_uint),
+    ]
+    _fmt_ = {'usedGpuMemory': "%d B"}
+
+c_nvmlProcessInfo_t = c_nvmlProcessInfo_v2_t
+
+_nvmlProcessMode_t = c_uint
+NVML_PROCESS_MODE_COMPUTE  = 0
+NVML_PROCESS_MODE_GRAPHICS = 1
+NVML_PROCESS_MODE_MPS      = 2
+
+class c_nvmlProcessDetail_v1_t(Structure):
     _fields_ = [
         ('pid', c_uint),
         ('usedGpuMemory', c_ulonglong),
         ('gpuInstanceId', c_uint),
         ('computeInstanceId', c_uint),
+        ('usedGpuCcProtectedMemory', c_ulonglong),
     ]
-    _fmt_ = {'usedGpuMemory': "%d B",
-             }
 
+class c_nvmlProcessDetailList_v1_t(_PrintableStructure):
+    _fields_ = [
+        ('version', c_uint),
+        ('mode', _nvmlProcessMode_t),
+        ('numProcArrayEntries', c_uint),
+        ('procArray', POINTER(c_nvmlProcessDetail_v1_t)),
+    ]
+    _fmt_ = {'numProcArrayEntries': "%d B"}
+
+c_nvmlProcessDetailList_t = c_nvmlProcessDetailList_v1_t
+
+nvmlProcessDetailList_v1 = 0x1000018
 
 class c_nvmlBridgeChipInfo_t(_PrintableStructure):
     _fields_ = [
         ('type', _nvmlBridgeChipType_t),
         ('fwVersion', c_uint),
     ]
 
-
 class c_nvmlBridgeChipHierarchy_t(_PrintableStructure):
     _fields_ = [
         ('bridgeCount', c_uint),
         ('bridgeChipInfo', c_nvmlBridgeChipInfo_t * 128),
     ]
 
-
 class c_nvmlEccErrorCounts_t(_PrintableStructure):
     _fields_ = [
         ('l1Cache', c_ulonglong),
         ('l2Cache', c_ulonglong),
         ('deviceMemory', c_ulonglong),
         ('registerFile', c_ulonglong),
     ]
 
-
 class c_nvmlUtilization_t(_PrintableStructure):
     _fields_ = [
         ('gpu', c_uint),
         ('memory', c_uint),
     ]
     _fmt_ = {'<default>': "%d %%"}
 
-
 # Added in 2.285
 class c_nvmlHwbcEntry_t(_PrintableStructure):
     _fields_ = [
         ('hwbcId', c_uint),
         ('firmwareVersion', c_char * 32),
     ]
 
-
 class c_nvmlValue_t(Union):
     _fields_ = [
         ('dVal', c_double),
         ('uiVal', c_uint),
         ('ulVal', c_ulong),
         ('ullVal', c_ulonglong),
         ('sllVal', c_longlong),
+        ('siVal', c_int),
     ]
 
-
 class c_nvmlSample_t(_PrintableStructure):
     _fields_ = [
         ('timeStamp', c_ulonglong),
         ('sampleValue', c_nvmlValue_t),
     ]
 
-
 class c_nvmlViolationTime_t(_PrintableStructure):
     _fields_ = [
         ('referenceTime', c_ulonglong),
         ('violationTime', c_ulonglong),
     ]
 
-
 class c_nvmlFieldValue_t(_PrintableStructure):
     _fields_ = [
         ('fieldId', c_uint32),
         ('scopeId', c_uint32),
         ('timestamp', c_int64),
         ('latencyUsec', c_int64),
         ('valueType', _nvmlValueType_t),
         ('nvmlReturn', _nvmlReturn_t),
         ('value', c_nvmlValue_t)
     ]
 
-
 class c_nvmlVgpuInstanceUtilizationSample_t(_PrintableStructure):
     _fields_ = [
         ('vgpuInstance', _nvmlVgpuInstance_t),
         ('timeStamp', c_ulonglong),
         ('smUtil', c_nvmlValue_t),
         ('memUtil', c_nvmlValue_t),
         ('encUtil', c_nvmlValue_t),
         ('decUtil', c_nvmlValue_t),
     ]
 
-
 class c_nvmlVgpuProcessUtilizationSample_t(_PrintableStructure):
     _fields_ = [
         ('vgpuInstance', _nvmlVgpuInstance_t),
         ('pid', c_uint),
         ('processName', c_char * NVML_VGPU_NAME_BUFFER_SIZE),
         ('timeStamp', c_ulonglong),
         ('smUtil', c_uint),
         ('memUtil', c_uint),
         ('encUtil', c_uint),
         ('decUtil', c_uint),
     ]
 
-
 class c_nvmlVgpuLicenseExpiry_t(_PrintableStructure):
     _fields_ = [
-        ('year', c_uint32),
-        ('month', c_uint16),
-        ('day', c_uint16),
-        ('hour', c_uint16),
-        ('min', c_uint16),
-        ('sec', c_uint16),
-        ('status', c_uint8),
+        ('year',    c_uint32),
+        ('month',   c_uint16),
+        ('day',     c_uint16),
+        ('hour',    c_uint16),
+        ('min',     c_uint16),
+        ('sec',     c_uint16),
+        ('status',  c_uint8),
     ]
 
-
-NVML_GRID_LICENSE_STATE_UNKNOWN = 0
-NVML_GRID_LICENSE_STATE_UNINITIALIZED = 1
+NVML_GRID_LICENSE_STATE_UNKNOWN                 = 0
+NVML_GRID_LICENSE_STATE_UNINITIALIZED           = 1
 NVML_GRID_LICENSE_STATE_UNLICENSED_UNRESTRICTED = 2
-NVML_GRID_LICENSE_STATE_UNLICENSED_RESTRICTED = 3
-NVML_GRID_LICENSE_STATE_UNLICENSED = 4
-NVML_GRID_LICENSE_STATE_LICENSED = 5
-
+NVML_GRID_LICENSE_STATE_UNLICENSED_RESTRICTED   = 3
+NVML_GRID_LICENSE_STATE_UNLICENSED              = 4
+NVML_GRID_LICENSE_STATE_LICENSED                = 5
 
 class c_nvmlVgpuLicenseInfo_t(_PrintableStructure):
     _fields_ = [
-        ('isLicensed', c_uint8),
-        ('licenseExpiry', c_nvmlVgpuLicenseExpiry_t),
-        ('currentState', c_uint),
+        ('isLicensed',      c_uint8),
+        ('licenseExpiry',   c_nvmlVgpuLicenseExpiry_t),
+        ('currentState',    c_uint),
     ]
 
-
 class c_nvmlEncoderSession_t(_PrintableStructure):
     _fields_ = [
         ('sessionId', c_uint),
         ('pid', c_uint),
         ('vgpuInstance', _nvmlVgpuInstance_t),
         ('codecType', c_uint),
         ('hResolution', c_uint),
         ('vResolution', c_uint),
         ('averageFps', c_uint),
         ('encodeLatency', c_uint),
     ]
 
-
 class c_nvmlProcessUtilizationSample_t(_PrintableStructure):
     _fields_ = [
         ('pid', c_uint),
         ('timeStamp', c_ulonglong),
         ('smUtil', c_uint),
         ('memUtil', c_uint),
         ('encUtil', c_uint),
         ('decUtil', c_uint),
     ]
 
-
 class c_nvmlGridLicenseExpiry_t(_PrintableStructure):
     _fields_ = [
-        ('year', c_uint32),
-        ('month', c_uint16),
-        ('day', c_uint16),
-        ('hour', c_uint16),
-        ('min', c_uint16),
-        ('sec', c_uint16),
-        ('status', c_uint8),
+        ('year',    c_uint32),
+        ('month',   c_uint16),
+        ('day',     c_uint16),
+        ('hour',    c_uint16),
+        ('min',     c_uint16),
+        ('sec',     c_uint16),
+        ('status',  c_uint8),
     ]
 
-
 class c_nvmlGridLicensableFeature_v4_t(_PrintableStructure):
     _fields_ = [
-        ('featureCode', _nvmlGridLicenseFeatureCode_t),
-        ('featureState', c_uint),
-        ('licenseInfo', c_char * NVML_GRID_LICENSE_BUFFER_SIZE),
-        ('productName', c_char * NVML_GRID_LICENSE_BUFFER_SIZE),
+        ('featureCode',    _nvmlGridLicenseFeatureCode_t),
+        ('featureState',   c_uint),
+        ('licenseInfo',    c_char * NVML_GRID_LICENSE_BUFFER_SIZE),
+        ('productName',    c_char * NVML_GRID_LICENSE_BUFFER_SIZE),
         ('featureEnabled', c_uint),
-        ('licenseExpiry', c_nvmlGridLicenseExpiry_t),
+        ('licenseExpiry',  c_nvmlGridLicenseExpiry_t),
     ]
 
-
 class c_nvmlGridLicensableFeatures_v4_t(_PrintableStructure):
     _fields_ = [
-        ('isGridLicenseSupported', c_int),
+        ('isGridLicenseSupported',  c_int),
         ('licensableFeaturesCount', c_uint),
-        ('gridLicensableFeatures', c_nvmlGridLicensableFeature_v4_t * NVML_GRID_LICENSE_FEATURE_MAX_COUNT),
+        ('gridLicensableFeatures',  c_nvmlGridLicensableFeature_v4_t * NVML_GRID_LICENSE_FEATURE_MAX_COUNT),
     ]
 
-
 class c_nvmlGridLicensableFeature_v3_t(_PrintableStructure):
     _fields_ = [
         ('featureCode', _nvmlGridLicenseFeatureCode_t),
         ('featureState', c_uint),
         ('licenseInfo', c_char * NVML_GRID_LICENSE_BUFFER_SIZE),
         ('productName', c_char * NVML_GRID_LICENSE_BUFFER_SIZE),
         ('featureEnabled', c_uint),
     ]
 
-
 class c_nvmlGridLicensableFeatures_v3_t(_PrintableStructure):
     _fields_ = [
         ('isGridLicenseSupported', c_int),
         ('licensableFeaturesCount', c_uint),
         ('gridLicensableFeatures', c_nvmlGridLicensableFeature_v3_t * NVML_GRID_LICENSE_FEATURE_MAX_COUNT),
     ]
 
-
 class c_nvmlGridLicensableFeature_v2_t(_PrintableStructure):
     _fields_ = [
         ('featureCode', _nvmlGridLicenseFeatureCode_t),
         ('featureState', c_uint),
         ('licenseInfo', c_char * NVML_GRID_LICENSE_BUFFER_SIZE),
         ('productName', c_char * NVML_GRID_LICENSE_BUFFER_SIZE),
     ]
 
-
 class c_nvmlGridLicensableFeatures_v2_t(_PrintableStructure):
     _fields_ = [
         ('isGridLicenseSupported', c_int),
         ('licensableFeaturesCount', c_uint),
         ('gridLicensableFeatures', c_nvmlGridLicensableFeature_v2_t * NVML_GRID_LICENSE_FEATURE_MAX_COUNT),
     ]
 
-
 class c_nvmlGridLicensableFeature_t(_PrintableStructure):
     _fields_ = [
         ('featureCode', _nvmlGridLicenseFeatureCode_t),
         ('featureState', c_uint),
         ('licenseInfo', c_char * NVML_GRID_LICENSE_BUFFER_SIZE),
     ]
 
-
 class c_nvmlGridLicensableFeatures_t(_PrintableStructure):
     _fields_ = [
         ('isGridLicenseSupported', c_int),
         ('licensableFeaturesCount', c_uint),
         ('gridLicensableFeatures', c_nvmlGridLicensableFeature_t * NVML_GRID_LICENSE_FEATURE_MAX_COUNT),
     ]
 
-
 ## Event structures
 class struct_c_nvmlEventSet_t(Structure):
-    pass  # opaque handle
-
-
+    pass # opaque handle
 c_nvmlEventSet_t = POINTER(struct_c_nvmlEventSet_t)
 
-nvmlEventTypeSingleBitEccError = 0x0000000000000001
-nvmlEventTypeDoubleBitEccError = 0x0000000000000002
-nvmlEventTypePState = 0x0000000000000004
-nvmlEventTypeXidCriticalError = 0x0000000000000008
-nvmlEventTypeClock = 0x0000000000000010
-nvmlEventTypePowerSourceChange = 0x0000000000000080
-nvmlEventMigConfigChange = 0x0000000000000100
-nvmlEventTypeNone = 0x0000000000000000
-nvmlEventTypeAll = (
-        nvmlEventTypeNone
-        | nvmlEventTypeSingleBitEccError
-        | nvmlEventTypeDoubleBitEccError
-        | nvmlEventTypePState
-        | nvmlEventTypeClock
-        | nvmlEventTypePowerSourceChange
-        | nvmlEventTypeXidCriticalError
-        | nvmlEventMigConfigChange
-)
+nvmlEventTypeSingleBitEccError     = 0x0000000000000001
+nvmlEventTypeDoubleBitEccError     = 0x0000000000000002
+nvmlEventTypePState                = 0x0000000000000004
+nvmlEventTypeXidCriticalError      = 0x0000000000000008
+nvmlEventTypeClock                 = 0x0000000000000010
+nvmlEventTypePowerSourceChange     = 0x0000000000000080
+nvmlEventMigConfigChange           = 0x0000000000000100
+nvmlEventTypeNone                  = 0x0000000000000000
+nvmlEventTypeAll                   = (
+                                        nvmlEventTypeNone
+                                        | nvmlEventTypeSingleBitEccError
+                                        | nvmlEventTypeDoubleBitEccError
+                                        | nvmlEventTypePState
+                                        | nvmlEventTypeClock
+                                        | nvmlEventTypePowerSourceChange
+                                        | nvmlEventTypeXidCriticalError
+                                        | nvmlEventMigConfigChange
+                                     )
+
+## Clock Event Reasons defines
+nvmlClocksEventReasonGpuIdle              = 0x0000000000000001
+nvmlClocksEventReasonApplicationsClocksSetting = 0x0000000000000002
+nvmlClocksEventReasonUserDefinedClocks         = nvmlClocksEventReasonApplicationsClocksSetting # deprecated, use nvmlClocksEventReasonApplicationsClocksSetting
+nvmlClocksEventReasonSwPowerCap           = 0x0000000000000004
+nvmlClocksEventReasonHwSlowdown           = 0x0000000000000008
+nvmlClocksEventReasonSyncBoost            = 0x0000000000000010
+nvmlClocksEventReasonSwThermalSlowdown    = 0x0000000000000020
+nvmlClocksEventReasonHwThermalSlowdown    = 0x0000000000000040
+nvmlClocksEventReasonHwPowerBrakeSlowdown = 0x0000000000000080
+nvmlClocksEventReasonDisplayClockSetting  = 0x0000000000000100
+nvmlClocksEventReasonNone                 = 0x0000000000000000
+nvmlClocksEventReasonAll                  = (
+                                                  nvmlClocksEventReasonNone |
+                                                  nvmlClocksEventReasonGpuIdle |
+                                                  nvmlClocksEventReasonApplicationsClocksSetting |
+                                                  nvmlClocksEventReasonSwPowerCap |
+                                                  nvmlClocksEventReasonHwSlowdown |
+                                                  nvmlClocksEventReasonSyncBoost |
+                                                  nvmlClocksEventReasonSwThermalSlowdown |
+                                                  nvmlClocksEventReasonHwThermalSlowdown |
+                                                  nvmlClocksEventReasonHwPowerBrakeSlowdown |
+                                                  nvmlClocksEventReasonDisplayClockSetting
+                                               )
 
-## Clock Throttle Reasons defines
-nvmlClocksThrottleReasonGpuIdle = 0x0000000000000001
+## Following have been deprecated
+nvmlClocksThrottleReasonGpuIdle              = 0x0000000000000001
 nvmlClocksThrottleReasonApplicationsClocksSetting = 0x0000000000000002
-nvmlClocksThrottleReasonUserDefinedClocks = nvmlClocksThrottleReasonApplicationsClocksSetting  # deprecated, use nvmlClocksThrottleReasonApplicationsClocksSetting
-nvmlClocksThrottleReasonSwPowerCap = 0x0000000000000004
-nvmlClocksThrottleReasonHwSlowdown = 0x0000000000000008
-nvmlClocksThrottleReasonSyncBoost = 0x0000000000000010
-nvmlClocksThrottleReasonSwThermalSlowdown = 0x0000000000000020
-nvmlClocksThrottleReasonHwThermalSlowdown = 0x0000000000000040
+nvmlClocksThrottleReasonUserDefinedClocks         = nvmlClocksThrottleReasonApplicationsClocksSetting # deprecated, use nvmlClocksThrottleReasonApplicationsClocksSetting
+nvmlClocksThrottleReasonSwPowerCap           = 0x0000000000000004
+nvmlClocksThrottleReasonHwSlowdown           = 0x0000000000000008
+nvmlClocksThrottleReasonSyncBoost            = 0x0000000000000010
+nvmlClocksThrottleReasonSwThermalSlowdown    = 0x0000000000000020
+nvmlClocksThrottleReasonHwThermalSlowdown    = 0x0000000000000040
 nvmlClocksThrottleReasonHwPowerBrakeSlowdown = 0x0000000000000080
-nvmlClocksThrottleReasonDisplayClockSetting = 0x0000000000000100
-nvmlClocksThrottleReasonNone = 0x0000000000000000
-nvmlClocksThrottleReasonAll = (
-        nvmlClocksThrottleReasonNone |
-        nvmlClocksThrottleReasonGpuIdle |
-        nvmlClocksThrottleReasonApplicationsClocksSetting |
-        nvmlClocksThrottleReasonSwPowerCap |
-        nvmlClocksThrottleReasonHwSlowdown |
-        nvmlClocksThrottleReasonSyncBoost |
-        nvmlClocksThrottleReasonSwThermalSlowdown |
-        nvmlClocksThrottleReasonHwThermalSlowdown |
-        nvmlClocksThrottleReasonHwPowerBrakeSlowdown |
-        nvmlClocksThrottleReasonDisplayClockSetting
-)
-
+nvmlClocksThrottleReasonDisplayClockSetting  = 0x0000000000000100
+nvmlClocksThrottleReasonNone                 = 0x0000000000000000
+nvmlClocksThrottleReasonAll                  = (
+                                                  nvmlClocksThrottleReasonNone |
+                                                  nvmlClocksThrottleReasonGpuIdle |
+                                                  nvmlClocksThrottleReasonApplicationsClocksSetting |
+                                                  nvmlClocksThrottleReasonSwPowerCap |
+                                                  nvmlClocksThrottleReasonHwSlowdown |
+                                                  nvmlClocksThrottleReasonSyncBoost |
+                                                  nvmlClocksThrottleReasonSwThermalSlowdown |
+                                                  nvmlClocksThrottleReasonHwThermalSlowdown |
+                                                  nvmlClocksThrottleReasonHwPowerBrakeSlowdown |
+                                                  nvmlClocksThrottleReasonDisplayClockSetting
+                                               )
 
 class c_nvmlEventData_t(_PrintableStructure):
     _fields_ = [
         ('device', c_nvmlDevice_t),
         ('eventType', c_ulonglong),
         ('eventData', c_ulonglong),
         ('gpuInstanceId', c_uint),
         ('computeInstanceId', c_uint)
     ]
     _fmt_ = {'eventType': "0x%08X"}
 
-
 class c_nvmlAccountingStats_t(_PrintableStructure):
     _fields_ = [
         ('gpuUtilization', c_uint),
         ('memoryUtilization', c_uint),
         ('maxMemoryUsage', c_ulonglong),
         ('time', c_ulonglong),
         ('startTime', c_ulonglong),
         ('isRunning', c_uint),
         ('reserved', c_uint * 5)
     ]
 
-
 class c_nvmlVgpuVersion_t(Structure):
     _fields_ = [("minVersion", c_uint),
                 ("maxVersion", c_uint)
-                ]
-
+               ]
 
 class c_nvmlVgpuMetadata_t(_PrintableStructure):
     _fields_ = [("version", c_uint),
                 ("revision", c_uint),
                 ("guestInfoState", _nvmlVgpuGuestInfoState_t),
                 ("guestDriverVersion", c_char * NVML_SYSTEM_DRIVER_VERSION_BUFFER_SIZE),
                 ("hostDriverVersion", c_char * NVML_SYSTEM_DRIVER_VERSION_BUFFER_SIZE),
                 ("reserved", c_uint * 6),
                 ("vgpuVirtualizationCaps", c_uint),
                 ("guestVgpuVersion", c_uint),
                 ("opaqueDataSize", c_uint),
                 ("opaqueData", c_char * NVML_VGPU_METADATA_OPAQUE_DATA_SIZE)
-                ]
-
+               ]
 
 class c_nvmlVgpuPgpuMetadata_t(_PrintableStructure):
     _fields_ = [("version", c_uint),
                 ("revision", c_uint),
                 ("hostDriverVersion", c_char * NVML_SYSTEM_DRIVER_VERSION_BUFFER_SIZE),
                 ("pgpuVirtualizationCaps", c_uint),
                 ("reserved", c_uint * 5),
                 ("hostSupportedVgpuRange", c_nvmlVgpuVersion_t),
                 ("opaqueDataSize", c_uint),
                 ("opaqueData", c_char * NVML_VGPU_PGPU_METADATA_OPAQUE_DATA_SIZE)
-                ]
-
+               ]
 
 class c_nvmlVgpuPgpuCompatibility_t(Structure):
     _fields_ = [("vgpuVmCompatibility", _nvmlVgpuVmCompatibility_t),
                 ("compatibilityLimitCode", _nvmlVgpuPgpuCompatibilityLimitCode_t)
-                ]
-
+               ]
 
 ## vGPU scheduler policy defines
-NVML_VGPU_SCHEDULER_POLICY_UNKNOWN = 0
-NVML_VGPU_SCHEDULER_POLICY_BEST_EFFORT = 1
-NVML_VGPU_SCHEDULER_POLICY_EQUAL_SHARE = 2
-NVML_VGPU_SCHEDULER_POLICY_FIXED_SHARE = 3
+NVML_VGPU_SCHEDULER_POLICY_UNKNOWN      = 0
+NVML_VGPU_SCHEDULER_POLICY_BEST_EFFORT  = 1
+NVML_VGPU_SCHEDULER_POLICY_EQUAL_SHARE  = 2
+NVML_VGPU_SCHEDULER_POLICY_FIXED_SHARE  = 3
 
 ## Supported vGPU scheduler policy count
-NVML_SUPPORTED_VGPU_SCHEDULER_POLICY_COUNT = 3
+NVML_SUPPORTED_VGPU_SCHEDULER_POLICY_COUNT  = 3
 
-NVML_SCHEDULER_SW_MAX_LOG_ENTRIES = 200
+NVML_SCHEDULER_SW_MAX_LOG_ENTRIES           = 200
 
+NVML_VGPU_SCHEDULER_ARR_DEFAULT   = 0
+NVML_VGPU_SCHEDULER_ARR_DISABLE   = 1
+NVML_VGPU_SCHEDULER_ARR_ENABLE    = 2
 
 class c_nvmlVgpuSchedDataWithARR_t(_PrintableStructure):
     _fields_ = [
-        ('avgFactor', c_uint),
-        ('timeslice', c_uint),
+        ('avgFactor',   c_uint),
+        ('timeslice',   c_uint),
     ]
 
-
 class c_nvmlVgpuSchedData_t(_PrintableStructure):
     _fields_ = [
-        ('timeslice', c_uint),
+        ('timeslice',   c_uint),
     ]
 
-
 class c_nvmlVgpuSchedulerParams_t(Union):
     _fields_ = [
         ('vgpuSchedDataWithARR', c_nvmlVgpuSchedDataWithARR_t),
-        ('vgpuSchedData', c_nvmlVgpuSchedData_t),
+        ('vgpuSchedData',        c_nvmlVgpuSchedData_t),
     ]
 
-
 class c_nvmlVgpuSchedulerLogEntry_t(_PrintableStructure):
     _fields_ = [
-        ('timestamp', c_ulonglong),
-        ('timeRunTotal', c_ulonglong),
-        ('timeRun', c_ulonglong),
-        ('swRunlistId', c_uint),
-        ('targetTimeSlice', c_ulonglong),
-        ('cumulativePreemptionTime', c_ulonglong),
+        ('timestamp',                   c_ulonglong),
+        ('timeRunTotal',                c_ulonglong),
+        ('timeRun',                     c_ulonglong),
+        ('swRunlistId',                 c_uint),
+        ('targetTimeSlice',             c_ulonglong),
+        ('cumulativePreemptionTime',    c_ulonglong),
     ]
 
-
 class c_nvmlVgpuSchedulerLog_t(_PrintableStructure):
     _fields_ = [
-        ('engineId', c_uint),
+        ('engineId',        c_uint),
         ('schedulerPolicy', c_uint),
-        ('isEnabledARR', c_uint),
+        ('arrMode',         c_uint),
         ('schedulerParams', c_nvmlVgpuSchedulerParams_t),
-        ('entriesCount', c_uint),
-        ('logEntries', c_nvmlVgpuSchedulerLogEntry_t * NVML_SCHEDULER_SW_MAX_LOG_ENTRIES),
+        ('entriesCount',    c_uint),
+        ('logEntries',      c_nvmlVgpuSchedulerLogEntry_t * NVML_SCHEDULER_SW_MAX_LOG_ENTRIES),
     ]
 
-
 class c_nvmlVgpuSchedulerGetState_t(_PrintableStructure):
     _fields_ = [
         ('schedulerPolicy', c_uint),
-        ('isEnabledARR', c_uint),
+        ('arrMode',         c_uint),
         ('schedulerParams', c_nvmlVgpuSchedulerParams_t),
     ]
 
-
 class c_nvmlVgpuSchedSetDataWithARR_t(_PrintableStructure):
     _fields_ = [
-        ('avgFactor', c_uint),
-        ('frequency', c_uint),
+        ('avgFactor',   c_uint),
+        ('frequency',   c_uint),
     ]
 
-
 class c_nvmlVgpuSchedSetData_t(_PrintableStructure):
     _fields_ = [
-        ('timeslice', c_uint),
+        ('timeslice',   c_uint),
     ]
 
+class c_nvmlVgpuSchedulerSetParams_t(Union):
+    _fields_ = [
+        ('vgpuSchedDataWithARR', c_nvmlVgpuSchedSetDataWithARR_t),
+        ('vgpuSchedData',        c_nvmlVgpuSchedSetData_t),
+    ]
+
+class c_nvmlVgpuSchedulerSetState_t(_PrintableStructure):
+    _fields_ = [
+        ('schedulerPolicy', c_uint),
+        ('enableARRMode',   c_uint),
+        ('schedulerParams', c_nvmlVgpuSchedulerSetParams_t),
+    ]
 
 class c_nvmlVgpuSchedulerCapabilities_t(_PrintableStructure):
     _fields_ = [
         ('supportedSchedulers', c_uint * NVML_SUPPORTED_VGPU_SCHEDULER_POLICY_COUNT),
-        ('maxTimeslice', c_uint),
-        ('minTimeslice', c_uint),
-        ('isArrModeSupported', c_uint),
-        ('maxFrequencyForARR', c_uint),
-        ('minFrequencyForARR', c_uint),
-        ('maxAvgFactorForARR', c_uint),
-        ('minAvgFactorForARR', c_uint),
+        ('maxTimeslice',        c_uint),
+        ('minTimeslice',        c_uint),
+        ('isArrModeSupported',  c_uint),
+        ('maxFrequencyForARR',  c_uint),
+        ('minFrequencyForARR',  c_uint),
+        ('maxAvgFactorForARR',  c_uint),
+        ('minAvgFactorForARR',  c_uint),
     ]
 
-
 class c_nvmlFBCStats_t(Structure):
     _fields_ = [("sessionsCount", c_uint),
                 ("averageFPS", c_uint),
                 ("averageLatency", c_uint)
-                ]
-
+               ]
 
 class c_nvmlFBCSession_t(_PrintableStructure):
     _fields_ = [
         ('sessionId', c_uint),
         ('pid', c_uint),
         ('vgpuInstance', _nvmlVgpuInstance_t),
         ('displayOrdinal', c_uint),
@@ -1601,258 +1648,269 @@
         ('vMaxResolution', c_uint),
         ('hResolution', c_uint),
         ('vResolution', c_uint),
         ('averageFPS', c_uint),
         ('averageLatency', c_uint),
     ]
 
-
 NVML_DEVICE_MIG_DISABLE = 0x0
-NVML_DEVICE_MIG_ENABLE = 0x1
+NVML_DEVICE_MIG_ENABLE  = 0x1
 
-NVML_GPU_INSTANCE_PROFILE_1_SLICE = 0x0
-NVML_GPU_INSTANCE_PROFILE_2_SLICE = 0x1
-NVML_GPU_INSTANCE_PROFILE_3_SLICE = 0x2
-NVML_GPU_INSTANCE_PROFILE_4_SLICE = 0x3
-NVML_GPU_INSTANCE_PROFILE_7_SLICE = 0x4
-NVML_GPU_INSTANCE_PROFILE_8_SLICE = 0x5
-NVML_GPU_INSTANCE_PROFILE_6_SLICE = 0x6
+NVML_GPU_INSTANCE_PROFILE_1_SLICE      = 0x0
+NVML_GPU_INSTANCE_PROFILE_2_SLICE      = 0x1
+NVML_GPU_INSTANCE_PROFILE_3_SLICE      = 0x2
+NVML_GPU_INSTANCE_PROFILE_4_SLICE      = 0x3
+NVML_GPU_INSTANCE_PROFILE_7_SLICE      = 0x4
+NVML_GPU_INSTANCE_PROFILE_8_SLICE      = 0x5
+NVML_GPU_INSTANCE_PROFILE_6_SLICE      = 0x6
 NVML_GPU_INSTANCE_PROFILE_1_SLICE_REV1 = 0x7
 NVML_GPU_INSTANCE_PROFILE_2_SLICE_REV1 = 0x8
 NVML_GPU_INSTANCE_PROFILE_1_SLICE_REV2 = 0x9
-NVML_GPU_INSTANCE_PROFILE_COUNT = 0xA
-
+NVML_GPU_INSTANCE_PROFILE_COUNT        = 0xA
 
 class c_nvmlGpuInstancePlacement_t(Structure):
     _fields_ = [("start", c_uint),
                 ("size", c_uint)
-                ]
-
+               ]
 
 class c_nvmlGpuInstanceProfileInfo_t(Structure):
     _fields_ = [("id", c_uint),
                 ("isP2pSupported", c_uint),
                 ("sliceCount", c_uint),
                 ("instanceCount", c_uint),
                 ("multiprocessorCount", c_uint),
                 ("copyEngineCount", c_uint),
                 ("decoderCount", c_uint),
                 ("encoderCount", c_uint),
                 ("jpegCount", c_uint),
                 ("ofaCount", c_uint),
                 ("memorySizeMB", c_ulonglong),
-                ]
-
+               ]
 
 nvmlGpuInstanceProfileInfo_v2 = 0x02000098
 
-
 class c_nvmlGpuInstanceProfileInfo_v2_t(_PrintableStructure):
     _fields_ = [("version", c_uint),
                 ("id", c_uint),
                 ("isP2pSupported", c_uint),
                 ("sliceCount", c_uint),
                 ("instanceCount", c_uint),
                 ("multiprocessorCount", c_uint),
                 ("copyEngineCount", c_uint),
                 ("decoderCount", c_uint),
                 ("encoderCount", c_uint),
                 ("jpegCount", c_uint),
                 ("ofaCount", c_uint),
                 ("memorySizeMB", c_ulonglong),
                 ("name", c_char * NVML_DEVICE_NAME_V2_BUFFER_SIZE)
-                ]
-
+               ]
+    
     def __init__(self):
         super(c_nvmlGpuInstanceProfileInfo_v2_t, self).__init__(version=nvmlGpuInstanceProfileInfo_v2)
 
-
 class c_nvmlGpuInstanceInfo_t(Structure):
     _fields_ = [("device", c_nvmlDevice_t),
                 ("id", c_uint),
                 ("profileId", c_uint),
                 ("placement", c_nvmlGpuInstancePlacement_t)
-                ]
-
+               ]
 
 class struct_c_nvmlGpuInstance_t(Structure):
-    pass  # opaque handle
-
-
+    pass # opaque handle
 c_nvmlGpuInstance_t = POINTER(struct_c_nvmlGpuInstance_t)
 
-NVML_COMPUTE_INSTANCE_PROFILE_1_SLICE = 0x0
-NVML_COMPUTE_INSTANCE_PROFILE_2_SLICE = 0x1
-NVML_COMPUTE_INSTANCE_PROFILE_3_SLICE = 0x2
-NVML_COMPUTE_INSTANCE_PROFILE_4_SLICE = 0x3
-NVML_COMPUTE_INSTANCE_PROFILE_7_SLICE = 0x4
-NVML_COMPUTE_INSTANCE_PROFILE_8_SLICE = 0x5
-NVML_COMPUTE_INSTANCE_PROFILE_6_SLICE = 0x6
+NVML_COMPUTE_INSTANCE_PROFILE_1_SLICE      = 0x0
+NVML_COMPUTE_INSTANCE_PROFILE_2_SLICE      = 0x1
+NVML_COMPUTE_INSTANCE_PROFILE_3_SLICE      = 0x2
+NVML_COMPUTE_INSTANCE_PROFILE_4_SLICE      = 0x3
+NVML_COMPUTE_INSTANCE_PROFILE_7_SLICE      = 0x4
+NVML_COMPUTE_INSTANCE_PROFILE_8_SLICE      = 0x5
+NVML_COMPUTE_INSTANCE_PROFILE_6_SLICE      = 0x6
 NVML_COMPUTE_INSTANCE_PROFILE_1_SLICE_REV1 = 0x7
-NVML_COMPUTE_INSTANCE_PROFILE_COUNT = 0x8
+NVML_COMPUTE_INSTANCE_PROFILE_COUNT        = 0x8
 
 NVML_COMPUTE_INSTANCE_ENGINE_PROFILE_SHARED = 0x0
 NVML_COMPUTE_INSTANCE_ENGINE_PROFILE_COUNT = 0x1
 
-
 class c_nvmlComputeInstancePlacement_t(Structure):
     _fields_ = [("start", c_uint),
                 ("size", c_uint)
-                ]
-
+               ]
 
 class c_nvmlComputeInstanceProfileInfo_t(Structure):
     _fields_ = [("id", c_uint),
                 ("sliceCount", c_uint),
                 ("instanceCount", c_uint),
                 ("multiprocessorCount", c_uint),
                 ("sharedCopyEngineCount", c_uint),
                 ("sharedDecoderCount", c_uint),
                 ("sharedEncoderCount", c_uint),
                 ("sharedJpegCount", c_uint),
                 ("sharedOfaCount", c_uint)
-                ]
-
+               ]
 
 nvmlComputeInstanceProfileInfo_v2 = 0x02000088
 
-
 class c_nvmlComputeInstanceProfileInfo_v2_t(_PrintableStructure):
     _fields_ = [("version", c_uint),
                 ("id", c_uint),
                 ("sliceCount", c_uint),
                 ("instanceCount", c_uint),
                 ("multiprocessorCount", c_uint),
                 ("sharedCopyEngineCount", c_uint),
                 ("sharedDecoderCount", c_uint),
                 ("sharedEncoderCount", c_uint),
                 ("sharedJpegCount", c_uint),
                 ("sharedOfaCount", c_uint),
                 ("name", c_char * NVML_DEVICE_NAME_V2_BUFFER_SIZE)
-                ]
+               ]
 
     def __init__(self):
         super(c_nvmlComputeInstanceProfileInfo_v2_t, self).__init__(version=nvmlComputeInstanceProfileInfo_v2)
 
-
 class c_nvmlComputeInstanceInfo_t(Structure):
     _fields_ = [("device", c_nvmlDevice_t),
                 ("gpuInstance", c_nvmlGpuInstance_t),
                 ("id", c_uint),
                 ("profileId", c_uint),
                 ("placement", c_nvmlComputeInstancePlacement_t)
-                ]
-
+               ]
 
 NVML_MAX_GPU_UTILIZATIONS = 8
-NVML_GPU_UTILIZATION_DOMAIN_GPU = 0
-NVML_GPU_UTILIZATION_DOMAIN_FB = 1
-NVML_GPU_UTILIZATION_DOMAIN_VID = 2
-NVML_GPU_UTILIZATION_DOMAIN_BUS = 3
-
-
+NVML_GPU_UTILIZATION_DOMAIN_GPU    = 0
+NVML_GPU_UTILIZATION_DOMAIN_FB     = 1
+NVML_GPU_UTILIZATION_DOMAIN_VID    = 2
+NVML_GPU_UTILIZATION_DOMAIN_BUS    = 3
 class c_nvmlGpuDynamicPstatesUtilization_t(Structure):
     _fields_ = [("bIsPresent", c_uint, 1),
                 ("percentage", c_uint),
                 ("incThreshold", c_uint),
                 ("decThreshold", c_uint)]
-
-
 class c_nvmlGpuDynamicPstatesInfo_t(Structure):
     _fields_ = [("flags", c_uint),
                 ("utilization", c_nvmlGpuDynamicPstatesUtilization_t * NVML_MAX_GPU_UTILIZATIONS)]
 
-
 NVML_MAX_THERMAL_SENSORS_PER_GPU = 3
 
-NVML_THERMAL_TARGET_NONE = 0
-NVML_THERMAL_TARGET_GPU = 1
-NVML_THERMAL_TARGET_MEMORY = 2
-NVML_THERMAL_TARGET_POWER_SUPPLY = 4
-NVML_THERMAL_TARGET_BOARD = 8
-NVML_THERMAL_TARGET_VCD_BOARD = 9
-NVML_THERMAL_TARGET_VCD_INLET = 10
-NVML_THERMAL_TARGET_VCD_OUTLET = 11
-NVML_THERMAL_TARGET_ALL = 15
-NVML_THERMAL_TARGET_UNKNOWN = -1
-
-NVML_THERMAL_CONTROLLER_NONE = 0
-NVML_THERMAL_CONTROLLER_GPU_INTERNAL = 1
-NVML_THERMAL_CONTROLLER_ADM1032 = 2
-NVML_THERMAL_CONTROLLER_ADT7461 = 3
-NVML_THERMAL_CONTROLLER_MAX6649 = 4
-NVML_THERMAL_CONTROLLER_MAX1617 = 5
-NVML_THERMAL_CONTROLLER_LM99 = 6
-NVML_THERMAL_CONTROLLER_LM89 = 7
-NVML_THERMAL_CONTROLLER_LM64 = 8
-NVML_THERMAL_CONTROLLER_G781 = 9
-NVML_THERMAL_CONTROLLER_ADT7473 = 10
-NVML_THERMAL_CONTROLLER_SBMAX6649 = 11
-NVML_THERMAL_CONTROLLER_VBIOSEVT = 12
-NVML_THERMAL_CONTROLLER_OS = 13
+NVML_THERMAL_TARGET_NONE          = 0
+NVML_THERMAL_TARGET_GPU           = 1
+NVML_THERMAL_TARGET_MEMORY        = 2
+NVML_THERMAL_TARGET_POWER_SUPPLY  = 4
+NVML_THERMAL_TARGET_BOARD         = 8
+NVML_THERMAL_TARGET_VCD_BOARD     = 9
+NVML_THERMAL_TARGET_VCD_INLET     = 10
+NVML_THERMAL_TARGET_VCD_OUTLET    = 11
+NVML_THERMAL_TARGET_ALL           = 15
+NVML_THERMAL_TARGET_UNKNOWN       = -1
+
+NVML_THERMAL_CONTROLLER_NONE            = 0
+NVML_THERMAL_CONTROLLER_GPU_INTERNAL    = 1
+NVML_THERMAL_CONTROLLER_ADM1032         = 2
+NVML_THERMAL_CONTROLLER_ADT7461         = 3
+NVML_THERMAL_CONTROLLER_MAX6649         = 4
+NVML_THERMAL_CONTROLLER_MAX1617         = 5
+NVML_THERMAL_CONTROLLER_LM99            = 6
+NVML_THERMAL_CONTROLLER_LM89            = 7
+NVML_THERMAL_CONTROLLER_LM64            = 8
+NVML_THERMAL_CONTROLLER_G781            = 9
+NVML_THERMAL_CONTROLLER_ADT7473         = 10
+NVML_THERMAL_CONTROLLER_SBMAX6649       = 11
+NVML_THERMAL_CONTROLLER_VBIOSEVT        = 12
+NVML_THERMAL_CONTROLLER_OS              = 13
 NVML_THERMAL_CONTROLLER_NVSYSCON_CANOAS = 14
-NVML_THERMAL_CONTROLLER_NVSYSCON_E551 = 15
-NVML_THERMAL_CONTROLLER_MAX6649R = 16
-NVML_THERMAL_CONTROLLER_ADT7473S = 17
-NVML_THERMAL_CONTROLLER_UNKNOWN = -1
-
+NVML_THERMAL_CONTROLLER_NVSYSCON_E551   = 15
+NVML_THERMAL_CONTROLLER_MAX6649R        = 16
+NVML_THERMAL_CONTROLLER_ADT7473S        = 17
+NVML_THERMAL_CONTROLLER_UNKNOWN         = -1
 
 class c_nvmlGpuThermalSensor_t(Structure):
     _fields_ = [("controller", c_int),
                 ("defaultMinTemp", c_int),
                 ("defaultMaxTemp", c_int),
                 ("currentTemp", c_int),
                 ("target", c_int)]
-
-
 class c_nvmlGpuThermalSettings_t(Structure):
     _fields_ = [("count", c_uint),
                 ("sensor", c_nvmlGpuThermalSensor_t * NVML_MAX_THERMAL_SENSORS_PER_GPU)]
 
-
 class struct_c_nvmlComputeInstance_t(Structure):
-    pass  # opaque handle
-
-
+    pass # opaque handle
 c_nvmlComputeInstance_t = POINTER(struct_c_nvmlComputeInstance_t)
 
-
 class c_nvmlDeviceAttributes(Structure):
     _fields_ = [("multiprocessorCount", c_uint),
                 ("sharedCopyEngineCount", c_uint),
                 ("sharedDecoderCount", c_uint),
                 ("sharedEncoderCount", c_uint),
                 ("sharedJpegCount", c_uint),
                 ("sharedOfaCount", c_uint),
                 ("gpuInstanceSliceCount", c_uint),
                 ("computeInstanceSliceCount", c_uint),
                 ("memorySizeMB", c_ulonglong),
-                ]
-
+               ]
 
 class c_nvmlRowRemapperHistogramValues(Structure):
     _fields_ = [("max", c_uint),
                 ("high", c_uint),
                 ("partial", c_uint),
                 ("low", c_uint),
                 ("none", c_uint)
-                ]
+               ]
+
+NVML_GPU_CERT_CHAIN_SIZE                = 0x1000
+NVML_GPU_ATTESTATION_CERT_CHAIN_SIZE    = 0x1400
+NVML_CC_GPU_CEC_NONCE_SIZE              = 0x20
+NVML_CC_GPU_ATTESTATION_REPORT_SIZE     = 0x2000
+NVML_CC_GPU_CEC_ATTESTATION_REPORT_SIZE = 0x1000
+NVML_CC_CEC_ATTESTATION_REPORT_NOT_PRESENT = 0
+NVML_CC_CEC_ATTESTATION_REPORT_PRESENT     = 1
+
+class c_nvmlConfComputeSystemState_t(Structure):
+    _fields_ = [('environment', c_uint),
+                ('ccFeature', c_uint),
+                ('devToolsMode', c_uint),
+               ]
+
+class c_nvmlConfComputeSystemCaps_t(Structure):
+    _fields_ = [('cpuCaps', c_uint),
+                ('gpusCaps', c_uint),
+               ]
+
+class c_nvmlConfComputeMemSizeInfo_t(Structure):
+    _fields_ = [('protectedMemSizeKib', c_ulonglong),
+                ('unprotectedMemSizeKib', c_ulonglong),
+               ]
+
+class c_nvmlConfComputeGpuCertificate_t(Structure):
+    _fields_ = [('certChainSize', c_uint),
+                ('attestationCertChainSize', c_uint),
+                ('certChain', c_uint8 * NVML_GPU_CERT_CHAIN_SIZE),
+                ('attestationCertChain', c_uint8 * NVML_GPU_ATTESTATION_CERT_CHAIN_SIZE),
+               ]
+
+class c_nvmlConfComputeGpuAttestationReport_t(Structure):
+    _fields_ = [('isCecAttestationReportPresent', c_uint),
+                ('attestationReportSize', c_uint),
+                ('cecAttestationReportSize', c_uint),
+                ('nonce', c_uint8 * NVML_CC_GPU_CEC_NONCE_SIZE),
+                ('attestationReport', c_uint8 * NVML_CC_GPU_ATTESTATION_REPORT_SIZE),
+                ('cecAttestationReport', c_uint8 * NVML_CC_GPU_CEC_ATTESTATION_REPORT_SIZE),
+               ]
 
 
 ## string/bytes conversion for ease of use
 def convertStrBytes(func):
     '''
     In python 3, strings are unicode instead of bytes, and need to be converted for ctypes
     Args from caller: (1, 'string', <__main__.c_nvmlDevice_t at 0xFFFFFFFF>)
     Args passed to function: (1, b'string', <__main__.c_nvmlDevice_t at 0xFFFFFFFF)>
     ----
     Returned from function: b'returned string'
     Returned to caller: 'returned string'
     '''
-
     @wraps(func)
     def wrapper(*args, **kwargs):
         # encoding a str returns bytes in python 2 and 3
         args = [arg.encode() if isinstance(arg, str) else arg for arg in args]
         res = func(*args, **kwargs)
         # In python 2, str and bytes are the same
         # In python 3, str is unicode and should be decoded.
@@ -1863,15 +1921,14 @@
             return res.decode()
         return res
 
     if sys.version_info >= (3,):
         return wrapper
     return func
 
-
 ## C function wrappers ##
 def nvmlInitWithFlags(flags):
     _LoadNvmlLibrary()
 
     #
     # Initialize the library
     #
@@ -1882,56 +1939,52 @@
     # Atomically update refcount
     global _nvmlLib_refcount
     libLoadLock.acquire()
     _nvmlLib_refcount += 1
     libLoadLock.release()
     return None
 
-
 def nvmlInit():
     nvmlInitWithFlags(0)
     return None
 
-
 def _LoadNvmlLibrary():
     '''
     Load the library if it isn't loaded already
     '''
     global nvmlLib
 
-    if nvmlLib is None:
+    if (nvmlLib == None):
         # lock to ensure only one caller loads the library
         libLoadLock.acquire()
 
         try:
             # ensure the library still isn't loaded
-            if nvmlLib is None:
+            if (nvmlLib == None):
                 try:
                     if (sys.platform[:3] == "win"):
                         # cdecl calling convention
                         try:
                             # Check for nvml.dll in System32 first for DCH drivers
                             nvmlLib = CDLL(os.path.join(os.getenv("WINDIR", "C:/Windows"), "System32/nvml.dll"))
                         except OSError as ose:
                             # If nvml.dll is not found in System32, it should be in ProgramFiles
                             # load nvml.dll from %ProgramFiles%/NVIDIA Corporation/NVSMI/nvml.dll
-                            nvmlLib = CDLL(os.path.join(os.getenv("ProgramFiles", "C:/Program Files"),
-                                                        "NVIDIA Corporation/NVSMI/nvml.dll"))
+                            nvmlLib = CDLL(os.path.join(os.getenv("ProgramFiles", "C:/Program Files"), "NVIDIA Corporation/NVSMI/nvml.dll"))
                     else:
                         # assume linux
                         nvmlLib = CDLL("libnvidia-ml.so.1")
                 except OSError as ose:
                     _nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)
-                if nvmlLib is None:
+                if (nvmlLib == None):
                     _nvmlCheckReturn(NVML_ERROR_LIBRARY_NOT_FOUND)
         finally:
             # lock is always freed
             libLoadLock.release()
 
-
 def nvmlShutdown():
     #
     # Leave the library loaded, but shutdown the interface
     #
     fn = _nvmlGetFunctionPointer("nvmlShutdown")
     ret = fn()
     _nvmlCheckReturn(ret)
@@ -1940,376 +1993,349 @@
     global _nvmlLib_refcount
     libLoadLock.acquire()
     if (0 < _nvmlLib_refcount):
         _nvmlLib_refcount -= 1
     libLoadLock.release()
     return None
 
-
 # Added in 2.285
 @convertStrBytes
 def nvmlErrorString(result):
     fn = _nvmlGetFunctionPointer("nvmlErrorString")
-    fn.restype = c_char_p  # otherwise return is an int
+    fn.restype = c_char_p # otherwise return is an int
     ret = fn(result)
     return ret
 
-
 # Added in 2.285
 @convertStrBytes
 def nvmlSystemGetNVMLVersion():
     c_version = create_string_buffer(NVML_SYSTEM_NVML_VERSION_BUFFER_SIZE)
     fn = _nvmlGetFunctionPointer("nvmlSystemGetNVMLVersion")
     ret = fn(c_version, c_uint(NVML_SYSTEM_NVML_VERSION_BUFFER_SIZE))
     _nvmlCheckReturn(ret)
     return c_version.value
 
-
 def nvmlSystemGetCudaDriverVersion():
     c_cuda_version = c_int()
     fn = _nvmlGetFunctionPointer("nvmlSystemGetCudaDriverVersion")
     ret = fn(byref(c_cuda_version))
     _nvmlCheckReturn(ret)
     return c_cuda_version.value
 
-
 def nvmlSystemGetCudaDriverVersion_v2():
     c_cuda_version = c_int()
     fn = _nvmlGetFunctionPointer("nvmlSystemGetCudaDriverVersion_v2")
     ret = fn(byref(c_cuda_version))
     _nvmlCheckReturn(ret)
     return c_cuda_version.value
 
-
 # Added in 2.285
 @convertStrBytes
 def nvmlSystemGetProcessName(pid):
     c_name = create_string_buffer(1024)
     fn = _nvmlGetFunctionPointer("nvmlSystemGetProcessName")
     ret = fn(c_uint(pid), c_name, c_uint(1024))
     _nvmlCheckReturn(ret)
     return c_name.value
 
-
 @convertStrBytes
 def nvmlSystemGetDriverVersion():
     c_version = create_string_buffer(NVML_SYSTEM_DRIVER_VERSION_BUFFER_SIZE)
     fn = _nvmlGetFunctionPointer("nvmlSystemGetDriverVersion")
     ret = fn(c_version, c_uint(NVML_SYSTEM_DRIVER_VERSION_BUFFER_SIZE))
     _nvmlCheckReturn(ret)
     return c_version.value
 
-
 # Added in 2.285
 def nvmlSystemGetHicVersion():
     c_count = c_uint(0)
     hics = None
     fn = _nvmlGetFunctionPointer("nvmlSystemGetHicVersion")
 
     # get the count
     ret = fn(byref(c_count), None)
 
     # this should only fail with insufficient size
     if ((ret != NVML_SUCCESS) and
-            (ret != NVML_ERROR_INSUFFICIENT_SIZE)):
+        (ret != NVML_ERROR_INSUFFICIENT_SIZE)):
         raise NVMLError(ret)
 
     # If there are no hics
     if (c_count.value == 0):
         return []
 
     hic_array = c_nvmlHwbcEntry_t * c_count.value
     hics = hic_array()
     ret = fn(byref(c_count), hics)
     _nvmlCheckReturn(ret)
     return hics
 
-
 ## Unit get functions
 def nvmlUnitGetCount():
     c_count = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlUnitGetCount")
     ret = fn(byref(c_count))
     _nvmlCheckReturn(ret)
     return c_count.value
 
-
 def nvmlUnitGetHandleByIndex(index):
     c_index = c_uint(index)
     unit = c_nvmlUnit_t()
     fn = _nvmlGetFunctionPointer("nvmlUnitGetHandleByIndex")
     ret = fn(c_index, byref(unit))
     _nvmlCheckReturn(ret)
     return unit
 
-
 def nvmlUnitGetUnitInfo(unit):
     c_info = c_nvmlUnitInfo_t()
     fn = _nvmlGetFunctionPointer("nvmlUnitGetUnitInfo")
     ret = fn(unit, byref(c_info))
     _nvmlCheckReturn(ret)
     return c_info
 
-
 def nvmlUnitGetLedState(unit):
-    c_state = c_nvmlLedState_t()
+    c_state =  c_nvmlLedState_t()
     fn = _nvmlGetFunctionPointer("nvmlUnitGetLedState")
     ret = fn(unit, byref(c_state))
     _nvmlCheckReturn(ret)
     return c_state
 
-
 def nvmlUnitGetPsuInfo(unit):
     c_info = c_nvmlPSUInfo_t()
     fn = _nvmlGetFunctionPointer("nvmlUnitGetPsuInfo")
     ret = fn(unit, byref(c_info))
     _nvmlCheckReturn(ret)
     return c_info
 
-
 def nvmlUnitGetTemperature(unit, type):
     c_temp = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlUnitGetTemperature")
     ret = fn(unit, c_uint(type), byref(c_temp))
     _nvmlCheckReturn(ret)
     return c_temp.value
 
-
 def nvmlUnitGetFanSpeedInfo(unit):
     c_speeds = c_nvmlUnitFanSpeeds_t()
     fn = _nvmlGetFunctionPointer("nvmlUnitGetFanSpeedInfo")
     ret = fn(unit, byref(c_speeds))
     _nvmlCheckReturn(ret)
     return c_speeds
 
-
 # added to API
 def nvmlUnitGetDeviceCount(unit):
     c_count = c_uint(0)
     # query the unit to determine device count
     fn = _nvmlGetFunctionPointer("nvmlUnitGetDevices")
     ret = fn(unit, byref(c_count), None)
     if (ret == NVML_ERROR_INSUFFICIENT_SIZE):
         ret = NVML_SUCCESS
     _nvmlCheckReturn(ret)
     return c_count.value
 
-
 def nvmlUnitGetDevices(unit):
     c_count = c_uint(nvmlUnitGetDeviceCount(unit))
     device_array = c_nvmlDevice_t * c_count.value
     c_devices = device_array()
     fn = _nvmlGetFunctionPointer("nvmlUnitGetDevices")
     ret = fn(unit, byref(c_count), c_devices)
     _nvmlCheckReturn(ret)
     return c_devices
 
-
 ## Device get functions
 def nvmlDeviceGetCount():
     c_count = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetCount_v2")
     ret = fn(byref(c_count))
     _nvmlCheckReturn(ret)
     return c_count.value
 
-
 def nvmlDeviceGetHandleByIndex(index):
     c_index = c_uint(index)
     device = c_nvmlDevice_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetHandleByIndex_v2")
     ret = fn(c_index, byref(device))
     _nvmlCheckReturn(ret)
     return device
 
-
 @convertStrBytes
 def nvmlDeviceGetHandleBySerial(serial):
     c_serial = c_char_p(serial)
     device = c_nvmlDevice_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetHandleBySerial")
     ret = fn(c_serial, byref(device))
     _nvmlCheckReturn(ret)
     return device
 
-
 @convertStrBytes
 def nvmlDeviceGetHandleByUUID(uuid):
     c_uuid = c_char_p(uuid)
     device = c_nvmlDevice_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetHandleByUUID")
     ret = fn(c_uuid, byref(device))
     _nvmlCheckReturn(ret)
     return device
 
-
 @convertStrBytes
 def nvmlDeviceGetHandleByPciBusId(pciBusId):
     c_busId = c_char_p(pciBusId)
     device = c_nvmlDevice_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetHandleByPciBusId_v2")
     ret = fn(c_busId, byref(device))
     _nvmlCheckReturn(ret)
     return device
 
-
 @convertStrBytes
 def nvmlDeviceGetName(handle):
     c_name = create_string_buffer(NVML_DEVICE_NAME_V2_BUFFER_SIZE)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetName")
     ret = fn(handle, c_name, c_uint(NVML_DEVICE_NAME_V2_BUFFER_SIZE))
     _nvmlCheckReturn(ret)
     return c_name.value
 
-
 def nvmlDeviceGetBoardId(handle):
-    c_id = c_uint()
+    c_id = c_uint();
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetBoardId")
     ret = fn(handle, byref(c_id))
     _nvmlCheckReturn(ret)
     return c_id.value
 
-
 def nvmlDeviceGetMultiGpuBoard(handle):
-    c_multiGpu = c_uint()
+    c_multiGpu = c_uint();
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMultiGpuBoard")
     ret = fn(handle, byref(c_multiGpu))
     _nvmlCheckReturn(ret)
     return c_multiGpu.value
 
-
 def nvmlDeviceGetBrand(handle):
     c_type = _nvmlBrandType_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetBrand")
     ret = fn(handle, byref(c_type))
     _nvmlCheckReturn(ret)
     return c_type.value
 
-
 @convertStrBytes
 def nvmlDeviceGetBoardPartNumber(handle):
     c_part_number = create_string_buffer(NVML_DEVICE_PART_NUMBER_BUFFER_SIZE)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetBoardPartNumber")
     ret = fn(handle, c_part_number, c_uint(NVML_DEVICE_PART_NUMBER_BUFFER_SIZE))
     _nvmlCheckReturn(ret)
     return c_part_number.value
 
-
 @convertStrBytes
 def nvmlDeviceGetSerial(handle):
     c_serial = create_string_buffer(NVML_DEVICE_SERIAL_BUFFER_SIZE)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetSerial")
     ret = fn(handle, c_serial, c_uint(NVML_DEVICE_SERIAL_BUFFER_SIZE))
     _nvmlCheckReturn(ret)
     return c_serial.value
 
+def nvmlDeviceGetModuleId(handle, moduleId):
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetModuleId")
+    ret = fn(handle, moduleId)
+    return ret
 
 def nvmlDeviceGetMemoryAffinity(handle, nodeSetSize, scope):
     affinity_array = c_ulonglong * nodeSetSize
     c_affinity = affinity_array()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMemoryAffinity")
     ret = fn(handle, nodeSetSize, byref(c_affinity), _nvmlAffinityScope_t(scope))
     _nvmlCheckReturn(ret)
     return c_affinity
 
-
 def nvmlDeviceGetCpuAffinityWithinScope(handle, cpuSetSize, scope):
     affinity_array = c_ulonglong * cpuSetSize
     c_affinity = affinity_array()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetCpuAffinityWithinScope")
     ret = fn(handle, cpuSetSize, byref(c_affinity), _nvmlAffinityScope_t(scope))
     _nvmlCheckReturn(ret)
     return c_affinity
 
-
 def nvmlDeviceGetCpuAffinity(handle, cpuSetSize):
     affinity_array = c_ulonglong * cpuSetSize
     c_affinity = affinity_array()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetCpuAffinity")
     ret = fn(handle, cpuSetSize, byref(c_affinity))
     _nvmlCheckReturn(ret)
     return c_affinity
 
-
 def nvmlDeviceSetCpuAffinity(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetCpuAffinity")
     ret = fn(handle)
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceClearCpuAffinity(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceClearCpuAffinity")
     ret = fn(handle)
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceGetMinorNumber(handle):
     c_minor_number = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMinorNumber")
     ret = fn(handle, byref(c_minor_number))
     _nvmlCheckReturn(ret)
     return c_minor_number.value
 
-
 @convertStrBytes
 def nvmlDeviceGetUUID(handle):
     c_uuid = create_string_buffer(NVML_DEVICE_UUID_V2_BUFFER_SIZE)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetUUID")
     ret = fn(handle, c_uuid, c_uint(NVML_DEVICE_UUID_V2_BUFFER_SIZE))
     _nvmlCheckReturn(ret)
     return c_uuid.value
 
-
 @convertStrBytes
 def nvmlDeviceGetInforomVersion(handle, infoRomObject):
     c_version = create_string_buffer(NVML_DEVICE_INFOROM_VERSION_BUFFER_SIZE)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetInforomVersion")
     ret = fn(handle, _nvmlInforomObject_t(infoRomObject),
-             c_version, c_uint(NVML_DEVICE_INFOROM_VERSION_BUFFER_SIZE))
+                 c_version, c_uint(NVML_DEVICE_INFOROM_VERSION_BUFFER_SIZE))
     _nvmlCheckReturn(ret)
     return c_version.value
 
-
 # Added in 4.304
 @convertStrBytes
 def nvmlDeviceGetInforomImageVersion(handle):
     c_version = create_string_buffer(NVML_DEVICE_INFOROM_VERSION_BUFFER_SIZE)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetInforomImageVersion")
     ret = fn(handle, c_version, c_uint(NVML_DEVICE_INFOROM_VERSION_BUFFER_SIZE))
     _nvmlCheckReturn(ret)
     return c_version.value
 
-
 # Added in 4.304
 def nvmlDeviceGetInforomConfigurationChecksum(handle):
     c_checksum = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetInforomConfigurationChecksum")
     ret = fn(handle, byref(c_checksum))
     _nvmlCheckReturn(ret)
     return c_checksum.value
 
-
 # Added in 4.304
 def nvmlDeviceValidateInforom(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceValidateInforom")
     ret = fn(handle)
     _nvmlCheckReturn(ret)
     return None
 
+def nvmlDeviceGetLastBBXFlushTime(handle):
+    c_timestamp = c_ulonglong()
+    c_durationUs = c_ulong()
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetLastBBXFlushTime")
+    ret = fn(handle, byref(c_timestamp), byref(c_durationUs))
+    _nvmlCheckReturn(ret)
+    return [c_timestamp.value, c_durationUs.value]
 
 def nvmlDeviceGetDisplayMode(handle):
     c_mode = _nvmlEnableState_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetDisplayMode")
     ret = fn(handle, byref(c_mode))
     _nvmlCheckReturn(ret)
     return c_mode.value
 
-
 def nvmlDeviceGetDisplayActive(handle):
     c_mode = _nvmlEnableState_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetDisplayActive")
     ret = fn(handle, byref(c_mode))
     _nvmlCheckReturn(ret)
     return c_mode.value
 
@@ -2317,78 +2343,69 @@
 def nvmlDeviceGetPersistenceMode(handle):
     c_state = _nvmlEnableState_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPersistenceMode")
     ret = fn(handle, byref(c_state))
     _nvmlCheckReturn(ret)
     return c_state.value
 
-
 def nvmlDeviceGetPciInfo_v3(handle):
     c_info = nvmlPciInfo_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPciInfo_v3")
     ret = fn(handle, byref(c_info))
     _nvmlCheckReturn(ret)
     return c_info
 
-
 def nvmlDeviceGetPciInfo(handle):
     return nvmlDeviceGetPciInfo_v3(handle)
 
-
 def nvmlDeviceGetClockInfo(handle, type):
     c_clock = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetClockInfo")
     ret = fn(handle, _nvmlClockType_t(type), byref(c_clock))
     _nvmlCheckReturn(ret)
     return c_clock.value
 
-
 # Added in 2.285
 def nvmlDeviceGetMaxClockInfo(handle, type):
     c_clock = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMaxClockInfo")
     ret = fn(handle, _nvmlClockType_t(type), byref(c_clock))
     _nvmlCheckReturn(ret)
     return c_clock.value
 
-
 # Added in 4.304
 def nvmlDeviceGetApplicationsClock(handle, type):
     c_clock = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetApplicationsClock")
     ret = fn(handle, _nvmlClockType_t(type), byref(c_clock))
     _nvmlCheckReturn(ret)
     return c_clock.value
 
-
 def nvmlDeviceGetMaxCustomerBoostClock(handle, type):
     c_clock = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMaxCustomerBoostClock")
     ret = fn(handle, _nvmlClockType_t(type), byref(c_clock))
     _nvmlCheckReturn(ret)
     return c_clock.value
 
-
 def nvmlDeviceGetClock(handle, type, id):
     c_clock = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetClock")
     ret = fn(handle, _nvmlClockType_t(type), _nvmlClockId_t(id), byref(c_clock))
     _nvmlCheckReturn(ret)
     return c_clock.value
 
-
 # Added in 5.319
 def nvmlDeviceGetDefaultApplicationsClock(handle, type):
     c_clock = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetDefaultApplicationsClock")
     ret = fn(handle, _nvmlClockType_t(type), byref(c_clock))
     _nvmlCheckReturn(ret)
     return c_clock.value
 
-
 # Added in 4.304
 def nvmlDeviceGetSupportedMemoryClocks(handle):
     # first call to get the size
     c_count = c_uint(0)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetSupportedMemoryClocks")
     ret = fn(handle, byref(c_count), None)
 
@@ -2409,15 +2426,14 @@
             procs.append(c_clocks[i])
 
         return procs
     else:
         # error case
         raise NVMLError(ret)
 
-
 # Added in 4.304
 def nvmlDeviceGetSupportedGraphicsClocks(handle, memoryClockMHz):
     # first call to get the size
     c_count = c_uint(0)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetSupportedGraphicsClocks")
     ret = fn(handle, c_uint(memoryClockMHz), byref(c_count), None)
 
@@ -2438,143 +2454,126 @@
             procs.append(c_clocks[i])
 
         return procs
     else:
         # error case
         raise NVMLError(ret)
 
-
 def nvmlDeviceGetFanSpeed(handle):
     c_speed = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetFanSpeed")
     ret = fn(handle, byref(c_speed))
     _nvmlCheckReturn(ret)
     return c_speed.value
 
-
 def nvmlDeviceGetFanSpeed_v2(handle, fan):
     c_speed = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetFanSpeed_v2")
     ret = fn(handle, fan, byref(c_speed))
     _nvmlCheckReturn(ret)
     return c_speed.value
 
-
 def nvmlDeviceGetTargetFanSpeed(handle, fan):
     c_speed = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetTargetFanSpeed")
     ret = fn(handle, fan, byref(c_speed))
     _nvmlCheckReturn(ret)
     return c_speed.value
 
-
 def nvmlDeviceGetNumFans(device):
     c_numFans = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetNumFans")
     ret = fn(device, byref(c_numFans))
     _nvmlCheckReturn(ret)
     return c_numFans.value
 
-
 def nvmlDeviceSetDefaultFanSpeed_v2(handle, index):
-    fn = _nvmlGetFunctionPointer("nvmlDeviceSetDefaultFanSpeed_v2")
+    fn = _nvmlGetFunctionPointer("nvmlDeviceSetDefaultFanSpeed_v2");
     ret = fn(handle, index)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceGetMinMaxFanSpeed(handle, minSpeed, maxSpeed):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMinMaxFanSpeed")
     ret = fn(handle, minSpeed, maxSpeed)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceGetFanControlPolicy_v2(handle, fan, fanControlPolicy):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetFanControlPolicy_v2")
     ret = fn(handle, fan, fanControlPolicy)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceSetFanControlPolicy(handle, fan, fanControlPolicy):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetFanControlPolicy")
     ret = fn(handle, fan, _nvmlFanControlPolicy_t(fanControlPolicy))
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceGetTemperature(handle, sensor):
     c_temp = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetTemperature")
     ret = fn(handle, _nvmlTemperatureSensors_t(sensor), byref(c_temp))
     _nvmlCheckReturn(ret)
     return c_temp.value
 
-
 def nvmlDeviceGetTemperatureThreshold(handle, threshold):
     c_temp = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetTemperatureThreshold")
     ret = fn(handle, _nvmlTemperatureThresholds_t(threshold), byref(c_temp))
     _nvmlCheckReturn(ret)
     return c_temp.value
 
-
 def nvmlDeviceSetTemperatureThreshold(handle, threshold, temp):
     c_temp = c_uint()
     c_temp.value = temp
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetTemperatureThreshold")
     ret = fn(handle, _nvmlTemperatureThresholds_t(threshold), byref(c_temp))
     _nvmlCheckReturn(ret)
     return None
 
-
 # DEPRECATED use nvmlDeviceGetPerformanceState
 def nvmlDeviceGetPowerState(handle):
     c_pstate = _nvmlPstates_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPowerState")
     ret = fn(handle, byref(c_pstate))
     _nvmlCheckReturn(ret)
     return c_pstate.value
 
-
 def nvmlDeviceGetPerformanceState(handle):
     c_pstate = _nvmlPstates_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPerformanceState")
     ret = fn(handle, byref(c_pstate))
     _nvmlCheckReturn(ret)
     return c_pstate.value
 
-
 def nvmlDeviceGetPowerManagementMode(handle):
     c_pcapMode = _nvmlEnableState_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPowerManagementMode")
     ret = fn(handle, byref(c_pcapMode))
     _nvmlCheckReturn(ret)
     return c_pcapMode.value
 
-
 def nvmlDeviceGetPowerManagementLimit(handle):
     c_limit = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPowerManagementLimit")
     ret = fn(handle, byref(c_limit))
     _nvmlCheckReturn(ret)
     return c_limit.value
 
-
 # Added in 4.304
 def nvmlDeviceGetPowerManagementLimitConstraints(handle):
     c_minLimit = c_uint()
     c_maxLimit = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPowerManagementLimitConstraints")
     ret = fn(handle, byref(c_minLimit), byref(c_maxLimit))
     _nvmlCheckReturn(ret)
     return [c_minLimit.value, c_maxLimit.value]
 
-
 # Added in 4.304
 def nvmlDeviceGetPowerManagementDefaultLimit(handle):
     c_limit = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPowerManagementDefaultLimit")
     ret = fn(handle, byref(c_limit))
     _nvmlCheckReturn(ret)
     return c_limit.value
@@ -2584,211 +2583,202 @@
 def nvmlDeviceGetEnforcedPowerLimit(handle):
     c_limit = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetEnforcedPowerLimit")
     ret = fn(handle, byref(c_limit))
     _nvmlCheckReturn(ret)
     return c_limit.value
 
-
 def nvmlDeviceGetPowerUsage(handle):
     c_watts = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPowerUsage")
     ret = fn(handle, byref(c_watts))
     _nvmlCheckReturn(ret)
     return c_watts.value
 
-
 def nvmlDeviceGetTotalEnergyConsumption(handle):
     c_millijoules = c_uint64()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetTotalEnergyConsumption")
     ret = fn(handle, byref(c_millijoules))
     _nvmlCheckReturn(ret)
     return c_millijoules.value
 
-
 # Added in 4.304
 def nvmlDeviceGetGpuOperationMode(handle):
     c_currState = _nvmlGpuOperationMode_t()
     c_pendingState = _nvmlGpuOperationMode_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetGpuOperationMode")
     ret = fn(handle, byref(c_currState), byref(c_pendingState))
     _nvmlCheckReturn(ret)
     return [c_currState.value, c_pendingState.value]
 
-
 # Added in 4.304
 def nvmlDeviceGetCurrentGpuOperationMode(handle):
     return nvmlDeviceGetGpuOperationMode(handle)[0]
 
-
 # Added in 4.304
 def nvmlDeviceGetPendingGpuOperationMode(handle):
     return nvmlDeviceGetGpuOperationMode(handle)[1]
 
-
 def nvmlDeviceGetMemoryInfo(handle, version=None):
     if not version:
         c_memory = c_nvmlMemory_t()
         fn = _nvmlGetFunctionPointer("nvmlDeviceGetMemoryInfo")
     else:
         c_memory = c_nvmlMemory_v2_t()
         c_memory.version = version
         fn = _nvmlGetFunctionPointer("nvmlDeviceGetMemoryInfo_v2")
     ret = fn(handle, byref(c_memory))
     _nvmlCheckReturn(ret)
     return c_memory
 
-
 def nvmlDeviceGetBAR1MemoryInfo(handle):
     c_bar1_memory = c_nvmlBAR1Memory_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetBAR1MemoryInfo")
     ret = fn(handle, byref(c_bar1_memory))
     _nvmlCheckReturn(ret)
     return c_bar1_memory
 
-
 def nvmlDeviceGetComputeMode(handle):
     c_mode = _nvmlComputeMode_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetComputeMode")
     ret = fn(handle, byref(c_mode))
     _nvmlCheckReturn(ret)
     return c_mode.value
 
-
 def nvmlDeviceGetCudaComputeCapability(handle):
     c_major = c_int()
     c_minor = c_int()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetCudaComputeCapability")
     ret = fn(handle, byref(c_major), byref(c_minor))
     _nvmlCheckReturn(ret)
     return (c_major.value, c_minor.value)
 
-
 def nvmlDeviceGetEccMode(handle):
     c_currState = _nvmlEnableState_t()
     c_pendingState = _nvmlEnableState_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetEccMode")
     ret = fn(handle, byref(c_currState), byref(c_pendingState))
     _nvmlCheckReturn(ret)
     return [c_currState.value, c_pendingState.value]
 
-
 # added to API
 def nvmlDeviceGetCurrentEccMode(handle):
     return nvmlDeviceGetEccMode(handle)[0]
 
-
 # added to API
 def nvmlDeviceGetPendingEccMode(handle):
     return nvmlDeviceGetEccMode(handle)[1]
 
-
 def nvmlDeviceGetDefaultEccMode(handle):
     c_defaultState = _nvmlEnableState_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetDefaultEccMode")
     ret = fn(handle, byref(c_defaultState))
     _nvmlCheckReturn(ret)
     return [c_defaultState.value]
 
-
 def nvmlDeviceGetTotalEccErrors(handle, errorType, counterType):
     c_count = c_ulonglong()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetTotalEccErrors")
     ret = fn(handle, _nvmlMemoryErrorType_t(errorType),
-             _nvmlEccCounterType_t(counterType), byref(c_count))
+                 _nvmlEccCounterType_t(counterType), byref(c_count))
     _nvmlCheckReturn(ret)
     return c_count.value
 
-
 # This is deprecated, instead use nvmlDeviceGetMemoryErrorCounter
 def nvmlDeviceGetDetailedEccErrors(handle, errorType, counterType):
     c_counts = c_nvmlEccErrorCounts_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetDetailedEccErrors")
     ret = fn(handle, _nvmlMemoryErrorType_t(errorType),
-             _nvmlEccCounterType_t(counterType), byref(c_counts))
+                 _nvmlEccCounterType_t(counterType), byref(c_counts))
     _nvmlCheckReturn(ret)
     return c_counts
 
-
 # Added in 4.304
 def nvmlDeviceGetMemoryErrorCounter(handle, errorType, counterType, locationType):
     c_count = c_ulonglong()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMemoryErrorCounter")
     ret = fn(handle,
              _nvmlMemoryErrorType_t(errorType),
              _nvmlEccCounterType_t(counterType),
              _nvmlMemoryLocation_t(locationType),
              byref(c_count))
     _nvmlCheckReturn(ret)
     return c_count.value
 
-
 def nvmlDeviceGetUtilizationRates(handle):
     c_util = c_nvmlUtilization_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetUtilizationRates")
     ret = fn(handle, byref(c_util))
     _nvmlCheckReturn(ret)
     return c_util
 
-
 def nvmlDeviceGetEncoderUtilization(handle):
     c_util = c_uint()
     c_samplingPeriod = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetEncoderUtilization")
     ret = fn(handle, byref(c_util), byref(c_samplingPeriod))
     _nvmlCheckReturn(ret)
     return [c_util.value, c_samplingPeriod.value]
 
-
 def nvmlDeviceGetDecoderUtilization(handle):
     c_util = c_uint()
     c_samplingPeriod = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetDecoderUtilization")
     ret = fn(handle, byref(c_util), byref(c_samplingPeriod))
     _nvmlCheckReturn(ret)
     return [c_util.value, c_samplingPeriod.value]
 
+def nvmlDeviceGetJpgUtilization(handle):
+    c_util = c_uint()
+    c_samplingPeriod = c_uint()
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetJpgUtilization")
+    ret = fn(handle, byref(c_util), byref(c_samplingPeriod))
+    _nvmlCheckReturn(ret)
+    return [c_util.value, c_samplingPeriod.value]
+
+def nvmlDeviceGetOfaUtilization(handle):
+    c_util = c_uint()
+    c_samplingPeriod = c_uint()
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetOfaUtilization")
+    ret = fn(handle, byref(c_util), byref(c_samplingPeriod))
+    _nvmlCheckReturn(ret)
+    return [c_util.value, c_samplingPeriod.value]
 
 def nvmlDeviceGetPcieReplayCounter(handle):
     c_replay = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPcieReplayCounter")
     ret = fn(handle, byref(c_replay))
     _nvmlCheckReturn(ret)
     return c_replay.value
 
-
 def nvmlDeviceGetDriverModel(handle):
     c_currModel = _nvmlDriverModel_t()
     c_pendingModel = _nvmlDriverModel_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetDriverModel")
     ret = fn(handle, byref(c_currModel), byref(c_pendingModel))
     _nvmlCheckReturn(ret)
     return [c_currModel.value, c_pendingModel.value]
 
-
 # added to API
 def nvmlDeviceGetCurrentDriverModel(handle):
     return nvmlDeviceGetDriverModel(handle)[0]
 
-
 # added to API
 def nvmlDeviceGetPendingDriverModel(handle):
     return nvmlDeviceGetDriverModel(handle)[1]
 
-
 # Added in 2.285
 @convertStrBytes
 def nvmlDeviceGetVbiosVersion(handle):
     c_version = create_string_buffer(NVML_DEVICE_VBIOS_VERSION_BUFFER_SIZE)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetVbiosVersion")
     ret = fn(handle, c_version, c_uint(NVML_DEVICE_VBIOS_VERSION_BUFFER_SIZE))
     _nvmlCheckReturn(ret)
     return c_version.value
 
-
 # Added in 2.285
 def nvmlDeviceGetComputeRunningProcesses_v3(handle):
     # first call to get the size
     c_count = c_uint(0)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetComputeRunningProcesses_v3")
     ret = fn(handle, byref(c_count), None)
 
@@ -2816,19 +2806,17 @@
             procs.append(obj)
 
         return procs
     else:
         # error case
         raise NVMLError(ret)
 
-
 def nvmlDeviceGetComputeRunningProcesses(handle):
     return nvmlDeviceGetComputeRunningProcesses_v3(handle)
 
-
 def nvmlDeviceGetGraphicsRunningProcesses_v3(handle):
     # first call to get the size
     c_count = c_uint(0)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetGraphicsRunningProcesses_v3")
     ret = fn(handle, byref(c_count), None)
 
     if (ret == NVML_SUCCESS):
@@ -2855,23 +2843,20 @@
             procs.append(obj)
 
         return procs
     else:
         # error case
         raise NVMLError(ret)
 
-
 def nvmlDeviceGetGraphicsRunningProcesses(handle):
     return nvmlDeviceGetGraphicsRunningProcesses_v3(handle)
 
-
 def nvmlDeviceGetMPSComputeRunningProcesses(handle):
     return nvmlDeviceGetMPSComputeRunningProcesses_v3(handle)
 
-
 def nvmlDeviceGetMPSComputeRunningProcesses_v3(handle):
     # first call to get the size
     c_count = c_uint(0)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMPSComputeRunningProcesses_v3")
     ret = fn(handle, byref(c_count), None)
 
     if (ret == NVML_SUCCESS):
@@ -2898,409 +2883,412 @@
             procs.append(obj)
 
         return procs
     else:
         # error case
         raise NVMLError(ret)
 
+def nvmlDeviceGetRunningProcessDetailList(handle, version, mode):
+    c_processDetailList = c_nvmlProcessDetailList_t()
+    c_processDetailList.version = version
+    c_processDetailList.mode = mode
+
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetRunningProcessDetailList")
+
+    # first call to get the size
+    ret = fn(handle, byref(c_processDetailList))
+    if (ret == NVML_SUCCESS):
+        # special case, no running processes
+        return []
+    elif (ret == NVML_ERROR_INSUFFICIENT_SIZE):
+        c_procs = c_nvmlProcessDetail_v1_t * c_processDetailList.numProcArrayEntries
+        c_processDetailList.procArray = cast((c_procs)(), POINTER(c_nvmlProcessDetail_v1_t))
+
+        # make the call again
+        ret = fn(handle, byref(c_processDetailList))
+        _nvmlCheckReturn(ret)
+
+        procs = []
+        for i in range(c_processDetailList.numProcArrayEntries):
+            # use an alternative struct for this object
+            obj = c_processDetailList.procArray[i]
+            if (obj.usedGpuMemory == NVML_VALUE_NOT_AVAILABLE_ulonglong.value):
+                obj.usedGpuMemory = None
+            if (obj.usedGpuCcProtectedMemory == NVML_VALUE_NOT_AVAILABLE_ulonglong.value):
+                obj.usedGpuCcProtectedMemory = None
+            procs.append(obj)
+
+        return procs
+    else:
+        # error case
+        raise NVMLError(ret)
 
 def nvmlDeviceGetAutoBoostedClocksEnabled(handle):
     c_isEnabled = _nvmlEnableState_t()
     c_defaultIsEnabled = _nvmlEnableState_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetAutoBoostedClocksEnabled")
     ret = fn(handle, byref(c_isEnabled), byref(c_defaultIsEnabled))
     _nvmlCheckReturn(ret)
     return [c_isEnabled.value, c_defaultIsEnabled.value]
-    # Throws NVML_ERROR_NOT_SUPPORTED if hardware doesn't support setting auto boosted clocks
-
+    #Throws NVML_ERROR_NOT_SUPPORTED if hardware doesn't support setting auto boosted clocks
 
 ## Set functions
 def nvmlUnitSetLedState(unit, color):
     fn = _nvmlGetFunctionPointer("nvmlUnitSetLedState")
     ret = fn(unit, _nvmlLedColor_t(color))
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceSetPersistenceMode(handle, mode):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetPersistenceMode")
     ret = fn(handle, _nvmlEnableState_t(mode))
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceSetComputeMode(handle, mode):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetComputeMode")
     ret = fn(handle, _nvmlComputeMode_t(mode))
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceSetEccMode(handle, mode):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetEccMode")
     ret = fn(handle, _nvmlEnableState_t(mode))
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceClearEccErrorCounts(handle, counterType):
     fn = _nvmlGetFunctionPointer("nvmlDeviceClearEccErrorCounts")
     ret = fn(handle, _nvmlEccCounterType_t(counterType))
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceSetDriverModel(handle, model):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetDriverModel")
     ret = fn(handle, _nvmlDriverModel_t(model))
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceSetAutoBoostedClocksEnabled(handle, enabled):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetAutoBoostedClocksEnabled")
     ret = fn(handle, _nvmlEnableState_t(enabled))
     _nvmlCheckReturn(ret)
     return None
-    # Throws NVML_ERROR_NOT_SUPPORTED if hardware doesn't support setting auto boosted clocks
-
+    #Throws NVML_ERROR_NOT_SUPPORTED if hardware doesn't support setting auto boosted clocks
 
 def nvmlDeviceSetDefaultAutoBoostedClocksEnabled(handle, enabled, flags):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetDefaultAutoBoostedClocksEnabled")
     ret = fn(handle, _nvmlEnableState_t(enabled), c_uint(flags))
     _nvmlCheckReturn(ret)
     return None
-    # Throws NVML_ERROR_NOT_SUPPORTED if hardware doesn't support setting auto boosted clocks
-
+    #Throws NVML_ERROR_NOT_SUPPORTED if hardware doesn't support setting auto boosted clocks
 
 def nvmlDeviceSetGpuLockedClocks(handle, minGpuClockMHz, maxGpuClockMHz):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetGpuLockedClocks")
     ret = fn(handle, c_uint(minGpuClockMHz), c_uint(maxGpuClockMHz))
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceResetGpuLockedClocks(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceResetGpuLockedClocks")
     ret = fn(handle)
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceSetMemoryLockedClocks(handle, minMemClockMHz, maxMemClockMHz):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetMemoryLockedClocks")
     ret = fn(handle, c_uint(minMemClockMHz), c_uint(maxMemClockMHz))
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceResetMemoryLockedClocks(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceResetMemoryLockedClocks")
     ret = fn(handle)
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceGetClkMonStatus(handle, c_clkMonInfo):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetClkMonStatus")
     ret = fn(handle, c_clkMonInfo)
     return ret
 
-
 # Added in 4.304
 def nvmlDeviceSetApplicationsClocks(handle, maxMemClockMHz, maxGraphicsClockMHz):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetApplicationsClocks")
     ret = fn(handle, c_uint(maxMemClockMHz), c_uint(maxGraphicsClockMHz))
     _nvmlCheckReturn(ret)
     return None
 
-
 # Added in 4.304
 def nvmlDeviceResetApplicationsClocks(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceResetApplicationsClocks")
     ret = fn(handle)
     _nvmlCheckReturn(ret)
     return None
 
-
 # Added in 4.304
 def nvmlDeviceSetPowerManagementLimit(handle, limit):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetPowerManagementLimit")
     ret = fn(handle, c_uint(limit))
     _nvmlCheckReturn(ret)
     return None
 
-
 # Added in 4.304
 def nvmlDeviceSetGpuOperationMode(handle, mode):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetGpuOperationMode")
     ret = fn(handle, _nvmlGpuOperationMode_t(mode))
     _nvmlCheckReturn(ret)
     return None
 
-
 # Added in 2.285
 def nvmlEventSetCreate():
     fn = _nvmlGetFunctionPointer("nvmlEventSetCreate")
     eventSet = c_nvmlEventSet_t()
     ret = fn(byref(eventSet))
     _nvmlCheckReturn(ret)
     return eventSet
 
-
 # Added in 2.285
 def nvmlDeviceRegisterEvents(handle, eventTypes, eventSet):
     fn = _nvmlGetFunctionPointer("nvmlDeviceRegisterEvents")
     ret = fn(handle, c_ulonglong(eventTypes), eventSet)
     _nvmlCheckReturn(ret)
     return None
 
-
 # Added in 2.285
 def nvmlDeviceGetSupportedEventTypes(handle):
     c_eventTypes = c_ulonglong()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetSupportedEventTypes")
     ret = fn(handle, byref(c_eventTypes))
     _nvmlCheckReturn(ret)
     return c_eventTypes.value
 
-
 # raises NVML_ERROR_TIMEOUT exception on timeout
 def nvmlEventSetWait_v2(eventSet, timeoutms):
     fn = _nvmlGetFunctionPointer("nvmlEventSetWait_v2")
     data = c_nvmlEventData_t()
     ret = fn(eventSet, byref(data), c_uint(timeoutms))
     _nvmlCheckReturn(ret)
     return data
 
-
 def nvmlEventSetWait(eventSet, timeoutms):
     return nvmlEventSetWait_v2(eventSet, timeoutms)
 
-
 # Added in 2.285
 def nvmlEventSetFree(eventSet):
     fn = _nvmlGetFunctionPointer("nvmlEventSetFree")
     ret = fn(eventSet)
     _nvmlCheckReturn(ret)
     return None
 
-
 # Added in 3.295
 def nvmlDeviceOnSameBoard(handle1, handle2):
     fn = _nvmlGetFunctionPointer("nvmlDeviceOnSameBoard")
     onSameBoard = c_int()
     ret = fn(handle1, handle2, byref(onSameBoard))
     _nvmlCheckReturn(ret)
     return (onSameBoard.value != 0)
 
-
 # Added in 3.295
 def nvmlDeviceGetCurrPcieLinkGeneration(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetCurrPcieLinkGeneration")
     gen = c_uint()
     ret = fn(handle, byref(gen))
     _nvmlCheckReturn(ret)
     return gen.value
 
-
 # Added in 3.295
 def nvmlDeviceGetMaxPcieLinkGeneration(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMaxPcieLinkGeneration")
     gen = c_uint()
     ret = fn(handle, byref(gen))
     _nvmlCheckReturn(ret)
     return gen.value
 
-
 # Added in 3.295
 def nvmlDeviceGetCurrPcieLinkWidth(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetCurrPcieLinkWidth")
     width = c_uint()
     ret = fn(handle, byref(width))
     _nvmlCheckReturn(ret)
     return width.value
 
-
 # Added in 3.295
 def nvmlDeviceGetMaxPcieLinkWidth(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMaxPcieLinkWidth")
     width = c_uint()
     ret = fn(handle, byref(width))
     _nvmlCheckReturn(ret)
     return width.value
 
-
 def nvmlDeviceGetGpuMaxPcieLinkGeneration(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetGpuMaxPcieLinkGeneration")
     gen = c_uint()
     ret = fn(handle, byref(gen))
     _nvmlCheckReturn(ret)
     return gen.value
 
-
 # Added in 4.304
 def nvmlDeviceGetSupportedClocksThrottleReasons(handle):
-    c_reasons = c_ulonglong()
+    c_reasons= c_ulonglong()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetSupportedClocksThrottleReasons")
     ret = fn(handle, byref(c_reasons))
     _nvmlCheckReturn(ret)
     return c_reasons.value
 
+def nvmlDeviceGetSupportedClocksEventReasons(handle):
+    c_reasons= c_ulonglong()
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetSupportedClocksEventReasons")
+    ret = fn(handle, byref(c_reasons))
+    _nvmlCheckReturn(ret)
+    return c_reasons.value
 
 # Added in 4.304
 def nvmlDeviceGetCurrentClocksThrottleReasons(handle):
-    c_reasons = c_ulonglong()
+    c_reasons= c_ulonglong()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetCurrentClocksThrottleReasons")
     ret = fn(handle, byref(c_reasons))
     _nvmlCheckReturn(ret)
     return c_reasons.value
 
+def nvmlDeviceGetCurrentClocksEventReasons(handle):
+    c_reasons= c_ulonglong()
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetCurrentClocksEventReasons")
+    ret = fn(handle, byref(c_reasons))
+    _nvmlCheckReturn(ret)
+    return c_reasons.value
 
 # Added in 5.319
 def nvmlDeviceGetIndex(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetIndex")
     c_index = c_uint()
     ret = fn(handle, byref(c_index))
     _nvmlCheckReturn(ret)
     return c_index.value
 
-
 # Added in 5.319
 def nvmlDeviceGetAccountingMode(handle):
     c_mode = _nvmlEnableState_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetAccountingMode")
     ret = fn(handle, byref(c_mode))
     _nvmlCheckReturn(ret)
     return c_mode.value
 
-
 def nvmlDeviceSetAccountingMode(handle, mode):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetAccountingMode")
     ret = fn(handle, _nvmlEnableState_t(mode))
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceClearAccountingPids(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceClearAccountingPids")
     ret = fn(handle)
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceGetAccountingStats(handle, pid):
     stats = c_nvmlAccountingStats_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetAccountingStats")
     ret = fn(handle, c_uint(pid), byref(stats))
     _nvmlCheckReturn(ret)
     if (stats.maxMemoryUsage == NVML_VALUE_NOT_AVAILABLE_ulonglong.value):
         # special case for WDDM on Windows, see comment above
         stats.maxMemoryUsage = None
     return stats
 
-
 def nvmlDeviceGetAccountingPids(handle):
     count = c_uint(nvmlDeviceGetAccountingBufferSize(handle))
     pids = (c_uint * count.value)()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetAccountingPids")
     ret = fn(handle, byref(count), pids)
     _nvmlCheckReturn(ret)
     return list(map(int, pids[0:count.value]))
 
-
 def nvmlDeviceGetAccountingBufferSize(handle):
     bufferSize = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetAccountingBufferSize")
     ret = fn(handle, byref(bufferSize))
     _nvmlCheckReturn(ret)
     return int(bufferSize.value)
 
-
 def nvmlDeviceGetRetiredPages(device, sourceFilter):
     c_source = _nvmlPageRetirementCause_t(sourceFilter)
     c_count = c_uint(0)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetRetiredPages")
 
     # First call will get the size
     ret = fn(device, c_source, byref(c_count), None)
 
     # this should only fail with insufficient size
     if ((ret != NVML_SUCCESS) and
-            (ret != NVML_ERROR_INSUFFICIENT_SIZE)):
+        (ret != NVML_ERROR_INSUFFICIENT_SIZE)):
         raise NVMLError(ret)
 
     # call again with a buffer
     # oversize the array for the rare cases where additional pages
     # are retired between NVML calls
     c_count.value = c_count.value * 2 + 5
     page_array = c_ulonglong * c_count.value
     c_pages = page_array()
     ret = fn(device, c_source, byref(c_count), c_pages)
     _nvmlCheckReturn(ret)
     return list(map(int, c_pages[0:c_count.value]))
 
-
 def nvmlDeviceGetRetiredPages_v2(device, sourceFilter):
     c_source = _nvmlPageRetirementCause_t(sourceFilter)
     c_count = c_uint(0)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetRetiredPages_v2")
 
     # First call will get the size
     ret = fn(device, c_source, byref(c_count), None)
 
     # this should only fail with insufficient size
     if ((ret != NVML_SUCCESS) and
-            (ret != NVML_ERROR_INSUFFICIENT_SIZE)):
+        (ret != NVML_ERROR_INSUFFICIENT_SIZE)):
         raise NVMLError(ret)
 
     # call again with a buffer
     # oversize the array for the rare cases where additional pages
     # are retired between NVML calls
     c_count.value = c_count.value * 2 + 5
     page_array = c_ulonglong * c_count.value
     c_pages = page_array()
     times_array = c_ulonglong * c_count.value
     c_times = times_array()
     ret = fn(device, c_source, byref(c_count), c_pages, c_times)
     _nvmlCheckReturn(ret)
-    return [{'address': int(c_pages[i]), 'timestamp': int(c_times[i])} for i in range(c_count.value)]
-
+    return [ { 'address': int(c_pages[i]), 'timestamp': int(c_times[i]) } for i in range(c_count.value) ];
 
 def nvmlDeviceGetRetiredPagesPendingStatus(device):
     c_pending = _nvmlEnableState_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetRetiredPagesPendingStatus")
     ret = fn(device, byref(c_pending))
     _nvmlCheckReturn(ret)
     return int(c_pending.value)
 
-
 def nvmlDeviceGetAPIRestriction(device, apiType):
     c_permission = _nvmlEnableState_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetAPIRestriction")
     ret = fn(device, _nvmlRestrictedAPI_t(apiType), byref(c_permission))
     _nvmlCheckReturn(ret)
     return int(c_permission.value)
 
-
 def nvmlDeviceSetAPIRestriction(handle, apiType, isRestricted):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetAPIRestriction")
     ret = fn(handle, _nvmlRestrictedAPI_t(apiType), _nvmlEnableState_t(isRestricted))
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceGetBridgeChipInfo(handle):
     bridgeHierarchy = c_nvmlBridgeChipHierarchy_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetBridgeChipInfo")
     ret = fn(handle, byref(bridgeHierarchy))
     _nvmlCheckReturn(ret)
     return bridgeHierarchy
 
-
 def nvmlDeviceGetSamples(device, sampling_type, timeStamp):
     c_sampling_type = _nvmlSamplingType_t(sampling_type)
     c_time_stamp = c_ulonglong(timeStamp)
     c_sample_count = c_uint(0)
     c_sample_value_type = _nvmlValueType_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetSamples")
 
@@ -3309,38 +3297,35 @@
 
     # Stop if this fails
     if (ret != NVML_SUCCESS):
         raise NVMLError(ret)
 
     sampleArray = c_sample_count.value * c_nvmlSample_t
     c_samples = sampleArray()
-    ret = fn(device, c_sampling_type, c_time_stamp, byref(c_sample_value_type), byref(c_sample_count), c_samples)
+    ret = fn(device, c_sampling_type, c_time_stamp,  byref(c_sample_value_type), byref(c_sample_count), c_samples)
     _nvmlCheckReturn(ret)
     return (c_sample_value_type.value, c_samples[0:c_sample_count.value])
 
-
 def nvmlDeviceGetViolationStatus(device, perfPolicyType):
     c_perfPolicy_type = _nvmlPerfPolicyType_t(perfPolicyType)
     c_violTime = c_nvmlViolationTime_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetViolationStatus")
 
     ## Invoke the method to get violation time
     ret = fn(device, c_perfPolicy_type, byref(c_violTime))
     _nvmlCheckReturn(ret)
     return c_violTime
 
-
 def nvmlDeviceGetPcieThroughput(device, counter):
     c_util = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPcieThroughput")
     ret = fn(device, _nvmlPcieUtilCounter_t(counter), byref(c_util))
     _nvmlCheckReturn(ret)
     return c_util.value
 
-
 def nvmlSystemGetTopologyGpuSet(cpuNumber):
     c_count = c_uint(0)
     fn = _nvmlGetFunctionPointer("nvmlSystemGetTopologyGpuSet")
 
     # First call will get the size
     ret = fn(cpuNumber, byref(c_count), None)
 
@@ -3349,15 +3334,14 @@
     # call again with a buffer
     device_array = c_nvmlDevice_t * c_count.value
     c_devices = device_array()
     ret = fn(cpuNumber, byref(c_count), c_devices)
     _nvmlCheckReturn(ret)
     return list(c_devices[0:c_count.value])
 
-
 def nvmlDeviceGetTopologyNearestGpus(device, level):
     c_count = c_uint(0)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetTopologyNearestGpus")
 
     # First call will get the size
     ret = fn(device, level, byref(c_count), None)
 
@@ -3367,145 +3351,127 @@
     # call again with a buffer
     device_array = c_nvmlDevice_t * c_count.value
     c_devices = device_array()
     ret = fn(device, level, byref(c_count), c_devices)
     _nvmlCheckReturn(ret)
     return list(c_devices[0:c_count.value])
 
-
 def nvmlDeviceGetTopologyCommonAncestor(device1, device2):
     c_level = _nvmlGpuTopologyLevel_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetTopologyCommonAncestor")
     ret = fn(device1, device2, byref(c_level))
     _nvmlCheckReturn(ret)
     return c_level.value
 
-
 def nvmlDeviceGetNvLinkUtilizationCounter(device, link, counter):
     c_rxcounter = c_ulonglong()
     c_txcounter = c_ulonglong()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetNvLinkUtilizationCounter")
     ret = fn(device, link, counter, byref(c_rxcounter), byref(c_txcounter))
     _nvmlCheckReturn(ret)
     return (c_rxcounter.value, c_txcounter.value)
 
-
 def nvmlDeviceFreezeNvLinkUtilizationCounter(device, link, counter, freeze):
     fn = _nvmlGetFunctionPointer("nvmlDeviceFreezeNvLinkUtilizationCounter")
     ret = fn(device, link, counter, freeze)
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceResetNvLinkUtilizationCounter(device, link, counter):
     fn = _nvmlGetFunctionPointer("nvmlDeviceResetNvLinkUtilizationCounter")
     ret = fn(device, link, counter)
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceSetNvLinkUtilizationControl(device, link, counter, control, reset):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetNvLinkUtilizationControl")
     ret = fn(device, link, counter, byref(control), reset)
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceGetNvLinkUtilizationControl(device, link, counter):
     c_control = nvmlNvLinkUtilizationControl_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetNvLinkUtilizationControl")
     ret = fn(device, link, counter, byref(c_control))
     _nvmlCheckReturn(ret)
     return c_control
 
-
 def nvmlDeviceGetNvLinkCapability(device, link, capability):
     c_capResult = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetNvLinkCapability")
     ret = fn(device, link, capability, byref(c_capResult))
     _nvmlCheckReturn(ret)
     return c_capResult.value
 
-
 def nvmlDeviceGetNvLinkErrorCounter(device, link, counter):
     c_result = c_ulonglong()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetNvLinkErrorCounter")
     ret = fn(device, link, counter, byref(c_result))
     _nvmlCheckReturn(ret)
     return c_result.value
 
-
 def nvmlDeviceResetNvLinkErrorCounters(device, link):
     fn = _nvmlGetFunctionPointer("nvmlDeviceResetNvLinkErrorCounters")
     ret = fn(device, link)
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceGetNvLinkRemotePciInfo(device, link):
     c_pci = nvmlPciInfo_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetNvLinkRemotePciInfo_v2")
     ret = fn(device, link, byref(c_pci))
     _nvmlCheckReturn(ret)
     return c_pci
 
-
 def nvmlDeviceGetNvLinkRemoteDeviceType(handle, link):
     c_type = _nvmlNvLinkDeviceType_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetNvLinkRemoteDeviceType")
     ret = fn(handle, link, byref(c_type))
     _nvmlCheckReturn(ret)
     return c_type.value
 
-
 def nvmlDeviceGetNvLinkState(device, link):
     c_isActive = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetNvLinkState")
     ret = fn(device, link, byref(c_isActive))
     _nvmlCheckReturn(ret)
     return c_isActive.value
 
-
 def nvmlDeviceGetNvLinkVersion(device, link):
     c_version = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetNvLinkVersion")
     ret = fn(device, link, byref(c_version))
     _nvmlCheckReturn(ret)
     return c_version.value
 
-
 def nvmlDeviceModifyDrainState(pciInfo, newState):
     fn = _nvmlGetFunctionPointer("nvmlDeviceModifyDrainState")
     ret = fn(pointer(pciInfo), newState)
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceQueryDrainState(pciInfo):
     c_newState = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceQueryDrainState")
     ret = fn(pointer(pciInfo), byref(c_newState))
     _nvmlCheckReturn(ret)
     return c_newState.value
 
-
 def nvmlDeviceRemoveGpu(pciInfo):
     fn = _nvmlGetFunctionPointer("nvmlDeviceRemoveGpu")
     ret = fn(pointer(pciInfo))
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceDiscoverGpus(pciInfo):
     fn = _nvmlGetFunctionPointer("nvmlDeviceDiscoverGpus")
     ret = fn(pointer(pciInfo))
     _nvmlCheckReturn(ret)
     return None
 
-
 def nvmlDeviceGetFieldValues(handle, fieldIds):
     values_arr = c_nvmlFieldValue_t * len(fieldIds)
     values = values_arr()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetFieldValues")
 
     for i, fieldId in enumerate(fieldIds):
         try:
@@ -3513,15 +3479,14 @@
         except TypeError:
             values[i].fieldId = fieldId
 
     ret = fn(handle, c_int32(len(fieldIds)), byref(values))
     _nvmlCheckReturn(ret)
     return values
 
-
 def nvmlDeviceClearFieldValues(handle, fieldIds):
     values_arr = c_nvmlFieldValue_t * len(fieldIds)
     values = values_arr()
     fn = _nvmlGetFunctionPointer("nvmlDeviceClearFieldValues")
 
     for i, fieldId in enumerate(fieldIds):
         try:
@@ -3529,49 +3494,44 @@
         except TypeError:
             values[i].fieldId = fieldId
 
     ret = fn(handle, c_int32(len(fieldIds)), byref(values))
     _nvmlCheckReturn(ret)
     return values
 
-
 def nvmlDeviceGetVirtualizationMode(handle):
     c_virtualization_mode = c_ulonglong()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetVirtualizationMode")
     ret = fn(handle, byref(c_virtualization_mode))
     _nvmlCheckReturn(ret)
     return c_virtualization_mode.value
 
-
 def nvmlDeviceSetVirtualizationMode(handle, virtualization_mode):
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetVirtualizationMode")
     return fn(handle, virtualization_mode)
 
-
 def nvmlGetVgpuDriverCapabilities(capability):
     c_capResult = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlGetVgpuDriverCapabilities")
     ret = fn(_nvmlVgpuDriverCapability_t(capability), byref(c_capResult))
     _nvmlCheckReturn(ret)
     return c_capResult.value
 
-
 def nvmlDeviceGetVgpuCapabilities(handle, capability):
     c_capResult = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetVgpuCapabilities")
     ret = fn(handle, _nvmlDeviceVgpuCapability_t(capability), byref(c_capResult))
     _nvmlCheckReturn(ret)
     return c_capResult.value
 
-
 def nvmlDeviceGetSupportedVgpus(handle):
     # first call to get the size
     c_vgpu_count = c_uint(0)
 
-    fn = _nvmlGetFunctionPointer("nvmlDeviceGetSupportedVgpus")
+    fn =  _nvmlGetFunctionPointer("nvmlDeviceGetSupportedVgpus")
     ret = fn(handle, byref(c_vgpu_count), None)
 
     if (ret == NVML_SUCCESS):
         # special case, no supported vGPUs
         return []
     elif (ret == NVML_ERROR_INSUFFICIENT_SIZE):
         # typical case
@@ -3585,20 +3545,19 @@
         for i in range(c_vgpu_count.value):
             vgpus.append(c_vgpu_type_ids[i])
         return vgpus
     else:
         # error case
         raise NVMLError(ret)
 
-
 def nvmlDeviceGetCreatableVgpus(handle):
     # first call to get the size
     c_vgpu_count = c_uint(0)
 
-    fn = _nvmlGetFunctionPointer("nvmlDeviceGetCreatableVgpus")
+    fn =  _nvmlGetFunctionPointer("nvmlDeviceGetCreatableVgpus")
     ret = fn(handle, byref(c_vgpu_count), None)
 
     if (ret == NVML_SUCCESS):
         # special case, no supported vGPUs
         return []
     elif (ret == NVML_ERROR_INSUFFICIENT_SIZE):
         # typical case
@@ -3612,116 +3571,104 @@
         for i in range(c_vgpu_count.value):
             vgpus.append(c_vgpu_type_ids[i])
         return vgpus
     else:
         # error case
         raise NVMLError(ret)
 
-
 def nvmlVgpuTypeGetGpuInstanceProfileId(vgpuTypeId):
     c_profile_id = c_uint(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuTypeGetGpuInstanceProfileId")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuTypeGetGpuInstanceProfileId")
     ret = fn(vgpuTypeId, byref(c_profile_id))
     _nvmlCheckReturn(ret)
     return (c_profile_id.value)
 
-
 @convertStrBytes
 def nvmlVgpuTypeGetClass(vgpuTypeId):
     c_class = create_string_buffer(NVML_DEVICE_NAME_BUFFER_SIZE)
     c_buffer_size = c_uint(NVML_DEVICE_NAME_BUFFER_SIZE)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuTypeGetClass")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuTypeGetClass")
     ret = fn(vgpuTypeId, c_class, byref(c_buffer_size))
     _nvmlCheckReturn(ret)
     return c_class.value
 
-
 @convertStrBytes
 def nvmlVgpuTypeGetName(vgpuTypeId):
     c_name = create_string_buffer(NVML_DEVICE_NAME_BUFFER_SIZE)
     c_buffer_size = c_uint(NVML_DEVICE_NAME_BUFFER_SIZE)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuTypeGetName")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuTypeGetName")
     ret = fn(vgpuTypeId, c_name, byref(c_buffer_size))
     _nvmlCheckReturn(ret)
     return c_name.value
 
-
 def nvmlVgpuTypeGetDeviceID(vgpuTypeId):
-    c_device_id = c_ulonglong(0)
+    c_device_id    = c_ulonglong(0)
     c_subsystem_id = c_ulonglong(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuTypeGetDeviceID")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuTypeGetDeviceID")
     ret = fn(vgpuTypeId, byref(c_device_id), byref(c_subsystem_id))
     _nvmlCheckReturn(ret)
     return (c_device_id.value, c_subsystem_id.value)
 
-
 def nvmlVgpuTypeGetFramebufferSize(vgpuTypeId):
     c_fb_size = c_ulonglong(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuTypeGetFramebufferSize")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuTypeGetFramebufferSize")
     ret = fn(vgpuTypeId, byref(c_fb_size))
     _nvmlCheckReturn(ret)
     return c_fb_size.value
 
-
 def nvmlVgpuTypeGetNumDisplayHeads(vgpuTypeId):
     c_num_heads = c_uint(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuTypeGetNumDisplayHeads")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuTypeGetNumDisplayHeads")
     ret = fn(vgpuTypeId, byref(c_num_heads))
     _nvmlCheckReturn(ret)
     return c_num_heads.value
 
-
 def nvmlVgpuTypeGetResolution(vgpuTypeId):
     c_xdim = c_uint(0)
     c_ydim = c_uint(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuTypeGetResolution")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuTypeGetResolution")
     ret = fn(vgpuTypeId, 0, byref(c_xdim), byref(c_ydim))
     _nvmlCheckReturn(ret)
     return (c_xdim.value, c_ydim.value)
 
-
 @convertStrBytes
 def nvmlVgpuTypeGetLicense(vgpuTypeId):
     c_license = create_string_buffer(NVML_GRID_LICENSE_BUFFER_SIZE)
     c_buffer_size = c_uint(NVML_GRID_LICENSE_BUFFER_SIZE)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuTypeGetLicense")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuTypeGetLicense")
     ret = fn(vgpuTypeId, c_license, c_buffer_size)
     _nvmlCheckReturn(ret)
     return c_license.value
 
-
 def nvmlVgpuTypeGetFrameRateLimit(vgpuTypeId):
     c_frl_config = c_uint(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuTypeGetFrameRateLimit")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuTypeGetFrameRateLimit")
     ret = fn(vgpuTypeId, byref(c_frl_config))
     _nvmlCheckReturn(ret)
     return c_frl_config.value
 
-
 def nvmlVgpuTypeGetMaxInstances(handle, vgpuTypeId):
     c_max_instances = c_uint(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuTypeGetMaxInstances")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuTypeGetMaxInstances")
     ret = fn(handle, vgpuTypeId, byref(c_max_instances))
     _nvmlCheckReturn(ret)
     return c_max_instances.value
 
-
 def nvmlVgpuTypeGetMaxInstancesPerVm(vgpuTypeId):
     c_max_instances_per_vm = c_uint(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuTypeGetMaxInstancesPerVm")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuTypeGetMaxInstancesPerVm")
     ret = fn(vgpuTypeId, byref(c_max_instances_per_vm))
     _nvmlCheckReturn(ret)
     return c_max_instances_per_vm.value
 
-
 def nvmlDeviceGetActiveVgpus(handle):
     # first call to get the size
     c_vgpu_count = c_uint(0)
 
-    fn = _nvmlGetFunctionPointer("nvmlDeviceGetActiveVgpus")
+    fn  = _nvmlGetFunctionPointer("nvmlDeviceGetActiveVgpus")
     ret = fn(handle, byref(c_vgpu_count), None)
 
     if (ret == NVML_SUCCESS):
         # special case, no active vGPUs
         return []
     elif (ret == NVML_ERROR_INSUFFICIENT_SIZE):
         # typical case
@@ -3735,153 +3682,136 @@
         for i in range(c_vgpu_count.value):
             vgpus.append(c_vgpu_instances[i])
         return vgpus
     else:
         # error case
         raise NVMLError(ret)
 
-
 @convertStrBytes
 def nvmlVgpuInstanceGetVmID(vgpuInstance):
     c_vm_id = create_string_buffer(NVML_DEVICE_UUID_BUFFER_SIZE)
     c_buffer_size = c_uint(NVML_GRID_LICENSE_BUFFER_SIZE)
-    c_vm_id_type = c_uint(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetVmID")
+    c_vm_id_type  = c_uint(0)
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetVmID")
     ret = fn(vgpuInstance, byref(c_vm_id), c_buffer_size, byref(c_vm_id_type))
     _nvmlCheckReturn(ret)
     return (c_vm_id.value, c_vm_id_type.value)
 
-
 @convertStrBytes
 def nvmlVgpuInstanceGetUUID(vgpuInstance):
     c_uuid = create_string_buffer(NVML_DEVICE_UUID_BUFFER_SIZE)
     c_buffer_size = c_uint(NVML_DEVICE_UUID_BUFFER_SIZE)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetUUID")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetUUID")
     ret = fn(vgpuInstance, byref(c_uuid), c_buffer_size)
     _nvmlCheckReturn(ret)
     return c_uuid.value
 
-
 @convertStrBytes
 def nvmlVgpuInstanceGetMdevUUID(vgpuInstance):
     c_uuid = create_string_buffer(NVML_DEVICE_UUID_BUFFER_SIZE)
     c_buffer_size = c_uint(NVML_DEVICE_UUID_BUFFER_SIZE)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetMdevUUID")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetMdevUUID")
     ret = fn(vgpuInstance, byref(c_uuid), c_buffer_size)
     _nvmlCheckReturn(ret)
     return c_uuid.value
 
-
 @convertStrBytes
 def nvmlVgpuInstanceGetVmDriverVersion(vgpuInstance):
     c_driver_version = create_string_buffer(NVML_SYSTEM_DRIVER_VERSION_BUFFER_SIZE)
     c_buffer_size = c_uint(NVML_SYSTEM_DRIVER_VERSION_BUFFER_SIZE)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetVmDriverVersion")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetVmDriverVersion")
     ret = fn(vgpuInstance, byref(c_driver_version), c_buffer_size)
     _nvmlCheckReturn(ret)
     return c_driver_version.value
 
-
 def nvmlVgpuInstanceGetLicenseStatus(vgpuInstance):
     c_license_status = c_uint(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetLicenseStatus")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetLicenseStatus")
     ret = fn(vgpuInstance, byref(c_license_status))
     _nvmlCheckReturn(ret)
     return c_license_status.value
 
-
 def nvmlVgpuInstanceGetLicenseInfo_v2(vgpuInstance):
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetLicenseInfo_v2")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetLicenseInfo_v2")
     c_license_info = c_nvmlVgpuLicenseInfo_t()
     ret = fn(vgpuInstance, byref(c_license_info))
     _nvmlCheckReturn(ret)
     return c_license_info
 
-
 def nvmlVgpuInstanceGetLicenseInfo(vgpuInstance):
     return nvmlVgpuInstanceGetLicenseInfo_v2(vgpuInstance)
 
-
 def nvmlVgpuInstanceGetFrameRateLimit(vgpuInstance):
     c_frl = c_uint(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetFrameRateLimit")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetFrameRateLimit")
     ret = fn(vgpuInstance, byref(c_frl))
     _nvmlCheckReturn(ret)
     return c_frl.value
 
-
 def nvmlVgpuInstanceGetEccMode(vgpuInstance):
     c_mode = _nvmlEnableState_t()
     fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetEccMode")
     ret = fn(vgpuInstance, byref(c_mode))
     _nvmlCheckReturn(ret)
     return c_mode.value
 
-
 def nvmlVgpuInstanceGetType(vgpuInstance):
     c_vgpu_type = c_uint(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetType")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetType")
     ret = fn(vgpuInstance, byref(c_vgpu_type))
     _nvmlCheckReturn(ret)
     return c_vgpu_type.value
 
-
 def nvmlVgpuInstanceGetEncoderCapacity(vgpuInstance):
     c_encoder_capacity = c_ulonglong(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetEncoderCapacity")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetEncoderCapacity")
     ret = fn(vgpuInstance, byref(c_encoder_capacity))
     _nvmlCheckReturn(ret)
     return c_encoder_capacity.value
 
-
 def nvmlVgpuInstanceSetEncoderCapacity(vgpuInstance, encoder_capacity):
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceSetEncoderCapacity")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceSetEncoderCapacity")
     return fn(vgpuInstance, encoder_capacity)
 
-
 def nvmlVgpuInstanceGetFbUsage(vgpuInstance):
     c_fb_usage = c_uint(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetFbUsage")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetFbUsage")
     ret = fn(vgpuInstance, byref(c_fb_usage))
     _nvmlCheckReturn(ret)
     return c_fb_usage.value
 
-
 def nvmlVgpuTypeGetCapabilities(vgpuTypeId, capability):
     c_cap_result = c_uint(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuTypeGetCapabilities")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuTypeGetCapabilities")
     ret = fn(vgpuTypeId, _nvmlVgpuCapability_t(capability), byref(c_cap_result))
     _nvmlCheckReturn(ret)
     return (c_cap_result.value)
 
-
 def nvmlVgpuInstanceGetGpuInstanceId(vgpuInstance):
     c_id = c_uint(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetGpuInstanceId")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetGpuInstanceId")
     ret = fn(vgpuInstance, byref(c_id))
     _nvmlCheckReturn(ret)
     return (c_id.value)
 
-
 @convertStrBytes
 def nvmlVgpuInstanceGetGpuPciId(vgpuInstance):
     c_vgpuPciId = create_string_buffer(NVML_DEVICE_PCI_BUS_ID_BUFFER_SIZE)
     fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetGpuPciId")
     ret = fn(vgpuInstance, c_vgpuPciId, byref(c_uint(NVML_DEVICE_PCI_BUS_ID_BUFFER_SIZE)))
     _nvmlCheckReturn(ret)
     return c_vgpuPciId.value
 
-
 def nvmlDeviceGetVgpuUtilization(handle, timeStamp):
     # first call to get the size
     c_vgpu_count = c_uint(0)
     c_time_stamp = c_ulonglong(timeStamp)
     c_sample_value_type = _nvmlValueType_t()
 
-    fn = _nvmlGetFunctionPointer("nvmlDeviceGetVgpuUtilization")
+    fn  = _nvmlGetFunctionPointer("nvmlDeviceGetVgpuUtilization")
     ret = fn(handle, c_time_stamp, byref(c_sample_value_type), byref(c_vgpu_count), None)
 
     if (ret == NVML_SUCCESS):
         # special case, no active vGPUs
         return []
     elif (ret == NVML_ERROR_INSUFFICIENT_SIZE):
         # typical case
@@ -3893,66 +3823,59 @@
         _nvmlCheckReturn(ret)
 
         return c_samples[0:c_vgpu_count.value]
     else:
         # error case
         raise NVMLError(ret)
 
-
 def nvmlDeviceGetP2PStatus(device1, device2, p2pIndex):
     c_p2pstatus = _nvmlGpuP2PStatus_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetP2PStatus")
-    ret = fn(device1, device2, p2pIndex, byref(c_p2pstatus))
+    ret = fn(device1, device2,p2pIndex, byref(c_p2pstatus))
     _nvmlCheckReturn(ret)
     return c_p2pstatus.value
 
-
 def nvmlDeviceGetGridLicensableFeatures_v4(handle):
     c_get_grid_licensable_features = c_nvmlGridLicensableFeatures_v4_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetGridLicensableFeatures_v4")
     ret = fn(handle, byref(c_get_grid_licensable_features))
     _nvmlCheckReturn(ret)
 
     return (c_get_grid_licensable_features)
 
-
 def nvmlDeviceGetGridLicensableFeatures(handle):
     return nvmlDeviceGetGridLicensableFeatures_v4(handle)
 
-
 def nvmlDeviceGetGspFirmwareVersion(handle, version):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetGspFirmwareVersion")
     ret = fn(handle, version)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceGetGspFirmwareMode(handle, isEnabled, defaultMode):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetGspFirmwareMode")
     ret = fn(handle, isEnabled, defaultMode)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceGetEncoderCapacity(handle, encoderQueryType):
     c_encoder_capacity = c_ulonglong(0)
     c_encoderQuery_type = _nvmlEncoderQueryType_t(encoderQueryType)
 
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetEncoderCapacity")
     ret = fn(handle, c_encoderQuery_type, byref(c_encoder_capacity))
     _nvmlCheckReturn(ret)
     return c_encoder_capacity.value
 
-
 def nvmlDeviceGetVgpuProcessUtilization(handle, timeStamp):
     # first call to get the size
     c_vgpu_count = c_uint(0)
     c_time_stamp = c_ulonglong(timeStamp)
 
-    fn = _nvmlGetFunctionPointer("nvmlDeviceGetVgpuProcessUtilization")
+    fn  = _nvmlGetFunctionPointer("nvmlDeviceGetVgpuProcessUtilization")
     ret = fn(handle, c_time_stamp, byref(c_vgpu_count), None)
 
     if (ret == NVML_SUCCESS):
         # special case, no active vGPUs
         return []
     elif (ret == NVML_ERROR_INSUFFICIENT_SIZE):
         # typical case
@@ -3964,30 +3887,28 @@
         _nvmlCheckReturn(ret)
 
         return c_samples[0:c_vgpu_count.value]
     else:
         # error case
         raise NVMLError(ret)
 
-
 def nvmlDeviceGetEncoderStats(handle):
     c_encoderCount = c_ulonglong(0)
     c_encodeFps = c_ulonglong(0)
     c_encoderLatency = c_ulonglong(0)
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetEncoderStats")
     ret = fn(handle, byref(c_encoderCount), byref(c_encodeFps), byref(c_encoderLatency))
     _nvmlCheckReturn(ret)
     return (c_encoderCount.value, c_encodeFps.value, c_encoderLatency.value)
 
-
 def nvmlDeviceGetEncoderSessions(handle):
     # first call to get the size
     c_session_count = c_uint(0)
 
-    fn = _nvmlGetFunctionPointer("nvmlDeviceGetEncoderSessions")
+    fn  = _nvmlGetFunctionPointer("nvmlDeviceGetEncoderSessions")
     ret = fn(handle, byref(c_session_count), None)
 
     if (ret == NVML_SUCCESS):
         if (c_session_count.value != 0):
             # typical case
             session_array = c_nvmlEncoderSession_t * c_session_count.value
             c_sessions = session_array()
@@ -4001,28 +3922,26 @@
             return sessions
         else:
             return []  # no active sessions
     else:
         # error case
         raise NVMLError(ret)
 
-
 def nvmlDeviceGetFBCStats(handle):
     c_fbcStats = c_nvmlFBCStats_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetFBCStats")
     ret = fn(handle, byref(c_fbcStats))
     _nvmlCheckReturn(ret)
     return c_fbcStats
 
-
 def nvmlDeviceGetFBCSessions(handle):
     # first call to get the size
     c_session_count = c_uint(0)
 
-    fn = _nvmlGetFunctionPointer("nvmlDeviceGetFBCSessions")
+    fn  = _nvmlGetFunctionPointer("nvmlDeviceGetFBCSessions")
     ret = fn(handle, byref(c_session_count), None)
 
     if (ret == NVML_SUCCESS):
         if (c_session_count.value != 0):
             # typical case
             session_array = c_nvmlFBCSession_t * c_session_count.value
             c_sessions = session_array()
@@ -4036,30 +3955,28 @@
             return sessions
         else:
             return []  # no active sessions
     else:
         # error case
         raise NVMLError(ret)
 
-
 def nvmlVgpuInstanceGetEncoderStats(vgpuInstance):
-    c_encoderCount = c_ulonglong(0)
-    c_encodeFps = c_ulonglong(0)
-    c_encoderLatency = c_ulonglong(0)
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetEncoderStats")
+    c_encoderCount    = c_ulonglong(0)
+    c_encodeFps       = c_ulonglong(0)
+    c_encoderLatency  = c_ulonglong(0)
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetEncoderStats")
     ret = fn(vgpuInstance, byref(c_encoderCount), byref(c_encodeFps), byref(c_encoderLatency))
     _nvmlCheckReturn(ret)
     return (c_encoderCount.value, c_encodeFps.value, c_encoderLatency.value)
 
-
 def nvmlVgpuInstanceGetEncoderSessions(vgpuInstance):
     # first call to get the size
     c_session_count = c_uint(0)
 
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetEncoderSessions")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetEncoderSessions")
     ret = fn(vgpuInstance, byref(c_session_count), None)
 
     if (ret == NVML_SUCCESS):
         if (c_session_count.value != 0):
             # typical case
             session_array = c_nvmlEncoderSession_t * c_session_count.value
             c_sessions = session_array()
@@ -4073,28 +3990,26 @@
             return sessions
         else:
             return []  # no active sessions
     else:
         # error case
         raise NVMLError(ret)
 
-
 def nvmlVgpuInstanceGetFBCStats(vgpuInstance):
     c_fbcStats = c_nvmlFBCStats_t()
     fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetFBCStats")
     ret = fn(vgpuInstance, byref(c_fbcStats))
     _nvmlCheckReturn(ret)
     return c_fbcStats
 
-
 def nvmlVgpuInstanceGetFBCSessions(vgpuInstance):
     # first call to get the size
     c_session_count = c_uint(0)
 
-    fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetFBCSessions")
+    fn  = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetFBCSessions")
     ret = fn(vgpuInstance, byref(c_session_count), None)
 
     if (ret == NVML_SUCCESS):
         if (c_session_count.value != 0):
             # typical case
             session_array = c_nvmlFBCSession_t * c_session_count.value
             c_sessions = session_array()
@@ -4108,21 +4023,20 @@
             return sessions
         else:
             return []  # no active sessions
     else:
         # error case
         raise NVMLError(ret)
 
-
 def nvmlDeviceGetProcessUtilization(handle, timeStamp):
     # first call to get the size
     c_count = c_uint(0)
     c_time_stamp = c_ulonglong(timeStamp)
 
-    fn = _nvmlGetFunctionPointer("nvmlDeviceGetProcessUtilization")
+    fn  = _nvmlGetFunctionPointer("nvmlDeviceGetProcessUtilization")
     ret = fn(handle, None, byref(c_count), c_time_stamp)
 
     if (ret == NVML_ERROR_INSUFFICIENT_SIZE):
         # typical case
         sampleArray = c_count.value * c_nvmlProcessUtilizationSample_t
         c_samples = sampleArray()
 
@@ -4131,53 +4045,49 @@
         _nvmlCheckReturn(ret)
 
         return c_samples[0:c_count.value]
     else:
         # error case
         raise NVMLError(ret)
 
-
 def nvmlVgpuInstanceGetMetadata(vgpuInstance):
     fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetMetadata")
     c_vgpuMetadata = c_nvmlVgpuMetadata_t()
     c_bufferSize = c_uint(0)
     # Make the first NVML API call to get the c_bufferSize value.
     # We have already allocated required buffer above.
     ret = fn(vgpuInstance, byref(c_vgpuMetadata), byref(c_bufferSize))
     if (ret == NVML_ERROR_INSUFFICIENT_SIZE):
         ret = fn(vgpuInstance, byref(c_vgpuMetadata), byref(c_bufferSize))
         _nvmlCheckReturn(ret)
     else:
         raise NVMLError(ret)
     return c_vgpuMetadata
 
-
 def nvmlDeviceGetVgpuMetadata(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetVgpuMetadata")
     c_vgpuPgpuMetadata = c_nvmlVgpuPgpuMetadata_t()
     c_bufferSize = c_uint(0)
     # Make the first NVML API call to get the c_bufferSize value.
     # We have already allocated required buffer above.
     ret = fn(handle, byref(c_vgpuPgpuMetadata), byref(c_bufferSize))
     if (ret == NVML_ERROR_INSUFFICIENT_SIZE):
         ret = fn(handle, byref(c_vgpuPgpuMetadata), byref(c_bufferSize))
         _nvmlCheckReturn(ret)
     else:
         raise NVMLError(ret)
     return c_vgpuPgpuMetadata
 
-
 def nvmlGetVgpuCompatibility(vgpuMetadata, pgpuMetadata):
     fn = _nvmlGetFunctionPointer("nvmlGetVgpuCompatibility")
     c_vgpuPgpuCompatibility = c_nvmlVgpuPgpuCompatibility_t()
     ret = fn(byref(vgpuMetadata), byref(pgpuMetadata), byref(c_vgpuPgpuCompatibility))
     _nvmlCheckReturn(ret)
     return c_vgpuPgpuCompatibility
 
-
 @convertStrBytes
 def nvmlDeviceGetPgpuMetadataString(handle):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPgpuMetadataString")
     c_pgpuMetadata = create_string_buffer(NVML_VGPU_PGPU_METADATA_OPAQUE_DATA_SIZE)
     c_bufferSize = c_uint(0)
     # Make the first NVML API call to get the c_bufferSize value.
     # We have already allocated required buffer above.
@@ -4185,478 +4095,425 @@
     if (ret == NVML_ERROR_INSUFFICIENT_SIZE):
         ret = fn(handle, byref(c_pgpuMetadata), byref(c_bufferSize))
         _nvmlCheckReturn(ret)
     else:
         raise NVMLError(ret)
     return (c_pgpuMetadata.value, c_bufferSize.value)
 
-
 def nvmlDeviceGetVgpuSchedulerLog(handle):
     c_vgpu_sched_log = c_nvmlVgpuSchedulerLog_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetVgpuSchedulerLog")
     ret = fn(handle, byref(c_vgpu_sched_log))
     _nvmlCheckReturn(ret)
     return c_vgpu_sched_log
 
-
 def nvmlDeviceGetVgpuSchedulerState(handle):
     c_vgpu_sched_state = c_nvmlVgpuSchedulerGetState_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetVgpuSchedulerState")
     ret = fn(handle, byref(c_vgpu_sched_state))
     _nvmlCheckReturn(ret)
     return c_vgpu_sched_state
 
-
 def nvmlDeviceGetVgpuSchedulerCapabilities(handle):
     c_vgpu_sched_caps = c_nvmlVgpuSchedulerCapabilities_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetVgpuSchedulerCapabilities")
     ret = fn(handle, byref(c_vgpu_sched_caps))
     _nvmlCheckReturn(ret)
     return c_vgpu_sched_caps
 
+def nvmlDeviceSetVgpuSchedulerState(handle, sched_state):
+    fn = _nvmlGetFunctionPointer("nvmlDeviceSetVgpuSchedulerState")
+    ret = fn(handle, byref(sched_state))
+    _nvmlCheckReturn(ret)
+    return ret
 
 def nvmlSetVgpuVersion(vgpuVersion):
     fn = _nvmlGetFunctionPointer("nvmlSetVgpuVersion")
     ret = fn(byref(vgpuVersion))
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlGetVgpuVersion(supported, current):
     fn = _nvmlGetFunctionPointer("nvmlGetVgpuVersion")
     ret = fn(byref(supported), byref(current))
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlVgpuInstanceGetAccountingMode(vgpuInstance):
     c_mode = _nvmlEnableState_t()
     fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetAccountingMode")
     ret = fn(vgpuInstance, byref(c_mode))
     _nvmlCheckReturn(ret)
     return c_mode.value
 
-
 def nvmlVgpuInstanceGetAccountingPids(vgpuInstance):
     c_pidCount = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetAccountingPids")
     ret = fn(vgpuInstance, byref(c_pidCount), None)
     if (ret == NVML_ERROR_INSUFFICIENT_SIZE):
         sampleArray = c_pidCount.value * c_uint
         c_pidArray = sampleArray()
         ret = fn(vgpuInstance, byref(c_pidCount), byref(c_pidArray))
         _nvmlCheckReturn(ret)
     else:
         raise NVMLError(ret)
     return (c_pidCount, c_pidArray)
 
-
 def nvmlVgpuInstanceGetAccountingStats(vgpuInstance, pid):
     c_accountingStats = c_nvmlAccountingStats_t()
     fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceGetAccountingStats")
     ret = fn(vgpuInstance, pid, byref(c_accountingStats))
     _nvmlCheckReturn(ret)
     return c_accountingStats
 
-
 def nvmlVgpuInstanceClearAccountingPids(vgpuInstance):
     fn = _nvmlGetFunctionPointer("nvmlVgpuInstanceClearAccountingPids")
     ret = fn(vgpuInstance)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlGetExcludedDeviceCount():
     c_count = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlGetExcludedDeviceCount")
     ret = fn(byref(c_count))
     _nvmlCheckReturn(ret)
     return c_count.value
 
-
 def nvmlGetExcludedDeviceInfoByIndex(index):
     c_index = c_uint(index)
     info = c_nvmlExcludedDeviceInfo_t()
     fn = _nvmlGetFunctionPointer("nvmlGetExcludedDeviceInfoByIndex")
     ret = fn(c_index, byref(info))
     _nvmlCheckReturn(ret)
     return info
 
-
 def nvmlDeviceGetHostVgpuMode(handle):
     c_host_vgpu_mode = _nvmlHostVgpuMode_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetHostVgpuMode")
     ret = fn(handle, byref(c_host_vgpu_mode))
     _nvmlCheckReturn(ret)
     return c_host_vgpu_mode.value
 
-
 def nvmlDeviceSetMigMode(device, mode):
     c_activationStatus = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetMigMode")
     ret = fn(device, mode, byref(c_activationStatus))
     _nvmlCheckReturn(ret)
     return c_activationStatus.value
 
-
 def nvmlDeviceGetMigMode(device):
     c_currentMode = c_uint()
     c_pendingMode = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMigMode")
     ret = fn(device, byref(c_currentMode), byref(c_pendingMode))
     _nvmlCheckReturn(ret)
     return [c_currentMode.value, c_pendingMode.value]
 
-
 def nvmlDeviceGetGpuInstanceProfileInfo(device, profile, version=2):
     if version == 2:
         c_info = c_nvmlGpuInstanceProfileInfo_v2_t()
         fn = _nvmlGetFunctionPointer("nvmlDeviceGetGpuInstanceProfileInfoV")
     elif version == 1:
         c_info = c_nvmlGpuInstanceProfileInfo_t()
         fn = _nvmlGetFunctionPointer("nvmlDeviceGetGpuInstanceProfileInfo")
     else:
         raise NVMLError(NVML_ERROR_FUNCTION_NOT_FOUND)
     ret = fn(device, profile, byref(c_info))
     _nvmlCheckReturn(ret)
     return c_info
 
-
 # Define function alias for the API exposed by NVML
 nvmlDeviceGetGpuInstanceProfileInfoV = nvmlDeviceGetGpuInstanceProfileInfo
 
-
 def nvmlDeviceGetGpuInstanceRemainingCapacity(device, profileId):
     c_count = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetGpuInstanceRemainingCapacity")
     ret = fn(device, profileId, byref(c_count))
     _nvmlCheckReturn(ret)
     return c_count.value
 
-
 def nvmlDeviceGetGpuInstancePossiblePlacements(device, profileId, placementsRef, countRef):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetGpuInstancePossiblePlacements_v2")
     ret = fn(device, profileId, placementsRef, countRef)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceCreateGpuInstance(device, profileId):
     c_instance = c_nvmlGpuInstance_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceCreateGpuInstance")
     ret = fn(device, profileId, byref(c_instance))
     _nvmlCheckReturn(ret)
     return c_instance
 
-
 def nvmlDeviceCreateGpuInstanceWithPlacement(device, profileId, placement):
     c_instance = c_nvmlGpuInstance_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceCreateGpuInstanceWithPlacement")
     ret = fn(device, profileId, placement, byref(c_instance))
     _nvmlCheckReturn(ret)
     return c_instance
 
-
 def nvmlGpuInstanceDestroy(gpuInstance):
     fn = _nvmlGetFunctionPointer("nvmlGpuInstanceDestroy")
     ret = fn(gpuInstance)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceGetGpuInstances(device, profileId, gpuInstancesRef, countRef):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetGpuInstances")
     ret = fn(device, profileId, gpuInstancesRef, countRef)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceGetGpuInstanceById(device, gpuInstanceId):
     c_instance = c_nvmlGpuInstance_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetGpuInstanceById")
     ret = fn(device, gpuInstanceId, byref(c_instance))
     _nvmlCheckReturn(ret)
     return c_instance
 
-
 def nvmlGpuInstanceGetInfo(gpuInstance):
     c_info = c_nvmlGpuInstanceInfo_t()
     fn = _nvmlGetFunctionPointer("nvmlGpuInstanceGetInfo")
     ret = fn(gpuInstance, byref(c_info))
     _nvmlCheckReturn(ret)
     return c_info
 
-
 def nvmlGpuInstanceGetComputeInstanceProfileInfo(device, profile, engProfile, version=2):
     if version == 2:
         c_info = c_nvmlComputeInstanceProfileInfo_v2_t()
         fn = _nvmlGetFunctionPointer("nvmlGpuInstanceGetComputeInstanceProfileInfoV")
     elif version == 1:
         c_info = c_nvmlComputeInstanceProfileInfo_t()
         fn = _nvmlGetFunctionPointer("nvmlGpuInstanceGetComputeInstanceProfileInfo")
     else:
-        raise NVMLError(NVML_ERROR_FUNCTION_NOT_FOUND)
+        raise NVMLError(NVML_ERROR_FUNCTION_NOT_FOUND) 
     ret = fn(device, profile, engProfile, byref(c_info))
     _nvmlCheckReturn(ret)
     return c_info
 
-
 # Define function alias for the API exposed by NVML
 nvmlGpuInstanceGetComputeInstanceProfileInfoV = nvmlGpuInstanceGetComputeInstanceProfileInfo
 
-
 def nvmlGpuInstanceGetComputeInstanceRemainingCapacity(gpuInstance, profileId):
     c_count = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlGpuInstanceGetComputeInstanceRemainingCapacity")
     ret = fn(gpuInstance, profileId, byref(c_count))
     _nvmlCheckReturn(ret)
     return c_count.value
 
-
 def nvmlGpuInstanceGetComputeInstancePossiblePlacements(gpuInstance, profileId, placementsRef, countRef):
     fn = _nvmlGetFunctionPointer("nvmlGpuInstanceGetComputeInstancePossiblePlacements")
     ret = fn(gpuInstance, profileId, placementsRef, countRef)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlGpuInstanceCreateComputeInstance(gpuInstance, profileId):
     c_instance = c_nvmlComputeInstance_t()
     fn = _nvmlGetFunctionPointer("nvmlGpuInstanceCreateComputeInstance")
     ret = fn(gpuInstance, profileId, byref(c_instance))
     _nvmlCheckReturn(ret)
     return c_instance
 
-
 def nvmlGpuInstanceCreateComputeInstanceWithPlacement(gpuInstance, profileId, placement):
     c_instance = c_nvmlComputeInstance_t()
     fn = _nvmlGetFunctionPointer("nvmlGpuInstanceCreateComputeInstanceWithPlacement")
     ret = fn(gpuInstance, profileId, placement, byref(c_instance))
     _nvmlCheckReturn(ret)
     return c_instance
 
-
 def nvmlComputeInstanceDestroy(computeInstance):
     fn = _nvmlGetFunctionPointer("nvmlComputeInstanceDestroy")
     ret = fn(computeInstance)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlGpuInstanceGetComputeInstances(gpuInstance, profileId, computeInstancesRef, countRef):
     fn = _nvmlGetFunctionPointer("nvmlGpuInstanceGetComputeInstances")
     ret = fn(gpuInstance, profileId, computeInstancesRef, countRef)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlGpuInstanceGetComputeInstanceById(gpuInstance, computeInstanceId):
     c_instance = c_nvmlComputeInstance_t()
     fn = _nvmlGetFunctionPointer("nvmlGpuInstanceGetComputeInstanceById")
     ret = fn(gpuInstance, computeInstanceId, byref(c_instance))
     _nvmlCheckReturn(ret)
     return c_instance
 
-
 def nvmlComputeInstanceGetInfo_v2(computeInstance):
     c_info = c_nvmlComputeInstanceInfo_t()
     fn = _nvmlGetFunctionPointer("nvmlComputeInstanceGetInfo_v2")
     ret = fn(computeInstance, byref(c_info))
     _nvmlCheckReturn(ret)
     return c_info
 
-
 def nvmlComputeInstanceGetInfo(computeInstance):
     return nvmlComputeInstanceGetInfo_v2(computeInstance)
 
-
 def nvmlDeviceIsMigDeviceHandle(device):
     c_isMigDevice = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceIsMigDeviceHandle")
     ret = fn(device, byref(c_isMigDevice))
     _nvmlCheckReturn(ret)
     return c_isMigDevice
 
-
 def nvmlDeviceGetGpuInstanceId(device):
     c_gpuInstanceId = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetGpuInstanceId")
     ret = fn(device, byref(c_gpuInstanceId))
     _nvmlCheckReturn(ret)
     return c_gpuInstanceId.value
 
-
 def nvmlDeviceGetComputeInstanceId(device):
     c_computeInstanceId = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetComputeInstanceId")
     ret = fn(device, byref(c_computeInstanceId))
     _nvmlCheckReturn(ret)
     return c_computeInstanceId.value
 
-
 def nvmlDeviceGetMaxMigDeviceCount(device):
     c_count = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMaxMigDeviceCount")
     ret = fn(device, byref(c_count))
     _nvmlCheckReturn(ret)
     return c_count.value
 
-
 def nvmlDeviceGetMigDeviceHandleByIndex(device, index):
     c_index = c_uint(index)
     migDevice = c_nvmlDevice_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMigDeviceHandleByIndex")
     ret = fn(device, c_index, byref(migDevice))
     _nvmlCheckReturn(ret)
     return migDevice
 
-
 def nvmlDeviceGetDeviceHandleFromMigDeviceHandle(migDevice):
     device = c_nvmlDevice_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetDeviceHandleFromMigDeviceHandle")
     ret = fn(migDevice, byref(device))
     _nvmlCheckReturn(ret)
     return device
 
-
 def nvmlDeviceGetAttributes_v2(device):
     c_attrs = c_nvmlDeviceAttributes()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetAttributes_v2")
     ret = fn(device, byref(c_attrs))
     _nvmlCheckReturn(ret)
     return c_attrs
 
-
 def nvmlDeviceGetAttributes(device):
     return nvmlDeviceGetAttributes_v2(device)
 
-
 def nvmlDeviceGetRemappedRows(device):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetRemappedRows")
     c_corr = c_uint()
     c_unc = c_uint()
     c_bpending = c_uint()
     c_bfailure = c_uint()
     ret = fn(device, byref(c_corr), byref(c_unc), byref(c_bpending), byref(c_bfailure))
     _nvmlCheckReturn(ret)
     return (c_corr.value, c_unc.value, c_bpending.value, c_bfailure.value)
 
-
 def nvmlDeviceGetRowRemapperHistogram(device):
     c_vals = c_nvmlRowRemapperHistogramValues()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetRowRemapperHistogram")
     ret = fn(device, byref(c_vals))
     _nvmlCheckReturn(ret)
     return c_vals
 
-
 def nvmlDeviceGetArchitecture(device):
     arch = _nvmlDeviceArchitecture_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetArchitecture")
     ret = fn(device, byref(arch))
     _nvmlCheckReturn(ret)
     return arch.value
 
-
 def nvmlDeviceGetBusType(device):
     c_busType = _nvmlBusType_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetBusType")
     ret = fn(device, byref(c_busType))
     _nvmlCheckReturn(ret)
     return c_busType.value
 
-
 def nvmlDeviceGetIrqNum(device):
     c_irqNum = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetIrqNum")
     ret = fn(device, byref(c_irqNum))
     _nvmlCheckReturn(ret)
     return c_irqNum.value
 
-
 def nvmlDeviceGetNumGpuCores(device):
     c_numCores = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetNumGpuCores")
     ret = fn(device, byref(c_numCores))
     _nvmlCheckReturn(ret)
     return c_numCores.value
 
-
 def nvmlDeviceGetPowerSource(device):
     c_powerSource = _nvmlPowerSource_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPowerSource")
     ret = fn(device, byref(c_powerSource))
     _nvmlCheckReturn(ret)
     return c_powerSource.value
 
-
 def nvmlDeviceGetMemoryBusWidth(device):
     c_memBusWidth = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMemoryBusWidth")
     ret = fn(device, byref(c_memBusWidth))
     _nvmlCheckReturn(ret)
     return c_memBusWidth.value
 
-
 def nvmlDeviceGetPcieLinkMaxSpeed(device):
     c_speed = _nvmlPcieLinkMaxSpeed_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPcieLinkMaxSpeed")
     ret = fn(device, byref(c_speed))
     _nvmlCheckReturn(ret)
     return c_speed.value
 
-
 def nvmlDeviceGetAdaptiveClockInfoStatus(device):
     c_adaptiveClockInfoStatus = _nvmlAdaptiveClockInfoStatus_t()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetAdaptiveClockInfoStatus")
     ret = fn(device, byref(c_adaptiveClockInfoStatus))
     _nvmlCheckReturn(ret)
     return c_adaptiveClockInfoStatus.value
 
-
 def nvmlDeviceGetPcieSpeed(device):
     c_speed = c_uint()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetPcieSpeed")
     ret = fn(device, byref(c_speed))
     _nvmlCheckReturn(ret)
     return c_speed.value
 
-
 def nvmlDeviceGetDynamicPstatesInfo(device, c_dynamicpstatesinfo):
-    fn = _nvmlGetFunctionPointer("nvmlDeviceGetDynamicPstatesInfo")
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetDynamicPstatesInfo");
     ret = fn(device, c_dynamicpstatesinfo)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceSetFanSpeed_v2(handle, index, speed):
-    fn = _nvmlGetFunctionPointer("nvmlDeviceSetFanSpeed_v2")
+    fn = _nvmlGetFunctionPointer("nvmlDeviceSetFanSpeed_v2");
     ret = fn(handle, index, speed)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceGetThermalSettings(device, sensorindex, c_thermalsettings):
-    fn = _nvmlGetFunctionPointer("nvmlDeviceGetThermalSettings")
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetThermalSettings");
     ret = fn(device, sensorindex, c_thermalsettings)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceGetMinMaxClockOfPState(device, type, pstate, minClockMHz, maxClockMHz):
-    fn = _nvmlGetFunctionPointer("nvmlDeviceGetMinMaxClockOfPState")
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetMinMaxClockOfPState");
     ret = fn(device, _nvmlClockType_t(type), _nvmlClockType_t(pstate), minClockMHz, maxClockMHz)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceGetSupportedPerformanceStates(device):
     pstates = []
     c_count = c_uint(NVML_MAX_GPU_PERF_PSTATES)
-    c_size = sizeof(c_uint) * c_count.value
+    c_size = sizeof(c_uint)*c_count.value
 
     # NOTE: use 'c_uint' to represent the size of the nvmlPstate_t enumeration.
     pstates_array = _nvmlPstates_t * c_count.value
     c_pstates = pstates_array()
 
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetSupportedPerformanceStates")
     ret = fn(device, c_pstates, c_size)
@@ -4664,303 +4521,373 @@
 
     for value in c_pstates:
         if value != NVML_PSTATE_UNKNOWN:
             pstates.append(value)
 
     return pstates
 
-
 def nvmlDeviceGetGpcClkVfOffset(device):
     offset = c_int32()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetGpcClkVfOffset")
     ret = fn(device, byref(offset))
     _nvmlCheckReturn(ret)
     return offset.value
 
-
 def nvmlDeviceSetGpcClkVfOffset(device, offset):
     c_offset = c_int32(offset)
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetGpcClkVfOffset")
     ret = fn(device, c_offset)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceGetGpcClkMinMaxVfOffset(device, minOffset, maxOffset):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetGpcClkMinMaxVfOffset")
     ret = fn(device, minOffset, maxOffset)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceGetMemClkVfOffset(device):
     offset = c_int32()
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMemClkVfOffset")
     ret = fn(device, byref(offset))
     _nvmlCheckReturn(ret)
     return offset.value
 
-
 def nvmlDeviceSetMemClkVfOffset(device, offset):
     c_offset = c_int32(offset)
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetMemClkVfOffset")
     ret = fn(device, c_offset)
     _nvmlCheckReturn(ret)
     return ret
 
-
 def nvmlDeviceGetMemClkMinMaxVfOffset(device, minOffset, maxOffset):
     fn = _nvmlGetFunctionPointer("nvmlDeviceGetMemClkMinMaxVfOffset")
     ret = fn(device, minOffset, maxOffset)
     _nvmlCheckReturn(ret)
     return ret
 
+def nvmlSystemSetConfComputeGpusReadyState(state):
+    c_state = c_uint(state)
+    fn = _nvmlGetFunctionPointer("nvmlSystemSetConfComputeGpusReadyState")
+    ret = fn(c_state)
+    _nvmlCheckReturn(ret)
+    return ret
+
+def nvmlSystemGetConfComputeGpusReadyState():
+    c_state = c_uint()
+    fn = _nvmlGetFunctionPointer("nvmlSystemGetConfComputeGpusReadyState")
+    ret = fn(byref(c_state))
+    _nvmlCheckReturn(ret)
+    return c_state.value
+
+def nvmlSystemGetConfComputeCapabilities():
+    c_ccSysCaps = c_nvmlConfComputeSystemCaps_t()
+    fn = _nvmlGetFunctionPointer("nvmlSystemGetConfComputeCapabilities")
+    ret = fn(byref(c_ccSysCaps))
+    _nvmlCheckReturn(ret)
+    return c_ccSysCaps
+
+def nvmlSystemGetConfComputeState():
+    c_state = c_nvmlConfComputeSystemState_t()
+    fn = _nvmlGetFunctionPointer("nvmlSystemGetConfComputeState")
+    ret = fn(byref(c_state))
+    _nvmlCheckReturn(ret)
+    return c_state
+
+def nvmlDeviceSetConfComputeUnprotectedMemSize(device, c_ccMemSize):
+    fn = _nvmlGetFunctionPointer("nvmlDeviceSetConfComputeUnprotectedMemSize")
+    ret = fn(device, c_ccMemSize)
+    _nvmlCheckReturn(ret)
+    return ret
+
+def nvmlDeviceGetConfComputeMemSizeInfo(device):
+    c_ccMemSize = c_nvmlConfComputeMemSizeInfo_t()
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetConfComputeMemSizeInfo")
+    ret = fn(device, byref(c_ccMemSize))
+    _nvmlCheckReturn(ret)
+    return c_ccMemSize
+
+def nvmlDeviceGetConfComputeProtectedMemoryUsage(device):
+    c_memory = c_nvmlMemory_t()
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetConfComputeProtectedMemoryUsage")
+    ret = fn(device, byref(c_memory))
+    _nvmlCheckReturn(ret)
+    return c_memory
+
+def nvmlDeviceGetConfComputeGpuCertificate(device):
+    c_cert = c_nvmlConfComputeGpuCertificate_t()
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetConfComputeGpuCertificate")
+    ret = fn(device, byref(c_cert))
+    _nvmlCheckReturn(ret)
+    return c_cert
+
+def nvmlDeviceGetConfComputeGpuAttestationReport(device, c_nonce):
+    c_attestReport = c_nvmlConfComputeGpuAttestationReport_t()
+    c_nonce_arr = (c_uint8 * len(c_nonce))(*(c_nonce))
+    setattr(c_attestReport, 'nonce', c_nonce_arr)
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetConfComputeGpuAttestationReport")
+    ret = fn(device, byref(c_attestReport))
+    _nvmlCheckReturn(ret)
+    return c_attestReport
 
 ## GPM ##
 #########
 
 ## Enums/defines
 
 #### GPM Metric Identifiers
-NVML_GPM_METRIC_GRAPHICS_UTIL = 1  # Percentage of time any compute/graphics app was active on the GPU. 0.0 - 100.0
-NVML_GPM_METRIC_SM_UTIL = 2  # Percentage of SMs that were busy. 0.0 - 100.0
-NVML_GPM_METRIC_SM_OCCUPANCY = 3  # Percentage of warps that were active vs theoretical maximum. 0.0 - 100.0
-NVML_GPM_METRIC_INTEGER_UTIL = 4  # Percentage of time the GPU's SMs were doing integer operations. 0.0 - 100.0
-NVML_GPM_METRIC_ANY_TENSOR_UTIL = 5  # Percentage of time the GPU's SMs were doing ANY tensor operations. 0.0 - 100.0
-NVML_GPM_METRIC_DFMA_TENSOR_UTIL = 6  # Percentage of time the GPU's SMs were doing DFMA tensor operations. 0.0 - 100.0
-NVML_GPM_METRIC_HMMA_TENSOR_UTIL = 7  # Percentage of time the GPU's SMs were doing HMMA tensor operations. 0.0 - 100.0
-NVML_GPM_METRIC_IMMA_TENSOR_UTIL = 9  # Percentage of time the GPU's SMs were doing IMMA tensor operations. 0.0 - 100.0
-NVML_GPM_METRIC_DRAM_BW_UTIL = 10  # Percentage of DRAM bw used vs theoretical maximum. 0.0 - 100.0
-NVML_GPM_METRIC_FP64_UTIL = 11  # Percentage of time the GPU's SMs were doing non-tensor FP64 math. 0.0 - 100.0
-NVML_GPM_METRIC_FP32_UTIL = 12  # Percentage of time the GPU's SMs were doing non-tensor FP32 math. 0.0 - 100.0
-NVML_GPM_METRIC_FP16_UTIL = 13  # Percentage of time the GPU's SMs were doing non-tensor FP16 math. 0.0 - 100.0
-NVML_GPM_METRIC_PCIE_TX_PER_SEC = 20  # PCIe traffic from this GPU in MiB/sec
-NVML_GPM_METRIC_PCIE_RX_PER_SEC = 21  # PCIe traffic to this GPU in MiB/sec
-NVML_GPM_METRIC_NVDEC_0_UTIL = 30  # Percent utilization of NVDEC 0. 0.0 - 100.0
-NVML_GPM_METRIC_NVDEC_1_UTIL = 31  # Percent utilization of NVDEC 1. 0.0 - 100.0
-NVML_GPM_METRIC_NVDEC_2_UTIL = 32  # Percent utilization of NVDEC 2. 0.0 - 100.0
-NVML_GPM_METRIC_NVDEC_3_UTIL = 33  # Percent utilization of NVDEC 3. 0.0 - 100.0
-NVML_GPM_METRIC_NVDEC_4_UTIL = 34  # Percent utilization of NVDEC 4. 0.0 - 100.0
-NVML_GPM_METRIC_NVDEC_5_UTIL = 35  # Percent utilization of NVDEC 5. 0.0 - 100.0
-NVML_GPM_METRIC_NVDEC_6_UTIL = 36  # Percent utilization of NVDEC 6. 0.0 - 100.0
-NVML_GPM_METRIC_NVDEC_7_UTIL = 37  # Percent utilization of NVDEC 7. 0.0 - 100.0
-NVML_GPM_METRIC_NVJPG_0_UTIL = 40  # Percent utilization of NVJPG 0. 0.0 - 100.0
-NVML_GPM_METRIC_NVJPG_1_UTIL = 41  # Percent utilization of NVJPG 1. 0.0 - 100.0
-NVML_GPM_METRIC_NVJPG_2_UTIL = 42  # Percent utilization of NVJPG 2. 0.0 - 100.0
-NVML_GPM_METRIC_NVJPG_3_UTIL = 43  # Percent utilization of NVJPG 3. 0.0 - 100.0
-NVML_GPM_METRIC_NVJPG_4_UTIL = 44  # Percent utilization of NVJPG 4. 0.0 - 100.0
-NVML_GPM_METRIC_NVJPG_5_UTIL = 45  # Percent utilization of NVJPG 5. 0.0 - 100.0
-NVML_GPM_METRIC_NVJPG_6_UTIL = 46  # Percent utilization of NVJPG 6. 0.0 - 100.0
-NVML_GPM_METRIC_NVJPG_7_UTIL = 47  # Percent utilization of NVJPG 7. 0.0 - 100.0
-NVML_GPM_METRIC_NVOFA_0_UTIL = 50  # Percent utilization of NVOFA 0. 0.0 - 100.0
-NVML_GPM_METRIC_NVLINK_TOTAL_RX_PER_SEC = 60  # NvLink read bandwidth for all links in MiB/sec
-NVML_GPM_METRIC_NVLINK_TOTAL_TX_PER_SEC = 61  # NvLink write bandwidth for all links in MiB/sec
-NVML_GPM_METRIC_NVLINK_L0_RX_PER_SEC = 62  # NvLink read bandwidth for link 0 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L0_TX_PER_SEC = 63  # NvLink write bandwidth for link 0 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L1_RX_PER_SEC = 64  # NvLink read bandwidth for link 1 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L1_TX_PER_SEC = 65  # NvLink write bandwidth for link 1 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L2_RX_PER_SEC = 66  # NvLink read bandwidth for link 2 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L2_TX_PER_SEC = 67  # NvLink write bandwidth for link 2 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L3_RX_PER_SEC = 68  # NvLink read bandwidth for link 3 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L3_TX_PER_SEC = 69  # NvLink write bandwidth for link 3 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L4_RX_PER_SEC = 70  # NvLink read bandwidth for link 4 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L4_TX_PER_SEC = 71  # NvLink write bandwidth for link 4 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L5_RX_PER_SEC = 72  # NvLink read bandwidth for link 5 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L5_TX_PER_SEC = 73  # NvLink write bandwidth for link 5 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L6_RX_PER_SEC = 74  # NvLink read bandwidth for link 6 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L6_TX_PER_SEC = 75  # NvLink write bandwidth for link 6 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L7_RX_PER_SEC = 76  # NvLink read bandwidth for link 7 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L7_TX_PER_SEC = 77  # NvLink write bandwidth for link 7 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L8_RX_PER_SEC = 78  # NvLink read bandwidth for link 8 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L8_TX_PER_SEC = 79  # NvLink write bandwidth for link 8 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L9_RX_PER_SEC = 80  # NvLink read bandwidth for link 9 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L9_TX_PER_SEC = 81  # NvLink write bandwidth for link 9 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L10_RX_PER_SEC = 82  # NvLink read bandwidth for link 10 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L10_TX_PER_SEC = 83  # NvLink write bandwidth for link 10 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L11_RX_PER_SEC = 84  # NvLink read bandwidth for link 11 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L11_TX_PER_SEC = 85  # NvLink write bandwidth for link 11 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L12_RX_PER_SEC = 86  # NvLink read bandwidth for link 12 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L12_TX_PER_SEC = 87  # NvLink write bandwidth for link 12 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L13_RX_PER_SEC = 88  # NvLink read bandwidth for link 13 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L13_TX_PER_SEC = 89  # NvLink write bandwidth for link 13 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L14_RX_PER_SEC = 90  # NvLink read bandwidth for link 14 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L14_TX_PER_SEC = 91  # NvLink write bandwidth for link 14 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L15_RX_PER_SEC = 92  # NvLink read bandwidth for link 15 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L15_TX_PER_SEC = 93  # NvLink write bandwidth for link 15 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L16_RX_PER_SEC = 94  # NvLink read bandwidth for link 16 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L16_TX_PER_SEC = 95  # NvLink write bandwidth for link 16 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L17_RX_PER_SEC = 96  # NvLink read bandwidth for link 17 in MiB/sec
-NVML_GPM_METRIC_NVLINK_L17_TX_PER_SEC = 97  # NvLink write bandwidth for link 17 in MiB/sec
-NVML_GPM_METRIC_MAX = 98
-
+NVML_GPM_METRIC_GRAPHICS_UTIL           = 1 # Percentage of time any compute/graphics app was active on the GPU. 0.0 - 100.0
+NVML_GPM_METRIC_SM_UTIL                 = 2 # Percentage of SMs that were busy. 0.0 - 100.0
+NVML_GPM_METRIC_SM_OCCUPANCY            = 3 # Percentage of warps that were active vs theoretical maximum. 0.0 - 100.0
+NVML_GPM_METRIC_INTEGER_UTIL            = 4 # Percentage of time the GPU's SMs were doing integer operations. 0.0 - 100.0
+NVML_GPM_METRIC_ANY_TENSOR_UTIL         = 5 # Percentage of time the GPU's SMs were doing ANY tensor operations. 0.0 - 100.0
+NVML_GPM_METRIC_DFMA_TENSOR_UTIL        = 6 # Percentage of time the GPU's SMs were doing DFMA tensor operations. 0.0 - 100.0
+NVML_GPM_METRIC_HMMA_TENSOR_UTIL        = 7 # Percentage of time the GPU's SMs were doing HMMA tensor operations. 0.0 - 100.0
+NVML_GPM_METRIC_IMMA_TENSOR_UTIL        = 9 # Percentage of time the GPU's SMs were doing IMMA tensor operations. 0.0 - 100.0
+NVML_GPM_METRIC_DRAM_BW_UTIL            = 10 # Percentage of DRAM bw used vs theoretical maximum. 0.0 - 100.0
+NVML_GPM_METRIC_FP64_UTIL               = 11 # Percentage of time the GPU's SMs were doing non-tensor FP64 math. 0.0 - 100.0
+NVML_GPM_METRIC_FP32_UTIL               = 12 # Percentage of time the GPU's SMs were doing non-tensor FP32 math. 0.0 - 100.0
+NVML_GPM_METRIC_FP16_UTIL               = 13 # Percentage of time the GPU's SMs were doing non-tensor FP16 math. 0.0 - 100.0
+NVML_GPM_METRIC_PCIE_TX_PER_SEC         = 20 # PCIe traffic from this GPU in MiB/sec
+NVML_GPM_METRIC_PCIE_RX_PER_SEC         = 21 # PCIe traffic to this GPU in MiB/sec
+NVML_GPM_METRIC_NVDEC_0_UTIL            = 30 # Percent utilization of NVDEC 0. 0.0 - 100.0
+NVML_GPM_METRIC_NVDEC_1_UTIL            = 31 # Percent utilization of NVDEC 1. 0.0 - 100.0
+NVML_GPM_METRIC_NVDEC_2_UTIL            = 32 # Percent utilization of NVDEC 2. 0.0 - 100.0
+NVML_GPM_METRIC_NVDEC_3_UTIL            = 33 # Percent utilization of NVDEC 3. 0.0 - 100.0
+NVML_GPM_METRIC_NVDEC_4_UTIL            = 34 # Percent utilization of NVDEC 4. 0.0 - 100.0
+NVML_GPM_METRIC_NVDEC_5_UTIL            = 35 # Percent utilization of NVDEC 5. 0.0 - 100.0
+NVML_GPM_METRIC_NVDEC_6_UTIL            = 36 # Percent utilization of NVDEC 6. 0.0 - 100.0
+NVML_GPM_METRIC_NVDEC_7_UTIL            = 37 # Percent utilization of NVDEC 7. 0.0 - 100.0
+NVML_GPM_METRIC_NVJPG_0_UTIL            = 40 # Percent utilization of NVJPG 0. 0.0 - 100.0
+NVML_GPM_METRIC_NVJPG_1_UTIL            = 41 # Percent utilization of NVJPG 1. 0.0 - 100.0
+NVML_GPM_METRIC_NVJPG_2_UTIL            = 42 # Percent utilization of NVJPG 2. 0.0 - 100.0
+NVML_GPM_METRIC_NVJPG_3_UTIL            = 43 # Percent utilization of NVJPG 3. 0.0 - 100.0
+NVML_GPM_METRIC_NVJPG_4_UTIL            = 44 # Percent utilization of NVJPG 4. 0.0 - 100.0
+NVML_GPM_METRIC_NVJPG_5_UTIL            = 45 # Percent utilization of NVJPG 5. 0.0 - 100.0
+NVML_GPM_METRIC_NVJPG_6_UTIL            = 46 # Percent utilization of NVJPG 6. 0.0 - 100.0
+NVML_GPM_METRIC_NVJPG_7_UTIL            = 47 # Percent utilization of NVJPG 7. 0.0 - 100.0
+NVML_GPM_METRIC_NVOFA_0_UTIL            = 50 # Percent utilization of NVOFA 0. 0.0 - 100.0
+NVML_GPM_METRIC_NVLINK_TOTAL_RX_PER_SEC = 60 # NvLink read bandwidth for all links in MiB/sec
+NVML_GPM_METRIC_NVLINK_TOTAL_TX_PER_SEC = 61 # NvLink write bandwidth for all links in MiB/sec
+NVML_GPM_METRIC_NVLINK_L0_RX_PER_SEC    = 62 # NvLink read bandwidth for link 0 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L0_TX_PER_SEC    = 63 # NvLink write bandwidth for link 0 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L1_RX_PER_SEC    = 64 # NvLink read bandwidth for link 1 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L1_TX_PER_SEC    = 65 # NvLink write bandwidth for link 1 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L2_RX_PER_SEC    = 66 # NvLink read bandwidth for link 2 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L2_TX_PER_SEC    = 67 # NvLink write bandwidth for link 2 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L3_RX_PER_SEC    = 68 # NvLink read bandwidth for link 3 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L3_TX_PER_SEC    = 69 # NvLink write bandwidth for link 3 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L4_RX_PER_SEC    = 70 # NvLink read bandwidth for link 4 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L4_TX_PER_SEC    = 71 # NvLink write bandwidth for link 4 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L5_RX_PER_SEC    = 72 # NvLink read bandwidth for link 5 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L5_TX_PER_SEC    = 73 # NvLink write bandwidth for link 5 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L6_RX_PER_SEC    = 74 # NvLink read bandwidth for link 6 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L6_TX_PER_SEC    = 75 # NvLink write bandwidth for link 6 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L7_RX_PER_SEC    = 76 # NvLink read bandwidth for link 7 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L7_TX_PER_SEC    = 77 # NvLink write bandwidth for link 7 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L8_RX_PER_SEC    = 78 # NvLink read bandwidth for link 8 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L8_TX_PER_SEC    = 79 # NvLink write bandwidth for link 8 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L9_RX_PER_SEC    = 80 # NvLink read bandwidth for link 9 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L9_TX_PER_SEC    = 81 # NvLink write bandwidth for link 9 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L10_RX_PER_SEC   = 82 # NvLink read bandwidth for link 10 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L10_TX_PER_SEC   = 83 # NvLink write bandwidth for link 10 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L11_RX_PER_SEC   = 84 # NvLink read bandwidth for link 11 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L11_TX_PER_SEC   = 85 # NvLink write bandwidth for link 11 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L12_RX_PER_SEC   = 86 # NvLink read bandwidth for link 12 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L12_TX_PER_SEC   = 87 # NvLink write bandwidth for link 12 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L13_RX_PER_SEC   = 88 # NvLink read bandwidth for link 13 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L13_TX_PER_SEC   = 89 # NvLink write bandwidth for link 13 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L14_RX_PER_SEC   = 90 # NvLink read bandwidth for link 14 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L14_TX_PER_SEC   = 91 # NvLink write bandwidth for link 14 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L15_RX_PER_SEC   = 92 # NvLink read bandwidth for link 15 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L15_TX_PER_SEC   = 93 # NvLink write bandwidth for link 15 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L16_RX_PER_SEC   = 94 # NvLink read bandwidth for link 16 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L16_TX_PER_SEC   = 95 # NvLink write bandwidth for link 16 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L17_RX_PER_SEC   = 96 # NvLink read bandwidth for link 17 in MiB/sec
+NVML_GPM_METRIC_NVLINK_L17_TX_PER_SEC   = 97 # NvLink write bandwidth for link 17 in MiB/sec
+NVML_GPM_METRIC_MAX                     = 98
 
 ## Structs
 
 class c_nvmlUnitInfo_t(_PrintableStructure):
     _fields_ = [
         ('name', c_char * 96),
         ('id', c_char * 96),
         ('serial', c_char * 96),
         ('firmwareVersion', c_char * 96),
     ]
 
-
 class struct_c_nvmlGpmSample_t(Structure):
-    pass  # opaque handle
-
-
+    pass # opaque handle
 c_nvmlGpmSample_t = POINTER(struct_c_nvmlGpmSample_t)
 
-
 class c_metricInfo_t(Structure):
     _fields_ = [
         ("shortName", c_char_p),
         ("longName", c_char_p),
         ("unit", c_char_p),
     ]
 
-
 class c_nvmlGpmMetric_t(_PrintableStructure):
     _fields_ = [
         ('metricId', c_uint),
         ('nvmlReturn', _nvmlReturn_t),
         ('value', c_double),
         ('metricInfo', c_metricInfo_t)
     ]
 
-
 class c_nvmlGpmMetricsGet_t(_PrintableStructure):
     _fields_ = [
         ('version', c_uint),
         ('numMetrics', c_uint),
         ('sample1', c_nvmlGpmSample_t),
         ('sample2', c_nvmlGpmSample_t),
         ('metrics', c_nvmlGpmMetric_t * NVML_GPM_METRIC_MAX)
     ]
 
-
 NVML_GPM_METRICS_GET_VERSION = 1
 
-
 class c_nvmlGpmSupport_t(_PrintableStructure):
     _fields_ = [
         ('version', c_uint),
         ('isSupportedDevice', c_uint),
     ]
 
-
 NVML_GPM_SUPPORT_VERSION = 1
 
-
 ## Functions
 
 def nvmlGpmMetricsGet(metricsGet):
     fn = _nvmlGetFunctionPointer("nvmlGpmMetricsGet")
     ret = fn(byref(metricsGet))
     _nvmlCheckReturn(ret)
     return metricsGet
 
-
 def nvmlGpmSampleFree(gpmSample):
     fn = _nvmlGetFunctionPointer("nvmlGpmSampleFree")
     ret = fn(gpmSample)
     _nvmlCheckReturn(ret)
     return
 
-
 def nvmlGpmSampleAlloc():
     gpmSample = c_nvmlGpmSample_t()
     fn = _nvmlGetFunctionPointer("nvmlGpmSampleAlloc")
     ret = fn(byref(gpmSample))
     _nvmlCheckReturn(ret)
     return gpmSample
 
-
 def nvmlGpmSampleGet(device, gpmSample):
     fn = _nvmlGetFunctionPointer("nvmlGpmSampleGet")
     ret = fn(device, gpmSample)
     _nvmlCheckReturn(ret)
     return gpmSample
 
-
 def nvmlGpmMigSampleGet(device, gpuInstanceId, gpmSample):
     fn = _nvmlGetFunctionPointer("nvmlGpmMigSampleGet")
     ret = fn(device, gpuInstanceId, gpmSample)
     _nvmlCheckReturn(ret)
     return gpmSample
 
-
 def nvmlGpmQueryDeviceSupport(device):
     gpmSupport = c_nvmlGpmSupport_t()
     gpmSupport.version = NVML_GPM_SUPPORT_VERSION
     fn = _nvmlGetFunctionPointer("nvmlGpmQueryDeviceSupport")
     ret = fn(device, byref(gpmSupport))
     _nvmlCheckReturn(ret)
     return gpmSupport
 
-
-## CCU ##
-#########
-
-## Enums/defines
-
-#### CCU Stream State
-NVML_COUNTER_COLLECTION_UNIT_STREAM_STATE_DISABLE = 0
-NVML_COUNTER_COLLECTION_UNIT_STREAM_STATE_ENABLE = 1
-
-
-## Functions
-
-def nvmlDeviceCcuSetStreamState(device, state):
+def nvmlGpmSetStreamingEnabled(device, state):
     c_state = c_uint(state)
-    fn = _nvmlGetFunctionPointer("nvmlDeviceCcuSetStreamState")
+    fn = _nvmlGetFunctionPointer("nvmlGpmSetStreamingEnabled")
     ret = fn(device, c_state)
     _nvmlCheckReturn(ret)
     return ret
 
-
-def nvmlDeviceCcuGetStreamState(device):
+def nvmlGpmQueryIfStreamingEnabled(device):
     c_state = c_uint()
-    fn = _nvmlGetFunctionPointer("nvmlDeviceCcuGetStreamState")
+    fn = _nvmlGetFunctionPointer("nvmlGpmQueryIfStreamingEnabled")
     ret = fn(device, byref(c_state))
     _nvmlCheckReturn(ret)
     return c_state.value
 
-
 # Low Power Structure and Function
 
 class c_nvmlNvLinkPowerThres_t(Structure):
     _fields_ = [
         ("lowPwrThreshold", c_uint),
     ]
 
-
 def nvmlDeviceSetNvLinkDeviceLowPowerThreshold(device, l1threshold):
     c_info = c_nvmlNvLinkPowerThres_t()
     c_info.lowPwrThreshold = l1threshold
     fn = _nvmlGetFunctionPointer("nvmlDeviceSetNvLinkDeviceLowPowerThreshold")
     ret = fn(device, byref(c_info))
     _nvmlCheckReturn(ret)
-    return ret
-
+    return ret 
 
 _nvmlGpuFabricState_t = c_uint
 NVML_GPU_FABRIC_STATE_NOT_SUPPORTED = 0
-NVML_GPU_FABRIC_STATE_NOT_STARTED = 1
-NVML_GPU_FABRIC_STATE_IN_PROGRESS = 2
-NVML_GPU_FABRIC_STATE_COMPLETED = 3
-
+NVML_GPU_FABRIC_STATE_NOT_STARTED   = 1
+NVML_GPU_FABRIC_STATE_IN_PROGRESS   = 2
+NVML_GPU_FABRIC_STATE_COMPLETED     = 3
 
 class c_nvmlGpuFabricInfo_t(_PrintableStructure):
     _fields_ = [
         ("clusterUuid", c_char * NVML_DEVICE_UUID_BUFFER_SIZE),
         ("status", _nvmlReturn_t),
         ("partitionId", c_uint32),
         ("state", _nvmlGpuFabricState_t)
     ]
 
-
 def nvmlDeviceGetGpuFabricInfo(device, gpuFabricInfo):
-    fn = _nvmlGetFunctionPointer("nvmlDeviceGetGpuFabricInfo")
+    fn = _nvmlGetFunctionPointer("nvmlDeviceGetGpuFabricInfo");
     ret = fn(device, gpuFabricInfo)
     _nvmlCheckReturn(ret)
-    return ret
+    return ret
+
+######################
+## Enums/defines
+#### NVML GPU NVLINK BW MODE
+NVML_GPU_NVLINK_BW_MODE_FULL      = 0x0
+NVML_GPU_NVLINK_BW_MODE_OFF       = 0x1
+NVML_GPU_NVLINK_BW_MODE_MIN       = 0x2
+NVML_GPU_NVLINK_BW_MODE_HALF      = 0x3
+NVML_GPU_NVLINK_BW_MODE_3QUARTER  = 0x4
+NVML_GPU_NVLINK_BW_MODE_COUNT     = 0x5
+
+def nvmlSystemSetNvlinkBwMode(mode):
+    fn = _nvmlGetFunctionPointer("nvmlSystemSetNvlinkBwMode")
+    ret = fn(mode)
+    _nvmlCheckReturn(ret)
+    return ret
+
+def nvmlSystemGetNvlinkBwMode():
+    mode = c_uint();
+    fn = _nvmlGetFunctionPointer("nvmlSystemGetNvlinkBwMode")
+    ret = fn(byref(mode))
+    _nvmlCheckReturn(ret)
+    return mode.value
+
+_nvmlPowerScopeType_t = c_uint
+NVML_POWER_SCOPE_GPU     = 0
+NVML_POWER_SCOPE_MODULE  = 1
+
+class c_nvmlPowerValue_v2_t(_PrintableStructure):
+    _fields_ = [
+        ('version', c_uint),
+        ('powerScope', _nvmlPowerScopeType_t),
+        ('powerValueMw', c_uint),
+    ]
+    _fmt_ = {'<default>': "%d B"}
+
+nvmlPowerValue_v2 = 0x0200000C
+
+def nvmlDeviceSetPowerManagementLimit_v2(device, powerScope, powerLimit, version=nvmlPowerValue_v2):
+    c_powerScope = _nvmlPowerScopeType_t(powerScope)
+    c_powerValue = c_nvmlPowerValue_v2_t()
+    c_powerValue.version = c_uint(version)
+    c_powerValue.powerScope = c_powerScope
+    c_powerValue.powerValueMw = c_uint(powerLimit)
+    fn = _nvmlGetFunctionPointer("nvmlDeviceSetPowerManagementLimit_v2")
+    ret = fn(device, byref(c_powerValue))
+    return ret
+
```

## clearml_agent/helper/package/conda_api.py

```diff
@@ -23,15 +23,15 @@
     convert_cuda_version_to_float_single_digit_str, convert_cuda_version_to_int_10_base_str, )
 from clearml_agent.helper.process import Argv, Executable, DEVNULL, CommandSequence, PathLike, find_executable
 from clearml_agent.helper.package.requirements import SimpleVersion
 from clearml_agent.session import Session
 from .base import PackageManager
 from .pip_api.venv import VirtualenvPip
 from .requirements import RequirementsManager, MarkerRequirement
-from ...backend_api.session.defs import ENV_CONDA_ENV_PACKAGE
+from ...backend_api.session.defs import ENV_CONDA_ENV_PACKAGE, ENV_USE_CONDA_BASE_ENV
 
 package_normalize = partial(re.compile(r"""\[version=['"](.*)['"]\]""").sub, r"\1")
 
 
 def package_set(packages):
     return set(map(package_normalize, packages))
 
@@ -74,14 +74,19 @@
         self.session = session
         self.python = python
         self.source = None
         self.requirements_manager = requirements_manager
         self.path = path
         self.env_read_only = False
         self.extra_channels = self.session.config.get('agent.package_manager.conda_channels', [])
+        # install into base conda environment (should only be used if running in docker mode)
+        self.use_conda_base_env = ENV_USE_CONDA_BASE_ENV.get(
+            default=self.session.config.get('agent.package_manager.use_conda_base_env', None)
+        )
+        # notice this will not install any additional packages into the selected environment
         self.conda_env_as_base_docker = \
             self.session.config.get('agent.package_manager.conda_env_as_base_docker', None) or \
             bool(ENV_CONDA_ENV_PACKAGE.get())
         if ENV_CONDA_ENV_PACKAGE.get():
             self.conda_pre_build_env_path = ENV_CONDA_ENV_PACKAGE.get()
         else:
             self.conda_pre_build_env_path = execution_info.docker_cmd if execution_info else None
@@ -124,24 +129,46 @@
             raise CommandFailedError("Unidentified conda version string:", output)
         return match.group(0)
 
     @property
     def bin(self):
         return self.pip.bin
 
+    def _parse_package_marker_match_python_ver(self, line=None, marker_req=None):
+        if line:
+            marker_req = MarkerRequirement(Requirement.parse(line))
+
+        try:
+            mock_req = MarkerRequirement(Requirement.parse(marker_req.marker.replace("'", "").replace("\"", "")))
+        except Exception as ex:
+            print("WARNING: failed parsing, assuming package is okay {}".format(ex))
+            return marker_req
+
+        if not mock_req.compare_version(requested_version=self.python):
+            print("SKIPPING package `{}` not required python version {}".format(marker_req.tostr(), self.python))
+            return None
+        return marker_req
+
     # noinspection SpellCheckingInspection
     def upgrade_pip(self):
         # do not change pip version if pre built environement is used
         if self.env_read_only:
             print('Conda environment in read-only mode, skipping pip upgrade.')
             return ''
+
+        pip_versions = []
+        for req_pip_line in self.pip.get_pip_versions():
+            req = self._parse_package_marker_match_python_ver(line=req_pip_line)
+            if req:
+                pip_versions.append(req.tostr(markers=False))
+
         return self._install(
             *select_for_platform(
-                windows=self.pip.get_pip_versions(),
-                linux=self.pip.get_pip_versions()
+                windows=pip_versions,
+                linux=pip_versions
             )
         )
 
     def create(self):
         """
         Create a new environment
         """
@@ -168,14 +195,23 @@
                 print("Fixing prefix in Conda environment {}".format(self.path))
                 CommandSequence(('source', conda_env.as_posix()),
                                 ((self.path / 'bin' / 'conda-unpack').as_posix(), )).get_output()
                 return self
             else:
                 raise ValueError("Could not restore Conda environment, cannot find {}".format(
                     self.conda_pre_build_env_path))
+        elif self.use_conda_base_env:
+            try:
+                base_path = Path(self.conda).parent.parent.as_posix()
+                print("Using base conda environment at {}".format(base_path))
+                self._init_existing_environment(base_path, is_readonly=False)
+                return self
+            except Exception as ex:
+                print("WARNING: Failed using base conda environment, reverting to new environment: {}".format(ex))
+
 
         command = Argv(
             self.conda,
             "create",
             "--yes",
             "--mkdir",
             "--prefix",
@@ -195,28 +231,43 @@
 
         conda_env = self._get_conda_sh()
         if conda_env.is_file() and not is_windows_platform():
             self.source = self.pip.source = CommandSequence(('source', conda_env.as_posix()), self.source)
 
         return self
 
-    def _init_existing_environment(self, conda_pre_build_env_path):
+    def _init_existing_environment(self, conda_pre_build_env_path, is_readonly=True):
         print("Using pre-existing Conda environment from {}".format(conda_pre_build_env_path))
         self.path = Path(conda_pre_build_env_path)
         self.source = ("conda", "activate", self.path.as_posix())
+        conda_env = self._get_conda_sh()
+        self.source = CommandSequence(('source', conda_env.as_posix()), self.source)
+
+        conda_packages_json = json.loads(
+            self._run_command((self.conda, "list", "--json", "-p", self.path), raw=True))
+
+        try:
+            for package in conda_packages_json:
+                if package.get("name") == "python" and package.get("version"):
+                    self.python = ".".join(package.get("version").split(".")[:2])
+                    print("Existing conda environment, found python version {}".format(self.python))
+                    break
+        except Exception as ex:
+            print("WARNING: failed detecting existing conda python version: {}".format(ex))
+
         self.pip = CondaPip(
             session=self.session,
             source=self.source,
             python=self.python,
             requirements_manager=self.requirements_manager,
             path=self.path,
         )
-        conda_env = self._get_conda_sh()
-        self.source = self.pip.source = CommandSequence(('source', conda_env.as_posix()), self.source)
-        self.env_read_only = True
+        self.pip.source = self.source
+
+        self.env_read_only = is_readonly
 
     def remove(self):
         """
         Delete a conda environment.
         Use 'conda env remove', then 'rm_tree' to be safe.
 
         Conda seems to load "vcruntime140.dll" from all its environment on startup.
@@ -494,15 +545,15 @@
                 continue
             # python version, only major.minor
             if m.name == 'python' and m.specs:
                 m.specs = [(m.specs[0][0], '.'.join(m.specs[0][1].split('.')[:2])), ]
                 if '.' not in m.specs[0][1]:
                     continue
 
-            if m.name.lower() == 'cudatoolkit':
+            if m.name.lower() in ('cudatoolkit', 'cuda-toolkit'):
                 # skip cuda if we are running on CPU
                 if not cuda_version:
                     continue
 
                 has_cudatoolkit = True
                 # cuda version, only major.minor
                 requested_cuda_version = '.'.join(m.specs[0][1].split('.')[:2])
@@ -521,18 +572,30 @@
                 has_torch = True
                 m.req.name = 'pytorch'
 
             if m.req.name.lower() in ('tensorflow_gpu', 'tensorflow-gpu', 'tensorflow'):
                 has_torch = True
                 m.req.name = 'tensorflow-gpu' if cuda_version > 0 else 'tensorflow'
 
+            # push the clearml packages into the pip_requirements
+            if "clearml" in m.req.name and "clearml" not in self.extra_channels:
+                if self.session.debug_mode:
+                    print("info: moving `{}` packages to `pip` section".format(m.req))
+                pip_requirements.append(m)
+                continue
+
             reqs.append(m)
 
         if not has_cudatoolkit and cuda_version:
-            m = MarkerRequirement(Requirement.parse("cudatoolkit == {}".format(cuda_version_full)))
+            # nvidia channel is using `cuda-toolkit` and has newer versions of cuda,
+            # older cuda can be picked from conda-forge (<12)
+            if "nvidia" in self.extra_channels:
+                m = MarkerRequirement(Requirement.parse("cuda-toolkit == {}".format(cuda_version_full)))
+            else:
+                m = MarkerRequirement(Requirement.parse("cudatoolkit == {}".format(cuda_version_full)))
             has_cudatoolkit = True
             reqs.append(m)
 
         # if we have a conda list, the rest should be installed with pip,
         # this means  any experiment that was executed with pip environment,
         # will be installed using pip
         if requirements.get('conda', None) is not None:
@@ -584,29 +647,38 @@
 
         # conform conda packages (version/name)
         for r in reqs:
             # change _ to - in name but not the prefix _ (as this is conda prefix)
             if r.name and not r.name.startswith('_') and not requirements.get('conda', None):
                 r.name = r.name.replace('_', '-')
 
-            if has_cudatoolkit and r.specs and len(r.specs[0]) > 1 and r.name == 'cudatoolkit':
+            if has_cudatoolkit and r.specs and len(r.specs[0]) > 1 and r.name in ('cudatoolkit', 'cuda-toolkit'):
                 # select specific cuda version if it came from the requirements
                 r.specs = [(r.specs[0][0].replace('==', '='), r.specs[0][1].split('.post')[0])]
             elif r.specs and r.specs[0] and len(r.specs[0]) > 1:
                 # remove .post from version numbers it fails with ~= version, and change == to ~=
-                r.specs = [(r.specs[0][0].replace('==', '~='), r.specs[0][1].split('.post')[0])]
+                r.specs = [(s[0].replace('==', '~='), s[1].split('.post')[0]) for s in r.specs]
 
         while reqs:
             # notice, we give conda more freedom in version selection, to help it choose best combination
             def clean_ver(ar):
-                if not ar.specs:
-                    return ar.tostr()
-                ar.specs = [(ar.specs[0][0], ar.specs[0][1] + '.0' if '.' not in ar.specs[0][1] else ar.specs[0][1])]
-                return ar.tostr()
-            conda_env['dependencies'] = [clean_ver(r) for r in reqs]
+                markers = None
+                if ar.marker:
+                    # check if we really need it based on python version
+                    ar = self._parse_package_marker_match_python_ver(marker_req=ar)
+                    if not ar:
+                        # empty lines should be skipped
+                        return ""
+                    # if we do make sure we note that we ignored markers
+                    print("WARNING: ignoring marker in `{}`".format(ar.tostr()))
+                    markers = False
+                if ar.specs:
+                    ar.specs = [(s[0], s[1] + '.0' if '.' not in s[1] else s[1]) for s in ar.specs]
+                return ar.tostr(markers=markers)
+            conda_env['dependencies'] = [clean_ver(r) for r in reqs if clean_ver(r)]
             with self.temp_file("conda_env", yaml.dump(conda_env), suffix=".yml") as name:
                 print('Conda: Trying to install requirements:\n{}'.format(conda_env['dependencies']))
                 if self.session.debug_mode:
                     print('{}:\n{}'.format(name, yaml.dump(conda_env)))
                 result = self._run_command(
                     ("env", "update", "-p", self.path, "--file", name)
                 )
```

## clearml_agent/helper/package/poetry_api.py

```diff
@@ -36,19 +36,19 @@
         return new_func
 
     return decorator
 
 
 class PoetryConfig:
 
-    def __init__(self, session, interpreter=None):
+    def __init__(self, session):
         # type: (Session, str) -> None
         self.session = session
         self._log = session.get_logger(__name__)
-        self._python = interpreter or sys.executable
+        self._python = sys.executable  # default, overwritten from session config in initialize()
         self._initialized = False
 
     @property
     def log(self):
         return self._log
 
     @property
@@ -84,14 +84,19 @@
 
     def _config(self, *args, **kwargs):
         return self.run("config", *args, **kwargs)
 
     @_guard_enabled
     def initialize(self, cwd=None):
         if not self._initialized:
+            # use correct python version -- detected in Worker.install_virtualenv() and written to
+            # session
+            if self.session.config.get("agent.python_binary", None):
+                self._python = self.session.config.get("agent.python_binary")
+
             if self.session.config.get("agent.package_manager.poetry_version", None) is not None:
                 version = str(self.session.config.get("agent.package_manager.poetry_version"))
 
                 # get poetry version
                 version = version.replace(' ', '')
                 if ('=' in version) or ('~' in version) or ('<' in version) or ('>' in version):
                     version = version
```

## Comparing `clearml_agent-1.8.0rc0.dist-info/LICENSE` & `clearml_agent-1.8.1rc0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `clearml_agent-1.8.0rc0.dist-info/METADATA` & `clearml_agent-1.8.1rc0.dist-info/METADATA`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: clearml-agent
-Version: 1.8.0rc0
+Version: 1.8.1rc0
 Summary: ClearML Agent - Auto-Magical DevOps for Deep Learning
 Home-page: https://github.com/allegroai/clearml-agent
 Author: Allegroai
 Author-email: clearml@allegro.ai
 License: Apache License 2.0
 Keywords: clearml trains devops machine deep learning agent automation hpc cluster
 Platform: UNKNOWN
@@ -24,42 +24,45 @@
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: License :: OSI Approved :: Apache Software License
 Description-Content-Type: text/markdown
-Requires-Dist: attrs (<23.0.0,>=18.0)
+Requires-Dist: attrs (<24.0.0,>=18.0)
 Requires-Dist: furl (<2.2.0,>=2.0.0)
 Requires-Dist: jsonschema (<5.0.0,>=2.6.0)
 Requires-Dist: pathlib2 (<2.4.0,>=2.3.0)
 Requires-Dist: psutil (<5.10.0,>=3.4.2)
-Requires-Dist: pyparsing (<3.1.0,>=2.0.3)
+Requires-Dist: pyparsing (<3.2.0,>=2.0.3)
 Requires-Dist: python-dateutil (<2.9.0,>=2.4.2)
-Requires-Dist: pyjwt (<2.7.0,>=2.4.0)
+Requires-Dist: pyjwt (<2.9.0,>=2.4.0)
 Requires-Dist: PyYAML (<6.1,>=3.12)
 Requires-Dist: requests (<=2.31.0,>=2.20.0)
 Requires-Dist: six (<1.17.0,>=1.13.0)
-Requires-Dist: urllib3 (<1.27.0,>=1.21.1)
+Requires-Dist: urllib3 (<2,>=1.21.1)
 Requires-Dist: virtualenv (<21,>=16)
 Requires-Dist: typing (<3.8.0,>=3.6.4) ; python_version < "3.5"
 Requires-Dist: enum34 (<1.2.0,>=0.9) ; python_version < "3.6"
 
 <div align="center">
 
 <img src="https://github.com/allegroai/clearml-agent/blob/master/docs/clearml_agent_logo.png?raw=true" width="250px">
 
-**ClearML Agent - ML-Ops made easy  
-ML-Ops scheduler & orchestration solution supporting Linux, macOS and Windows**
+**ClearML Agent - MLOps/LLMOps made easy  
+MLOps/LLMOps scheduler & orchestration solution supporting Linux, macOS and Windows**
 
 [![GitHub license](https://img.shields.io/github/license/allegroai/clearml-agent.svg)](https://img.shields.io/github/license/allegroai/clearml-agent.svg)
 [![PyPI pyversions](https://img.shields.io/pypi/pyversions/clearml-agent.svg)](https://img.shields.io/pypi/pyversions/clearml-agent.svg)
 [![PyPI version shields.io](https://img.shields.io/pypi/v/clearml-agent.svg)](https://img.shields.io/pypi/v/clearml-agent.svg)
 [![PyPI Downloads](https://pepy.tech/badge/clearml-agent/month)](https://pypi.org/project/clearml-agent/)
 [![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/allegroai)](https://artifacthub.io/packages/search?repo=allegroai)
+
+`🌟 ClearML is open-source - Leave a star to support the project! 🌟`
+
 </div>
 
 ---
 
 ### ClearML-Agent
 
 #### *Formerly known as Trains Agent*
@@ -107,37 +110,47 @@
 
 **Using the ClearML Agent, you can now set up a dynamic cluster with \*epsilon DevOps**
 
 *epsilon - Because we are :triangular_ruler: and nothing is really zero work
 
 ### Kubernetes Integration (Optional)
 
-We think Kubernetes is awesome, but it should be a choice. We designed `clearml-agent` so you can run bare-metal or
-inside a pod with any mix that fits your environment.
+We think Kubernetes is awesome, but it is not a must to get started with remote execution agents and cluster management.
+We designed `clearml-agent` so you can run both bare-metal and on top of Kubernetes, in any combination that fits your environment.
 
-Find Dockerfiles in the [docker](./docker) dir and a helm Chart in https://github.com/allegroai/clearml-helm-charts
+You can find the Dockerfiles in the [docker folder](./docker) and the helm Chart in https://github.com/allegroai/clearml-helm-charts
 
-#### Benefits of integrating existing K8s with ClearML-Agent
+#### Benefits of integrating existing Kubernetes cluster with ClearML
 
-- ClearML-Agent adds the missing scheduling capabilities to K8s
-- Allowing for more flexible automation from code
-- A programmatic interface for easier learning curve (and debugging)
-- Seamless integration with ML/DL experiment manager
+- ClearML-Agent adds the missing scheduling capabilities to your Kubernetes cluster
+- Users do not need to have direct Kubernetes access!
+- Easy learning curve with UI and CLI requiring no DevOps knowledge from end users
+- Unlike other solutions, ClearML-Agents work in tandem with other customers of your Kubernetes cluster 
+- Allows for more flexible automation from code, building pipelines and visibility
+- A programmatic interface for easy CI/CD workflows, enabling GitOps to trigger jobs inside your cluster
+- Seamless integration with the ClearML ML/DL/GenAI experiment manager
 - Web UI for customization, scheduling & prioritization of jobs
+- **Enterprise Features**: RBAC, vault, multi-tenancy, scheduler, quota management, fractional GPU support 
 
 **Run the agent in Kubernetes Glue mode an map ClearML jobs directly to K8s jobs:**
 - Use the [ClearML Agent Helm Chart](https://github.com/allegroai/clearml-helm-charts/tree/main/charts/clearml-agent) to spin an agent pod acting as a controller
-  - Alternatively (less recommended) run the [clearml-k8s glue](https://github.com/allegroai/clearml-agent/blob/master/examples/k8s_glue_example.py) on
-    a K8s cpu node
-- The clearml-k8s glue pulls jobs from the ClearML job execution queue and prepares a K8s job (based on provided
+  - Or run the [clearml-k8s glue](https://github.com/allegroai/clearml-agent/blob/master/examples/k8s_glue_example.py) on
+    a Kubernetes cpu node
+- The clearml-k8s glue pulls jobs from the ClearML job execution queue and prepares a Kubernetes job (based on provided
   yaml template)
-- Inside each task pod itself the clearml-agent will install the job (experiment) environment and spin and monitor the
-  experiment's process
+- Inside each pod the clearml-agent will install the job (experiment) environment and spin and monitor the
+  experiment's process, fully visible in the clearml UI
 - Benefits: Kubernetes full view of all running jobs in the system
-- Downside: No real scheduling (k8s scheduler), no docker image verification (post-mortem only)
+- **Enterprise Features**
+  - Full scheduler features added on Top of Kubernetes, with quota/over-quota management, priorities and order.
+  - Fractional GPU support, allowing multiple isolated containers sharing the same GPU with memory/compute limit per container 
+
+### SLURM (Optional)
+
+Yes! Slurm integration is available, check the [documentation](https://clear.ml/docs/latest/docs/clearml_agent/#slurm) for further details 
 
 ### Using the ClearML Agent
 
 **Full scale HPC with a click of a button**
 
 The ClearML Agent is a job scheduler that listens on job queue(s), pulls jobs, sets the job environments, executes the
 job and monitors its progress.
```

## Comparing `clearml_agent-1.8.0rc0.dist-info/RECORD` & `clearml_agent-1.8.1rc0.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 clearml_agent/__init__.py,sha256=x8fsfFnx1WMwOw5RJmsZxSfeUCWc6ZLXGX_78McBsNs,50
 clearml_agent/__main__.py,sha256=UlsXGOOFOyMfJCTpFWpYFmM21rNtdKYQ7lhgAeBYphs,2891
 clearml_agent/complete.py,sha256=g8oDVqTg6Nq-p56bTJyhBwCPgsoerh73VRox8YY4FUM,2410
 clearml_agent/config.py,sha256=-pLaHyLsQJxpEIY3TysH5baN6fc5hkpfhAiBT1P--ps,736
-clearml_agent/definitions.py,sha256=SE4s-9SxzKwZoCbIDSe6W7guj1-2-750smwva_8q8fU,11938
+clearml_agent/definitions.py,sha256=sTB-xIM0DARxTbCg9hShnBjxnJ-0-bxA-QygjX2ztX0,12008
 clearml_agent/errors.py,sha256=JI7zT0mLJeL-rwgrFJAUAc__XdGm9HGpnxhEYeSu-44,2826
 clearml_agent/session.py,sha256=cafYhx7K05Tbow6ZvlKfsqzkXTkwiaoe3vGnwMihO5E,16765
-clearml_agent/version.py,sha256=uZ_GCyGjfDq7Vy7QRxa5zXFuU03AywOAxEhkR8dTU9s,25
+clearml_agent/version.py,sha256=qjFkMm2x9pEZmf1MtBC-HFnExma7rg_j47y_4cT0pg0,25
 clearml_agent/backend_api/__init__.py,sha256=lN-HRyAnJd6044dJ_RKgsA28BarmAG4Pbdxu9IIwWsE,123
 clearml_agent/backend_api/utils.py,sha256=tFHquUe5nJQX9p9dB25nx5HKNfbwOBWj29fG387W1-s,4786
 clearml_agent/backend_api/config/__init__.py,sha256=7prYyl5e9R4evwdOfMevoD-hjpj2P8UTbsy-OwidpDw,561
-clearml_agent/backend_api/config/default/agent.conf,sha256=Z8RCta1DFJsi6FKhwPOugPetZBVrXEKi8DpHfQMf_jo,21950
+clearml_agent/backend_api/config/default/agent.conf,sha256=_Jrkfh7JxtX-U-H6bB2d3yNvZb2JRUm4qXkGJkZugAU,21960
 clearml_agent/backend_api/config/default/api.conf,sha256=aEe45ERpEBh-a5XivxORZQDtoKR8VKOO0_mKxaWM3Uk,1796
 clearml_agent/backend_api/config/default/logging.conf,sha256=ZvFOI9Ww6ro4IgbNcCY-Zx3D25xaSpLKdDgG7PcxMfg,92
-clearml_agent/backend_api/config/default/sdk.conf,sha256=gGkyvVQtlFTRrhhRQlUANdm6TgQoON-FhRiJIUF0g8o,6865
+clearml_agent/backend_api/config/default/sdk.conf,sha256=KDtfsaA34je4lvWJODEWOd6L636YVQr06UTCcBSjysE,6855
 clearml_agent/backend_api/schema/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 clearml_agent/backend_api/schema/action.py,sha256=EuE2jJ6-FNZBzb9PtGDfgZmEc7YMU_ONuqC3aklXjYQ,1295
 clearml_agent/backend_api/schema/service.py,sha256=a9o4_bWGk5MQan_-bynCmQqC7t5AmIH_GhzzKHjMfEE,6824
 clearml_agent/backend_api/services/__init__.py,sha256=upHJgJ3Y09BeF6rHQAItNICvfybaZSr8mEvh9ie60kA,282
 clearml_agent/backend_api/services/v2_4/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 clearml_agent/backend_api/services/v2_4/auth.py,sha256=RxRsTFwnHDFzhDbGgpsEl2lt10fI2SrOCM8uSeI1V1k,17434
 clearml_agent/backend_api/services/v2_4/debug.py,sha256=7sfr4ov3m-39IIYArPwMG8L0xlOJPU5ASpforAtTlB0,4029
@@ -33,15 +33,15 @@
 clearml_agent/backend_api/services/v2_5/queues.py,sha256=rYyNfE-XzDCKQwlq68Rh-axI0rMIFY5kM8En16HaWpg,66636
 clearml_agent/backend_api/services/v2_5/tasks.py,sha256=j4jvFWaTX7kJYHX4XnwS7ATgeJodwrpAcbA42wnqgkk,234295
 clearml_agent/backend_api/services/v2_5/workers.py,sha256=PHcG_PhZxE6ghCjToS_NJsIcZgyLOgMnSdU_Ge9e0yQ,77996
 clearml_agent/backend_api/session/__init__.py,sha256=lfHjqJWkpL2XySWzjGxGg0WePhqXS3yAYiE3aW_BNJk,338
 clearml_agent/backend_api/session/apimodel.py,sha256=1fCbOEL-2ZGqSHYV4qEwDZLZpZRylOI2RYhb4f5thq8,156
 clearml_agent/backend_api/session/callresult.py,sha256=WYs1FiG18nTUozThYHQ4nX7oF3AYH6GC7w9IjCQQdco,5233
 clearml_agent/backend_api/session/datamodel.py,sha256=861TZeos7oDRirvYp2dum_LasyQyuCnK3wyqB5nNHc8,4598
-clearml_agent/backend_api/session/defs.py,sha256=ifsc7XfykR3ujIicOcRC3qeiEwN0xU_EEBwqkshmN5w,1981
+clearml_agent/backend_api/session/defs.py,sha256=IWVb26GNFy5hCkYV4_CMgp4htVpN88j1XYOcClQ3V6Q,2056
 clearml_agent/backend_api/session/errors.py,sha256=FKra1Ade-HfXRVMiPfTV1EUFGcFlbo-kZzi-DnVOwa0,345
 clearml_agent/backend_api/session/request.py,sha256=2yJNWKtCkQ1TUSQnK42OTdUvDWjqsEE_SNA_j5U7vyI,2817
 clearml_agent/backend_api/session/response.py,sha256=1mmxHy2BKyAWCjMVjsJxvpYmg3_HIIgqmxqj5pRq12k,1932
 clearml_agent/backend_api/session/session.py,sha256=A5Dy5hazUOoCEr4JLVuxf40ZJdf3yO58Pxf8erA30QI,28540
 clearml_agent/backend_api/session/token_manager.py,sha256=I6qfPGWxc7JIGYA8gjg44t2ZO_b0l-iy_d9SxDaaVQk,4200
 clearml_agent/backend_api/session/client/__init__.py,sha256=gUnQLkLkXZS97LBYSyJYlNhhw_SB03Ow-XNdKAo3QDU,55
 clearml_agent/backend_api/session/client/client.py,sha256=nPRfk0Wx83lz2RUiz_0M5Pxz0f6dWYIWhaN6f1hPDqk,16055
@@ -65,73 +65,73 @@
 clearml_agent/backend_config/utils.py,sha256=cKJ4YfvPHv4QFupSs34HuZu_M1OYfqsQABh-2nNomnY,4264
 clearml_agent/commands/__init__.py,sha256=YV58pttbL_17b-nKhaQ_PvljaUcOiQeVoB-t-dBj_mY,99
 clearml_agent/commands/base.py,sha256=KESXmyIa3gGIMsQoSeBkvC63OLHB-SqrlntXAmrBvs4,15160
 clearml_agent/commands/check_config.py,sha256=EDrc16zKuNvRX-YWEI4y8qutBWk7BmWluyF5lAoF9tk,536
 clearml_agent/commands/config.py,sha256=mo8SR3w-Pd05Ap-iF8YeyqwHhLqRVbvV4ay8jjz3dkg,17027
 clearml_agent/commands/events.py,sha256=IRBrR-kwtSN6Y_kKiynnra9pHlFYx_RS-ICr6bXPPfU,4488
 clearml_agent/commands/resolver.py,sha256=JJKXArIhZVjLwejrCg075eh2i6CDHqbH9iheXBgSnBI,6552
-clearml_agent/commands/worker.py,sha256=OpS9OGOb7fZxGLsQB9eMsPbWNQonqaqZGbOalBpgViA,200640
+clearml_agent/commands/worker.py,sha256=DOgP4iM2Z548DjXXmI9j7jVXFr48ggyltaOHgZcWmMQ,201544
 clearml_agent/external/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 clearml_agent/external/pyhocon/__init__.py,sha256=9Y64dUMI_8P52FEC4HP0IcB90JkrtJEAjqXRn8dLX0Q,256
 clearml_agent/external/pyhocon/config_parser.py,sha256=kKaRs0uKTw_MYi0zzExNksFY9gC_NJw-hB-LlqbSFok,32918
 clearml_agent/external/pyhocon/config_tree.py,sha256=Fbw1_2DoplrJXJTUVNlscmr6x42smNNMAYxilFVT7Dg,22532
 clearml_agent/external/pyhocon/converter.py,sha256=b0Yj2t5GeUJRaH26KBoToOa5KYzuyroz9zJO-Jvea54,13100
 clearml_agent/external/pyhocon/exceptions.py,sha256=k_6C6fB063ifnjiMDiRtL53tF4TO6lcbkwLA2wsYOZc,352
 clearml_agent/external/requirements_parser/__init__.py,sha256=lAOYEvxEeIkllA8iyViWAaiR3GDB7MagIrK_nWGr_L8,353
 clearml_agent/external/requirements_parser/fragment.py,sha256=6wOYDZVGIvx_EGX9CtnsJlgC35Yd4BvxFf6JfyoYhZ0,1298
 clearml_agent/external/requirements_parser/parser.py,sha256=YmuLV_XIHwiQo2XfpeEiA3PHh-YS_drYPc2SKlM6O14,2368
-clearml_agent/external/requirements_parser/requirement.py,sha256=RxAvVLlMTec7uC3IQpBe40D5FqEiB_DyH0-HCoNwNP0,9362
+clearml_agent/external/requirements_parser/requirement.py,sha256=4oTOb3IagiPt5VfrIkSBJQp2x60IJ0SMG3GH5LsIk6E,9457
 clearml_agent/external/requirements_parser/vcs.py,sha256=mC72sDWbzzXUuZHZCw25eQ3dJitXII5E4AY3kg8yHEw,405
 clearml_agent/glue/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
 clearml_agent/glue/daemon.py,sha256=jgTt_kMcRk815Wq9tfQ9m2qY6uBio5oZ9FuYin9RKhw,358
 clearml_agent/glue/definitions.py,sha256=K5lMOSOznlJFI5FK87oMn7iY5pMqXnnGwZ3Gd4XThD4,665
 clearml_agent/glue/errors.py,sha256=pu8chuJdn87kmonenU7aRJwcul8LavLRqizhJeggcgs,130
-clearml_agent/glue/k8s.py,sha256=aO1vhQN4Jj7CPHId0m0F-nyy-yE2a9mlzv0B3e61E7s,49967
-clearml_agent/glue/pending_pods_daemon.py,sha256=hqVhM-AdYjJ0QnbbkXGtm3MYScLvqqd8jSepaHKwMjI,10396
+clearml_agent/glue/k8s.py,sha256=FHF_QW00GTAohRYQRv1ioY5uc3oQi1xd0Tb-NDxu7_4,49985
+clearml_agent/glue/pending_pods_daemon.py,sha256=ZIjVgG7IBznRP8FqvWQvnvmxaRYnmAvFQx5E0BCXWv8,10646
 clearml_agent/glue/utilities.py,sha256=c4CJIf10ADyBwd7fKIMyLqStLWXEGal2v8evmbHrKHo,452
 clearml_agent/helper/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 clearml_agent/helper/base.py,sha256=kdv37nYPUrmERAmD8amzxSZy8gKrgAAMNEXyE3zhVbQ,18798
 clearml_agent/helper/check_update.py,sha256=jPqXe-3pZ0uRjkhcNuLPxSyXhGuMxJ-IMkbubNMY4WQ,2200
 clearml_agent/helper/console.py,sha256=iaoo3U51xXRwahfWdMMjXw4OkY5BlKGXZdu5SzFIZVA,3650
 clearml_agent/helper/dicts.py,sha256=9NJVHPegGw3Cgn8Lyem2UM6prnzwf8IkR7uKYGPzPlA,828
 clearml_agent/helper/docker_args.py,sha256=gyDVGitxz3MJrjTQ65cfepL_fxkHtX9sBi2cvq8MMAU,6299
 clearml_agent/helper/process.py,sha256=OJjsy64PQ_YtLhlrpoyWfKjGL7dXtoWmOoXl47h0QVI,16242
 clearml_agent/helper/repo.py,sha256=UVbwWwTU3MmuNnrbwDLaKbMai-qqaWhTdxY5C1PeLzo,34018
-clearml_agent/helper/resource_monitor.py,sha256=glV2QlKMttPR9b8XApA5OoL-adCWzcyh_LUn53k0lJo,12222
+clearml_agent/helper/resource_monitor.py,sha256=hdHQItHeeweOkIlZgcJF0tzw4_eIUM8NIEegBpQpZwk,21636
 clearml_agent/helper/runtime_verification.py,sha256=s_o80EmcPXeEZKk733RgKpW_J1iiA4sht5M9oYwcjRg,5470
 clearml_agent/helper/singleton.py,sha256=cPIeOl9kggNJxuZoVUKZyOTDrZoU6Dc-iqWbb1CrU0U,6697
 clearml_agent/helper/trace.py,sha256=Cg4n_p2cJudiDB_34fHNvH2U_HdnjyyzLGmyOZft6_M,4759
 clearml_agent/helper/environment/__init__.py,sha256=hc0AVZeYx8NilFJMpXi0i_I8IBCQQQvr8X8XuifdE3k,125
 clearml_agent/helper/environment/converters.py,sha256=jZRr5wMP6LV0hPtLN6NCZRA_WTpgfY3gSi83ckVVqu4,2215
 clearml_agent/helper/environment/entry.py,sha256=2SjCEGSxdZrq5HyayWpiqiMZIdnGCINwiwJXbnDr4jc,4063
 clearml_agent/helper/environment/environment.py,sha256=MHGbFjg0ceqWA8BtXqFNtbl3P7cKidCPHeuUJMOarrc,738
 clearml_agent/helper/gpu/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-clearml_agent/helper/gpu/gpustat.py,sha256=T67V5-nFiyVfB2C_70_8MHktMHPu657gjSpqUatcFoY,15079
-clearml_agent/helper/gpu/pynvml.py,sha256=07ffbjWu19-O2bfJ-1KJGpAQtNmF8q72TKO39yusFe0,166328
+clearml_agent/helper/gpu/gpustat.py,sha256=aXT6mh3VIkozZTrylJ3ZAL2kEuldb-o4s-oIdIFin_s,16829
+clearml_agent/helper/gpu/pynvml.py,sha256=7JmV9Np4um2D_GZqErVCrvmaAN7TS4hD-pKuoSbTrCE,184408
 clearml_agent/helper/os/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 clearml_agent/helper/os/daemonize.py,sha256=rhjg9VQqQR9a-ddBx4KfkFIL2qtrAFuQi34g-co-s4c,2949
 clearml_agent/helper/os/folder_cache.py,sha256=CMknmXbkW-Dx7-nndt-1e302kX55DAelMFcJMpRxH6A,9919
 clearml_agent/helper/os/locks.py,sha256=bnr9WqrujGaDY7kH4Nk-lGTyZASUpABdiJmTrjOtKZM,7134
 clearml_agent/helper/os/portalocker.py,sha256=tkE6Gh4NL9jfNy-NYnto4UEgxL2GCT_HLD-iOvenoBc,7204
 clearml_agent/helper/package/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 clearml_agent/helper/package/base.py,sha256=KgEMkXioAc06erQK5e29UbFhzW8ZXm5HciWjC-xpliI,11889
-clearml_agent/helper/package/conda_api.py,sha256=uTONytcPWZGrBtcpmCr9VIAZ7ihY2jnKMhgtp26ggoc,32285
+clearml_agent/helper/package/conda_api.py,sha256=tacU-5bpFHGB2222jUHkk1IP8UixlB-XEPTpVYpz45s,35879
 clearml_agent/helper/package/external_req.py,sha256=ddFkbcbsbehUdjM3sC4ZnrZAiXSZtZf87vgpVJc5ol4,8224
-clearml_agent/helper/package/poetry_api.py,sha256=mHA9qnprF6VUvPShOIZZvpkvGssObtJioQmsGK7Neas,7110
+clearml_agent/helper/package/poetry_api.py,sha256=wIwkKcmFHn66P_Wl2I2ZfPVduElOsS7c2Y31HVMU8Iw,7406
 clearml_agent/helper/package/post_req.py,sha256=IZSGNDK8TUTLSAuCAHaN8y5AnFGhhYehm1Du6yJVysM,1764
 clearml_agent/helper/package/priority_req.py,sha256=bM3PBGnjJUOHQrzGVK5IA6QwSKZTY4GCORjZHQd_k68,4761
 clearml_agent/helper/package/pytorch.py,sha256=7mhQ4LyeOv0shoj5TIJzlYNz-PzxZJZkjVJNiUYvS-I,41760
 clearml_agent/helper/package/requirements.py,sha256=cyRu7OgfS6_oWhMjbUHzlw78uwOM6oRs6OqpOi3rqVM,31340
 clearml_agent/helper/package/translator.py,sha256=jwdc0wwD7UI1Z80NLwGLEf1cFrzZKI28KPkqA-ZEURI,3452
 clearml_agent/helper/package/venv_update_api.py,sha256=dX_EeraHgU2cd36S2pKEzp_bNKGKeyTz83yOgYyw_vo,3401
 clearml_agent/helper/package/pip_api/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 clearml_agent/helper/package/pip_api/system.py,sha256=Ik4QP4tIQhwQlJa-sJYTURCfdxmro5qqSeoRJZ9C9lQ,3913
 clearml_agent/helper/package/pip_api/venv.py,sha256=t-xhl1djtlS_XhATwEeahI6eId_N6mMnN1ai2J0k6OI,2951
 clearml_agent/interface/__init__.py,sha256=8Bxzt8z7hcpx8EBDu7MrSt0aegdcCX1-EI6-yOY6sGs,1244
 clearml_agent/interface/base.py,sha256=gjECQZsolfZY6AADkomj_OzNy0Gy3ap5mnex2O7Wi0A,15036
 clearml_agent/interface/worker.py,sha256=AEKdxr2zWSQvZVl0fYtu-rM_vdO2XvnLy_qpgIbNDQ8,9937
-clearml_agent-1.8.0rc0.dist-info/LICENSE,sha256=y_zZWeeAnf6mRnYn7HBoaFA8qF9Xsx3j01jNTcppKlY,11340
-clearml_agent-1.8.0rc0.dist-info/METADATA,sha256=rFy20MxgPbd4TJZK460ixW-y7OB0toWFLt7cbJj9Wzg,17980
-clearml_agent-1.8.0rc0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-clearml_agent-1.8.0rc0.dist-info/entry_points.txt,sha256=05FyI7Hjs821dPHdDAe0OOu7ZRYDpJ4i7RpgNdX6NXA,63
-clearml_agent-1.8.0rc0.dist-info/top_level.txt,sha256=_TrkgE1QyUVMVlaIweOwBzQtGx6A2PJ60rBpYMYSlYo,14
-clearml_agent-1.8.0rc0.dist-info/RECORD,,
+clearml_agent-1.8.1rc0.dist-info/LICENSE,sha256=y_zZWeeAnf6mRnYn7HBoaFA8qF9Xsx3j01jNTcppKlY,11340
+clearml_agent-1.8.1rc0.dist-info/METADATA,sha256=T6LjlLYIu8EkdyVIvS0WkSYXwmWhO7Q-dJjUjP9_eN4,18967
+clearml_agent-1.8.1rc0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+clearml_agent-1.8.1rc0.dist-info/entry_points.txt,sha256=05FyI7Hjs821dPHdDAe0OOu7ZRYDpJ4i7RpgNdX6NXA,63
+clearml_agent-1.8.1rc0.dist-info/top_level.txt,sha256=_TrkgE1QyUVMVlaIweOwBzQtGx6A2PJ60rBpYMYSlYo,14
+clearml_agent-1.8.1rc0.dist-info/RECORD,,
```

