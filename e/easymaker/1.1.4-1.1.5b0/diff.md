# Comparing `tmp/easymaker-1.1.4-py3-none-any.whl.zip` & `tmp/easymaker-1.1.5b0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,33 +1,35 @@
-Zip file size: 27447 bytes, number of entries: 31
--rw-r--r--  2.0 unx     1237 b- defN 24-Feb-27 00:04 easymaker/__init__.py
--rw-r--r--  2.0 unx      341 b- defN 24-Feb-27 00:04 easymaker/__main__.py
--rw-r--r--  2.0 unx     2033 b- defN 24-Feb-27 00:04 easymaker/initializer.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-27 00:04 easymaker/api/__init__.py
--rw-r--r--  2.0 unx    20674 b- defN 24-Feb-27 00:04 easymaker/api/api_sender.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-27 00:04 easymaker/cli/__init__.py
--rw-r--r--  2.0 unx     4013 b- defN 24-Feb-27 00:04 easymaker/cli/cli.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-27 00:04 easymaker/common/__init__.py
--rw-r--r--  2.0 unx     1070 b- defN 24-Feb-27 00:04 easymaker/common/constants.py
--rw-r--r--  2.0 unx      161 b- defN 24-Feb-27 00:04 easymaker/common/environment_variables.py
--rw-r--r--  2.0 unx      227 b- defN 24-Feb-27 00:04 easymaker/common/exceptions.py
--rw-r--r--  2.0 unx      872 b- defN 24-Feb-27 00:04 easymaker/common/utils/__init__.py
--rw-r--r--  2.0 unx     1659 b- defN 24-Feb-27 00:04 easymaker/common/utils/status_code_utils.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-27 00:04 easymaker/endpoint/__init__.py
--rw-r--r--  2.0 unx    11128 b- defN 24-Feb-27 00:04 easymaker/endpoint/endpoint.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-27 00:04 easymaker/experiment/__init__.py
--rw-r--r--  2.0 unx     2406 b- defN 24-Feb-27 00:04 easymaker/experiment/experiment.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-27 00:04 easymaker/image/__init__.py
--rw-r--r--  2.0 unx     7103 b- defN 24-Feb-27 00:04 easymaker/image/docker_builder.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-27 00:04 easymaker/log/__init__.py
--rw-r--r--  2.0 unx     2051 b- defN 24-Feb-27 00:04 easymaker/log/logger.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-27 00:04 easymaker/storage/__init__.py
--rw-r--r--  2.0 unx    16556 b- defN 24-Feb-27 00:04 easymaker/storage/objectstorage.py
--rw-r--r--  2.0 unx        0 b- defN 24-Feb-27 00:04 easymaker/training/__init__.py
--rw-r--r--  2.0 unx     8456 b- defN 24-Feb-27 00:04 easymaker/training/hyperparameter_tuning.py
--rw-r--r--  2.0 unx     2745 b- defN 24-Feb-27 00:04 easymaker/training/model.py
--rw-r--r--  2.0 unx     4968 b- defN 24-Feb-27 00:04 easymaker/training/training.py
--rw-r--r--  2.0 unx    15494 b- defN 24-Feb-27 00:05 easymaker-1.1.4.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Feb-27 00:05 easymaker-1.1.4.dist-info/WHEEL
--rw-r--r--  2.0 unx       10 b- defN 24-Feb-27 00:05 easymaker-1.1.4.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2613 b- defN 24-Feb-27 00:05 easymaker-1.1.4.dist-info/RECORD
-31 files, 105909 bytes uncompressed, 23207 bytes compressed:  78.1%
+Zip file size: 28525 bytes, number of entries: 33
+-rw-r--r--  2.0 unx     1249 b- defN 24-Apr-08 01:55 easymaker/__init__.py
+-rw-r--r--  2.0 unx      343 b- defN 24-Apr-08 01:55 easymaker/__main__.py
+-rw-r--r--  2.0 unx     1934 b- defN 24-Apr-08 01:55 easymaker/initializer.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 01:55 easymaker/api/__init__.py
+-rw-r--r--  2.0 unx    22053 b- defN 24-Apr-08 01:55 easymaker/api/api_sender.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 01:55 easymaker/batch_inference/__init__.py
+-rw-r--r--  2.0 unx     3818 b- defN 24-Apr-08 01:55 easymaker/batch_inference/batch_inference.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 01:55 easymaker/cli/__init__.py
+-rw-r--r--  2.0 unx     3771 b- defN 24-Apr-08 01:55 easymaker/cli/cli.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 01:55 easymaker/common/__init__.py
+-rw-r--r--  2.0 unx     1051 b- defN 24-Apr-08 01:55 easymaker/common/constants.py
+-rw-r--r--  2.0 unx      161 b- defN 24-Apr-08 01:55 easymaker/common/environment_variables.py
+-rw-r--r--  2.0 unx      228 b- defN 24-Apr-08 01:55 easymaker/common/exceptions.py
+-rw-r--r--  2.0 unx      245 b- defN 24-Apr-08 01:55 easymaker/common/utils/__init__.py
+-rw-r--r--  2.0 unx     1591 b- defN 24-Apr-08 01:55 easymaker/common/utils/status_code_utils.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 01:55 easymaker/endpoint/__init__.py
+-rw-r--r--  2.0 unx     9407 b- defN 24-Apr-08 01:55 easymaker/endpoint/endpoint.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 01:55 easymaker/experiment/__init__.py
+-rw-r--r--  2.0 unx     2271 b- defN 24-Apr-08 01:55 easymaker/experiment/experiment.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 01:55 easymaker/image/__init__.py
+-rw-r--r--  2.0 unx     6546 b- defN 24-Apr-08 01:55 easymaker/image/docker_builder.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 01:55 easymaker/log/__init__.py
+-rw-r--r--  2.0 unx     1868 b- defN 24-Apr-08 01:55 easymaker/log/logger.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 01:55 easymaker/storage/__init__.py
+-rw-r--r--  2.0 unx    15885 b- defN 24-Apr-08 01:55 easymaker/storage/objectstorage.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-08 01:55 easymaker/training/__init__.py
+-rw-r--r--  2.0 unx     6330 b- defN 24-Apr-08 01:55 easymaker/training/hyperparameter_tuning.py
+-rw-r--r--  2.0 unx     2130 b- defN 24-Apr-08 01:55 easymaker/training/model.py
+-rw-r--r--  2.0 unx     3752 b- defN 24-Apr-08 01:55 easymaker/training/training.py
+-rw-r--r--  2.0 unx    15496 b- defN 24-Apr-08 01:55 easymaker-1.1.5b0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-08 01:55 easymaker-1.1.5b0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       10 b- defN 24-Apr-08 01:55 easymaker-1.1.5b0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2812 b- defN 24-Apr-08 01:55 easymaker-1.1.5b0.dist-info/RECORD
+33 files, 103043 bytes uncompressed, 23955 bytes compressed:  76.8%
```

## zipnote {}

```diff
@@ -9,14 +9,20 @@
 
 Filename: easymaker/api/__init__.py
 Comment: 
 
 Filename: easymaker/api/api_sender.py
 Comment: 
 
+Filename: easymaker/batch_inference/__init__.py
+Comment: 
+
+Filename: easymaker/batch_inference/batch_inference.py
+Comment: 
+
 Filename: easymaker/cli/__init__.py
 Comment: 
 
 Filename: easymaker/cli/cli.py
 Comment: 
 
 Filename: easymaker/common/__init__.py
@@ -75,20 +81,20 @@
 
 Filename: easymaker/training/model.py
 Comment: 
 
 Filename: easymaker/training/training.py
 Comment: 
 
-Filename: easymaker-1.1.4.dist-info/METADATA
+Filename: easymaker-1.1.5b0.dist-info/METADATA
 Comment: 
 
-Filename: easymaker-1.1.4.dist-info/WHEEL
+Filename: easymaker-1.1.5b0.dist-info/WHEEL
 Comment: 
 
-Filename: easymaker-1.1.4.dist-info/top_level.txt
+Filename: easymaker-1.1.5b0.dist-info/top_level.txt
 Comment: 
 
-Filename: easymaker-1.1.4.dist-info/RECORD
+Filename: easymaker-1.1.5b0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## easymaker/__init__.py

```diff
@@ -1,30 +1,17 @@
-from easymaker import initializer
-
-from easymaker.log import logger
-
-from easymaker.experiment import experiment
-
-from easymaker.training import training
-
-from easymaker.training import hyperparameter_tuning
-
-from easymaker.training import model
-
-from easymaker.endpoint import endpoint
+import importlib_metadata
 
+from easymaker import initializer
+from easymaker.batch_inference import batch_inference
 from easymaker.common import constants
-
-from easymaker.common import exceptions
-
-from easymaker.common import utils
-
+from easymaker.endpoint import endpoint
+from easymaker.experiment import experiment
+from easymaker.log import logger
 from easymaker.storage import objectstorage
-
-import importlib_metadata
+from easymaker.training import hyperparameter_tuning, model, training
 
 __version__ = importlib_metadata.version("easymaker")
 
 easymaker_config = initializer.global_config
 
 init = easymaker_config.init
 
@@ -36,25 +23,28 @@
 
 HyperparameterTuning = hyperparameter_tuning.HyperparameterTuning
 
 Model = model.Model
 
 Endpoint = endpoint.Endpoint
 
+BatchInference = batch_inference.BatchInference
+
 download = objectstorage.download
 
 upload = objectstorage.upload
 
 ObjectStorage = objectstorage.ObjectStorage
 
-TENSORFLOW = 'TENSORFLOW'
-PYTORCH = 'PYTORCH'
+TENSORFLOW = "TENSORFLOW"
+PYTORCH = "PYTORCH"
 
 HYPERPARAMETER_TYPE_CODE = constants.HYPERPARAMETER_TYPE_CODE
 OBJECTIVE_TYPE_CODE = constants.OBJECTIVE_TYPE_CODE
 TUNING_STRATEGY = constants.TUNING_STRATEGY
 EARLY_STOPPING_ALGORITHM = constants.EARLY_STOPPING_ALGORITHM
+INPUT_DATA_TYPE_CODE = constants.INPUT_DATA_TYPE_CODE
 
 __all__ = (
     "init",
     "Training",
 )
```

## easymaker/__main__.py

```diff
@@ -2,17 +2,19 @@
 EasyMaker command line tool (python -m easymaker [options])
 """
 
 import sys
 
 
 def main():
-    if __package__ == '':
+    if __package__ == "":
         import os.path
+
         path = os.path.dirname(os.path.dirname(__file__))
         sys.path[0:0] = [path]
     from easymaker.cli import cli
+
     sys.exit(cli.main())
 
 
 if __name__ == "__main__":
     sys.exit(main())
```

## easymaker/initializer.py

```diff
@@ -1,52 +1,51 @@
 # -*- coding: utf-8 -*-
 
 import logging
 import os
 from typing import Optional
 
-from easymaker.common import utils
-from easymaker.common import constants
 from easymaker.api.api_sender import ApiSender
+from easymaker.common import constants
 
 _LOGGER = logging.getLogger(__name__)
 
+
 class _Config:
     """Stores common parameters and options for API calls."""
 
     def __init__(self):
-        self._appkey = os.environ.get('EM_APPKEY')
-        self._region = os.environ.get('EM_REGION')
+        self._appkey = os.environ.get("EM_APPKEY")
+        self._region = os.environ.get("EM_REGION")
         self._user_id = None
         self._secret_key = None
         self.api_sender = None
-        if os.environ.get('EM_APPKEY') and os.environ.get('EM_REGION'):
+        if os.environ.get("EM_APPKEY") and os.environ.get("EM_REGION"):
             self.api_sender = ApiSender(self._region, self._appkey)
 
     def init(
-            self,
-            *,
-            appkey: Optional[str] = None,
-            region: Optional[str] = None,
-            secret_key: Optional[str] = None,
-            profile: Optional[str] = None,
+        self,
+        *,
+        appkey: Optional[str] = None,
+        region: Optional[str] = None,
+        secret_key: Optional[str] = None,
+        profile: Optional[str] = None,
     ):
         """
         Args:
             appkey (str): easymaker appkey
             region (str): region (kr1, ..)
             secret_key (str): easymaker secret key
             profile (str): easymaker profile (alpha, beta)
         """
-        _LOGGER.debug('EasyMaker Config init')
+        _LOGGER.debug("EasyMaker Config init")
         if appkey:
             self._appkey = appkey
             os.environ["EM_APPKEY"] = appkey
         if region:
-            utils.validate_region(region)
             self._region = region
             os.environ["EM_REGION"] = region
         if secret_key:
             self._secret_key = secret_key
             os.environ["EM_SECRET_KEY"] = secret_key
         if profile:
             os.environ["EM_PROFILE"] = profile
@@ -61,9 +60,10 @@
     def region(self) -> str:
         return self._region or constants.DEFAULT_REGION
 
     @property
     def secret_key(self) -> str:
         return self._secret_key
 
+
 # global config to store init parameters: easymaker.init(appkey=..., region=...)
 global_config = _Config()
```

## easymaker/api/api_sender.py

```diff
@@ -1,479 +1,531 @@
 import os
 import ssl
 
+import requests
 from requests.adapters import HTTPAdapter, Retry
 from requests.sessions import Session
 from urllib3 import poolmanager
 
-from easymaker.common import constants, exceptions, utils
+from easymaker.common import constants, exceptions
 from easymaker.common.utils import status_code_utils
 
 
 class TLSAdapter(HTTPAdapter):
     def init_poolmanager(self, connections, maxsize, block=False):
         """Create and initialize the urllib3 PoolManager."""
         ctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)
         ctx.options |= 0x4  # OP_LEGACY_SERVER_CONNECT
-        self.poolmanager = poolmanager.PoolManager(
-            num_pools=connections,
-            maxsize=maxsize,
-            block=block,
-            ssl_context=ctx)
+        self.poolmanager = poolmanager.PoolManager(num_pools=connections, maxsize=maxsize, block=block, ssl_context=ctx)
 
 
 class ApiSender:
     def __init__(self, region, appkey, secret_key=None):
-        utils.validate_region(region)
-        if os.environ.get('EM_PROFILE'):
-            self._easymakerApiUrl = constants.EASYMAKER_DEV_API_URL.format(region, os.environ.get('EM_PROFILE')).rstrip("/")
-            if os.environ.get('EM_PROFILE') == 'local':
+
+        if os.environ.get("EM_PROFILE"):
+            self._easymakerApiUrl = constants.EASYMAKER_DEV_API_URL.format(region, os.environ.get("EM_PROFILE")).rstrip("/")
+            if os.environ.get("EM_PROFILE") == "local":
                 self._easymakerApiUrl = "http://127.0.0.1:10090".rstrip("/")
         else:
             self._easymakerApiUrl = constants.EASYMAKER_API_URL.format(region).rstrip("/")
 
         self._appkey = appkey
         self._secret_key = secret_key
 
         self.session = Session()
-        self.session.mount('https://', TLSAdapter(max_retries=Retry(total=3, backoff_factor=1)))
+        self.session.mount("https://", TLSAdapter(max_retries=Retry(total=3, backoff_factor=1)))
         self.session.headers.update(self._get_headers())
 
+        try:
+            requests.get(self._easymakerApiUrl + "/nhn-api-gateway")
+        except Exception:
+            raise exceptions.EasyMakerRegionError(f"Please provide a region")
+
     def _isSuccessful(self, response):
-        isSuccess = response['header']['isSuccessful']
+        isSuccess = response["header"]["isSuccessful"]
         if not isSuccess:
-            raise exceptions.EasyMakerError(response['header']['resultMessage'])
+            raise exceptions.EasyMakerError(response["header"]["resultMessage"])
 
         return isSuccess
 
     def _get_headers(self):
-        if os.environ.get('EM_TOKEN'):
-            headers = {'X-EasyMaker-Token': os.environ.get('EM_TOKEN')}
+        if os.environ.get("EM_TOKEN"):
+            headers = {"X-EasyMaker-Token": os.environ.get("EM_TOKEN")}
         else:
-            headers = {'X-Secret-Key': self._secret_key}
+            headers = {"X-Secret-Key": self._secret_key}
         return headers
 
     def _replace_status(self, obj, key):
         obj[key] = status_code_utils.replace_status_code(obj[key])
         return obj
 
     def _replace_status_code_in_dict_list(self, dict_list, status_key):
         return list(map(lambda d: self._replace_status(d, status_key), dict_list))
 
     def get_objectstorage_token(self, tenant_id=None, username=None, password=None):
 
-        if os.environ.get('EM_TOKEN'):
+        if os.environ.get("EM_TOKEN"):
             response = self.session.get(f'{self._easymakerApiUrl}/token/v1.0/appkeys/{self._appkey}/groups/{os.environ.get("EM_GROUP_ID")}/iaas-token').json()
             self._isSuccessful(response)
             return response
         else:
             if tenant_id and username and password:
                 token_url = constants.OBJECT_STORAGE_TOKEN_URL
-                req_header = {'Content-Type': 'application/json'}
-                body = {
-                    'auth': {
-                        'tenantId': tenant_id,
-                        'passwordCredentials': {
-                            'username': username,
-                            'password': password
-                        }
-                    }
-                }
+                req_header = {"Content-Type": "application/json"}
+                body = {"auth": {"tenantId": tenant_id, "passwordCredentials": {"username": username, "password": password}}}
                 response = self.session.post(token_url, headers=req_header, json=body).json()
                 return response
             else:
-                raise exceptions.EasyMakerError(f'Invalid object storage username/password')
+                raise exceptions.EasyMakerError(f"Invalid object storage username/password")
 
     def get_instance_list(self):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/flavors').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/flavors").json()
         self._isSuccessful(response)
 
         flavor_dict_list = []
-        for flavor in response['flavorList']:
-            flavor_dict_list.append({'id': flavor['id'], 'name': flavor['name']})
+        for flavor in response["flavorList"]:
+            flavor_dict_list.append({"id": flavor["id"], "name": flavor["name"]})
         return flavor_dict_list
 
     def get_image_list(self):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/images').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/images").json()
         self._isSuccessful(response)
 
         image_dict_list = []
-        for image in response['imageList']:
-            if image['groupTypeCode'] == 'TRAINING':
-                image_dict_list.append({'id': image['imageId'], 'name': image['imageName']})
+        for image in response["imageList"]:
+            if image["groupTypeCode"] == "TRAINING":
+                image_dict_list.append({"id": image["imageId"], "name": image["imageName"]})
         return image_dict_list
 
     def get_algorithm_list(self):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/algorithms').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/algorithms").json()
         self._isSuccessful(response)
 
         algorithm_dict_list = []
-        image_dict = {image['id']: image['name'] for image in self.get_image_list()}
+        image_dict = {image["id"]: image["name"] for image in self.get_image_list()}
 
-        for algorithm in response['algorithmList']:
-            algorithm_dict_list.append(
-                {
-                    'id': algorithm['algorithmId'],
-                    'name': algorithm['algorithmName'],
-                    'availableTrainingImageList': [image_dict[algorithm['cpuTrainingImageId']], image_dict[algorithm['gpuTrainingImageId']]]
-                })
+        for algorithm in response["algorithmList"]:
+            algorithm_dict_list.append({"id": algorithm["algorithmId"], "name": algorithm["algorithmName"], "availableTrainingImageList": [image_dict[algorithm["cpuTrainingImageId"]], image_dict[algorithm["gpuTrainingImageId"]]]})
 
         return algorithm_dict_list
 
     def get_experiment_list(self):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/experiments').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/experiments").json()
         self._isSuccessful(response)
 
         dict_list = []
-        for experiment in response['experimentList']:
-            dict_list.append({'id': experiment['experimentId'],
-                              'name': experiment['experimentName']})
+        for experiment in response["experimentList"]:
+            dict_list.append({"id": experiment["experimentId"], "name": experiment["experimentName"]})
         return dict_list
 
     def create_experiment(self, experiment_name, experiment_description):
-        body = {
-            'experimentName': experiment_name,
-            'description': experiment_description
-        }
-        response = self.session.post(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/experiments', json=body).json()
+        body = {"experimentName": experiment_name, "description": experiment_description}
+        response = self.session.post(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/experiments", json=body).json()
         self._isSuccessful(response)
 
         return response
 
     def get_experiment_by_id(self, experiment_id):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/experiments/{experiment_id}').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/experiments/{experiment_id}").json()
         self._isSuccessful(response)
 
         return response
 
     def delete_experiment_by_id(self, experiment_id):
-        response = self.session.delete(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/experiments/{experiment_id}').json()
+        response = self.session.delete(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/experiments/{experiment_id}").json()
         self._isSuccessful(response)
 
         return response
 
-    def run_training(self, training_name, training_description, experiment_id, image_id, flavor_id,
-                     distributed_node_count, data_storage_size, source_dir_uri, entry_point, algorithm_id, hyperparameter_list,
-                     dataset_list, check_point_input_uri, check_point_upload_uri, model_upload_uri, training_type_code, timeout_hours,
-                     tag_list, use_log, use_torchrun, nproc_per_node):
+    def run_training(self, training_name, training_description, experiment_id, image_id, flavor_id, distributed_node_count, data_storage_size, source_dir_uri, entry_point, algorithm_id, hyperparameter_list, dataset_list, check_point_input_uri, check_point_upload_uri, model_upload_uri, training_type_code, timeout_hours, tag_list, use_log, use_torchrun, nproc_per_node):
         body = {
-            'trainingName': training_name,
-            'description': training_description,
-            'experimentId': experiment_id,
-            'imageId': image_id,
-            'flavorId': flavor_id,
-            'instanceCount': distributed_node_count,
-            'dataStorageSize': data_storage_size,
-            'algorithmId': algorithm_id,
-            'hyperparameterList': hyperparameter_list,
-            'datasetList': dataset_list,
-            'checkPointInputUri': check_point_input_uri,
-            'checkPointUploadUri': check_point_upload_uri,
-            'modelUploadUri': model_upload_uri,
-            'trainingTypeCode': training_type_code,
-            'timeoutMinutes': timeout_hours * 60,
-            'tagList': tag_list,
-            'useLog': use_log,
-            'useTorchrun': use_torchrun,
-            'nprocPerNode': nproc_per_node,
+            "trainingName": training_name,
+            "description": training_description,
+            "experimentId": experiment_id,
+            "imageId": image_id,
+            "flavorId": flavor_id,
+            "instanceCount": distributed_node_count,
+            "dataStorageSize": data_storage_size,
+            "algorithmId": algorithm_id,
+            "hyperparameterList": hyperparameter_list,
+            "datasetList": dataset_list,
+            "checkPointInputUri": check_point_input_uri,
+            "checkPointUploadUri": check_point_upload_uri,
+            "modelUploadUri": model_upload_uri,
+            "trainingTypeCode": training_type_code,
+            "timeoutMinutes": timeout_hours * 60,
+            "tagList": tag_list,
+            "useLog": use_log,
+            "useTorchrun": use_torchrun,
+            "nprocPerNode": nproc_per_node,
         }
 
         if algorithm_id is None:
-            body['sourceDirUri'] = source_dir_uri
-            body['entryPoint'] = entry_point
+            body["sourceDirUri"] = source_dir_uri
+            body["entryPoint"] = entry_point
 
-        response = self.session.post(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/trainings',
-                                     json=body).json()
+        response = self.session.post(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/trainings", json=body).json()
 
         self._isSuccessful(response)
         return response
 
     def get_training_list(self):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/trainings').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/trainings").json()
         self._isSuccessful(response)
 
         dict_list = []
-        for training in response['trainingList']:
-            dict_list.append({'id': training['trainingId'],
-                              'name': training['trainingName']})
+        for training in response["trainingList"]:
+            dict_list.append({"id": training["trainingId"], "name": training["trainingName"]})
         return dict_list
 
     def get_training_by_id(self, training_id):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/trainings/{training_id}').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/trainings/{training_id}").json()
         self._isSuccessful(response)
 
         return response
 
     def delete_training_by_id(self, training_id):
-        response = self.session.delete(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/trainings/{training_id}').json()
+        response = self.session.delete(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/trainings/{training_id}").json()
         self._isSuccessful(response)
 
         return response
 
-    def run_hyperparameter_tuning(self, hyperparameter_tuning_name, hyperparameter_tuning_description, experiment_id, algorithm_id, image_id,
-                                  flavor_id, distributed_node_count, parallel_trial_count, data_storage_size, source_dir_uri, entry_point,
-                                  hyperparameter_spec_list, dataset_list, check_point_input_uri, check_point_upload_uri, model_upload_uri,
-                                  timeout_hours, tag_list, use_log, metric_list, metric_regex, objective_metric, objective_type_code,
-                                  objective_goal, max_failed_trial_count, max_trial_count, tuning_strategy_name, tuning_strategy_random_state,
-                                  early_stopping_algorithm, early_stopping_min_trial_count, early_stopping_start_step, use_torchrun, nproc_per_node):
+    def run_hyperparameter_tuning(
+        self,
+        hyperparameter_tuning_name,
+        hyperparameter_tuning_description,
+        experiment_id,
+        algorithm_id,
+        image_id,
+        flavor_id,
+        distributed_node_count,
+        parallel_trial_count,
+        data_storage_size,
+        source_dir_uri,
+        entry_point,
+        hyperparameter_spec_list,
+        dataset_list,
+        check_point_input_uri,
+        check_point_upload_uri,
+        model_upload_uri,
+        timeout_hours,
+        tag_list,
+        use_log,
+        metric_list,
+        metric_regex,
+        objective_metric,
+        objective_type_code,
+        objective_goal,
+        max_failed_trial_count,
+        max_trial_count,
+        tuning_strategy_name,
+        tuning_strategy_random_state,
+        early_stopping_algorithm,
+        early_stopping_min_trial_count,
+        early_stopping_start_step,
+        use_torchrun,
+        nproc_per_node,
+    ):
         body = {
-            'hyperparameterTuningName': hyperparameter_tuning_name,
-            'description': hyperparameter_tuning_description,
-            'experimentId': experiment_id,
-            'algorithmId': algorithm_id,
-            'sourceDirUri': source_dir_uri,
-            'entryPoint': entry_point,
-            'hyperparameterSpecList': hyperparameter_spec_list,
-            'imageId': image_id,
-            'flavorId': flavor_id,
-            'instanceCount': distributed_node_count * parallel_trial_count,
-            'datasetList': dataset_list,
-            'modelUploadUri': model_upload_uri,
-            'checkPointInputUri': check_point_input_uri,
-            'checkPointUploadUri': check_point_upload_uri,
-            'dataStorageSize': data_storage_size,
-            'timeoutMinutes': timeout_hours * 60,
-            'useLog': use_log,
-            'tagList': tag_list,
-            'metricList': metric_list,
-            'metricRegex': metric_regex,
-            'objectiveMetric': objective_metric,
-            'objectiveTypeCode': objective_type_code,
-            'objectiveGoal': objective_goal,
-            'maxFailedTrialCount': max_failed_trial_count,
-            'maxTrialCount': max_trial_count,
-            'parallelTrialCount': parallel_trial_count,
-            'tuningStrategyName': tuning_strategy_name,
-            'tuningStrategyRandomState': tuning_strategy_random_state,
-            'earlyStoppingAlgorithm': early_stopping_algorithm,
-            'earlyStoppingMinTrialCount': early_stopping_min_trial_count,
-            'earlyStoppingStartStep': early_stopping_start_step,
-            'useTorchrun': use_torchrun,
-            'nprocPerNode': nproc_per_node,
+            "hyperparameterTuningName": hyperparameter_tuning_name,
+            "description": hyperparameter_tuning_description,
+            "experimentId": experiment_id,
+            "algorithmId": algorithm_id,
+            "sourceDirUri": source_dir_uri,
+            "entryPoint": entry_point,
+            "hyperparameterSpecList": hyperparameter_spec_list,
+            "imageId": image_id,
+            "flavorId": flavor_id,
+            "instanceCount": distributed_node_count * parallel_trial_count,
+            "datasetList": dataset_list,
+            "modelUploadUri": model_upload_uri,
+            "checkPointInputUri": check_point_input_uri,
+            "checkPointUploadUri": check_point_upload_uri,
+            "dataStorageSize": data_storage_size,
+            "timeoutMinutes": timeout_hours * 60,
+            "useLog": use_log,
+            "tagList": tag_list,
+            "metricList": metric_list,
+            "metricRegex": metric_regex,
+            "objectiveMetric": objective_metric,
+            "objectiveTypeCode": objective_type_code,
+            "objectiveGoal": objective_goal,
+            "maxFailedTrialCount": max_failed_trial_count,
+            "maxTrialCount": max_trial_count,
+            "parallelTrialCount": parallel_trial_count,
+            "tuningStrategyName": tuning_strategy_name,
+            "tuningStrategyRandomState": tuning_strategy_random_state,
+            "earlyStoppingAlgorithm": early_stopping_algorithm,
+            "earlyStoppingMinTrialCount": early_stopping_min_trial_count,
+            "earlyStoppingStartStep": early_stopping_start_step,
+            "useTorchrun": use_torchrun,
+            "nprocPerNode": nproc_per_node,
         }
-        response = self.session.post(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/hyperparameter-tunings',
-                                     json=body).json()
+        response = self.session.post(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/hyperparameter-tunings", json=body).json()
 
         self._isSuccessful(response)
         return response
 
     def get_hyperparameter_tuning_list(self):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/hyperparameter-tunings').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/hyperparameter-tunings").json()
         self._isSuccessful(response)
 
         dict_list = []
-        for training in response['hyperparameterTuningList']:
-            dict_list.append({'id': training['hyperparameterTuningId'],
-                              'name': training['hyperparameterTuningName']})
+        for training in response["hyperparameterTuningList"]:
+            dict_list.append({"id": training["hyperparameterTuningId"], "name": training["hyperparameterTuningName"]})
         return dict_list
 
     def get_hyperparameter_tuning_by_id(self, hyperparameter_tuning_id):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/hyperparameter-tunings/{hyperparameter_tuning_id}').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/hyperparameter-tunings/{hyperparameter_tuning_id}").json()
         self._isSuccessful(response)
 
         return response
 
     def delete_hyperparameter_tuning_by_id(self, hyperparameter_tuning_id):
-        response = self.session.delete(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/hyperparameter-tunings/{hyperparameter_tuning_id}').json()
+        response = self.session.delete(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/hyperparameter-tunings/{hyperparameter_tuning_id}").json()
         self._isSuccessful(response)
 
         return response
 
-    def create_model(self, model_name, model_description=None, training_id=None, hyperparameter_tuning_id=None,
-                     framework_code=None, model_uri=None, tag_list=None):
+    def create_model(self, model_name, model_description=None, training_id=None, hyperparameter_tuning_id=None, framework_code=None, model_uri=None, tag_list=None):
         body = {
-            'modelName': model_name,
-            'description': model_description,
-            'trainingId': training_id,
-            'hyperparameterTuningId': hyperparameter_tuning_id,
-            'frameworkCode': framework_code,
-            'modelUploadUri': model_uri,
-            'tagList': tag_list,
+            "modelName": model_name,
+            "description": model_description,
+            "trainingId": training_id,
+            "hyperparameterTuningId": hyperparameter_tuning_id,
+            "frameworkCode": framework_code,
+            "modelUploadUri": model_uri,
+            "tagList": tag_list,
         }
-        response = self.session.post(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/models',
-                                     json=body).json()
+        response = self.session.post(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/models", json=body).json()
         self._isSuccessful(response)
 
         return response
 
     def get_model_list(self):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/models').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/models").json()
         self._isSuccessful(response)
 
         dict_list = []
-        for model in response['modelList']:
-            dict_list.append({'id': model['modelId'],
-                              'name': model['modelName']})
+        for model in response["modelList"]:
+            dict_list.append({"id": model["modelId"], "name": model["modelName"]})
         return dict_list
 
     def get_model_by_id(self, model_id):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/models/{model_id}').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/models/{model_id}").json()
         self._isSuccessful(response)
 
         return response
 
     def delete_model_by_id(self, model_id):
-        response = self.session.delete(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/models/{model_id}').json()
+        response = self.session.delete(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/models/{model_id}").json()
         self._isSuccessful(response)
 
         return response
 
-    def create_endpoint(self,
-                        endpoint_name,
-                        endpoint_description,
-                        flavor_id,
-                        endpoint_model_resource_list,
-                        node_count,
-                        tag_list,
-                        use_log,
-                        ca_enable,
-                        ca_min_node_count,
-                        ca_max_node_count,
-                        ca_scale_down_enable,
-                        ca_scale_down_util_thresh,
-                        ca_scale_down_unneeded_time,
-                        ca_scale_down_delay_after_add
-                        ):
+    def create_endpoint(self, endpoint_name, endpoint_description, flavor_id, endpoint_model_resource_list, node_count, tag_list, use_log, ca_enable, ca_min_node_count, ca_max_node_count, ca_scale_down_enable, ca_scale_down_util_thresh, ca_scale_down_unneeded_time, ca_scale_down_delay_after_add):
         body = {
-            'endpointName': endpoint_name,
-            'description': endpoint_description,
-            'flavorId': flavor_id,
-            'endpointModelResourceList': endpoint_model_resource_list,
-            'nodeCount': node_count,
-            'tagList': tag_list,
-            'useLog': use_log,
-            'caEnable': ca_enable,
-            'caMinNodeCount': ca_min_node_count,
-            'caMaxNodeCount': ca_max_node_count,
-            'caScaleDownEnable': ca_scale_down_enable,
-            'caScaleDownUtilThresh': ca_scale_down_util_thresh,
-            'caScaleDownUnneededTime': ca_scale_down_unneeded_time,
-            'caScaleDownDelayAfterAdd': ca_scale_down_delay_after_add,
+            "endpointName": endpoint_name,
+            "description": endpoint_description,
+            "flavorId": flavor_id,
+            "endpointModelResourceList": endpoint_model_resource_list,
+            "nodeCount": node_count,
+            "tagList": tag_list,
+            "useLog": use_log,
+            "caEnable": ca_enable,
+            "caMinNodeCount": ca_min_node_count,
+            "caMaxNodeCount": ca_max_node_count,
+            "caScaleDownEnable": ca_scale_down_enable,
+            "caScaleDownUtilThresh": ca_scale_down_util_thresh,
+            "caScaleDownUnneededTime": ca_scale_down_unneeded_time,
+            "caScaleDownDelayAfterAdd": ca_scale_down_delay_after_add,
         }
-        response = self.session.post(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoints',
-                                     json=body).json()
+        response = self.session.post(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoints", json=body).json()
         self._isSuccessful(response)
 
         return response
 
-    def create_stage(self,
-                     endpoint_id,
-                     stage_name,
-                     stage_description,
-                     flavor_id,
-                     endpoint_model_resource_list,
-                     node_count,
-                     tag_list,
-                     use_log,
-                     ca_enable,
-                     ca_min_node_count,
-                     ca_max_node_count,
-                     ca_scale_down_enable,
-                     ca_scale_down_util_thresh,
-                     ca_scale_down_unneeded_time,
-                     ca_scale_down_delay_after_add
-                     ):
+    def create_stage(self, endpoint_id, stage_name, stage_description, flavor_id, endpoint_model_resource_list, node_count, tag_list, use_log, ca_enable, ca_min_node_count, ca_max_node_count, ca_scale_down_enable, ca_scale_down_util_thresh, ca_scale_down_unneeded_time, ca_scale_down_delay_after_add):
         body = {
-            'endpointId': endpoint_id,
-            'apigwStageName': stage_name,
-            'description': stage_description,
-            'flavorId': flavor_id,
-            'endpointModelResourceList': endpoint_model_resource_list,
-            'nodeCount': node_count,
-            'tagList': tag_list,
-            'useLog': use_log,
-            'caEnable': ca_enable,
-            'caMinNodeCount': ca_min_node_count,
-            'caMaxNodeCount': ca_max_node_count,
-            'caScaleDownEnable': ca_scale_down_enable,
-            'caScaleDownUtilThresh': ca_scale_down_util_thresh,
-            'caScaleDownUnneededTime': ca_scale_down_unneeded_time,
-            'caScaleDownDelayAfterAdd': ca_scale_down_delay_after_add,
+            "endpointId": endpoint_id,
+            "apigwStageName": stage_name,
+            "description": stage_description,
+            "flavorId": flavor_id,
+            "endpointModelResourceList": endpoint_model_resource_list,
+            "nodeCount": node_count,
+            "tagList": tag_list,
+            "useLog": use_log,
+            "caEnable": ca_enable,
+            "caMinNodeCount": ca_min_node_count,
+            "caMaxNodeCount": ca_max_node_count,
+            "caScaleDownEnable": ca_scale_down_enable,
+            "caScaleDownUtilThresh": ca_scale_down_util_thresh,
+            "caScaleDownUnneededTime": ca_scale_down_unneeded_time,
+            "caScaleDownDelayAfterAdd": ca_scale_down_delay_after_add,
         }
 
-        response = self.session.post(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-stages',
-                                     json=body).json()
+        response = self.session.post(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-stages", json=body).json()
         self._isSuccessful(response)
 
         return response
 
     def get_endpoint_list(self):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoints').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoints").json()
         self._isSuccessful(response)
 
-        dict_list = response['endpointList']
-        dict_list = self._replace_status_code_in_dict_list(dict_list, 'endpointStatusCode')
+        dict_list = response["endpointList"]
+        dict_list = self._replace_status_code_in_dict_list(dict_list, "endpointStatusCode")
 
         for endpoint in dict_list:
-            endpoint['id'] = endpoint['endpointId']
-            endpoint['name'] = endpoint['endpointName']
+            endpoint["id"] = endpoint["endpointId"]
+            endpoint["name"] = endpoint["endpointName"]
 
         return dict_list
 
     def get_endpoint_by_id(self, endpoint_id):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoints/{endpoint_id}').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoints/{endpoint_id}").json()
         self._isSuccessful(response)
 
-        dict = response['endpoint']
-        dict = self._replace_status(dict, 'endpointStatusCode')
+        dict = response["endpoint"]
+        dict = self._replace_status(dict, "endpointStatusCode")
 
         return dict
 
     def get_endpoint_stage_list(self, endpoint_id):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-stages',
-                                    params={'endpointId': endpoint_id}).json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-stages", params={"endpointId": endpoint_id}).json()
         self._isSuccessful(response)
 
-        dict_list = response['endpointStageList']
-        dict_list = self._replace_status_code_in_dict_list(dict_list, 'endpointStageStatusCode')
+        dict_list = response["endpointStageList"]
+        dict_list = self._replace_status_code_in_dict_list(dict_list, "endpointStageStatusCode")
 
         return dict_list
 
     def get_endpoint_stage_by_id(self, endpoint_stage_id):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-stages/{endpoint_stage_id}').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-stages/{endpoint_stage_id}").json()
         self._isSuccessful(response)
 
-        dict = response['endpointStage']
-        dict = self._replace_status(dict, 'endpointStageStatusCode')
+        dict = response["endpointStage"]
+        dict = self._replace_status(dict, "endpointStageStatusCode")
 
         return dict
 
     def get_endpoint_model_list(self, endpoint_stage_id):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-models',
-                                    params={'endpointStageId': endpoint_stage_id}).json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-models", params={"endpointStageId": endpoint_stage_id}).json()
         self._isSuccessful(response)
 
-        dict_list = response['endpointModelList']
-        dict_list = self._replace_status_code_in_dict_list(dict_list, 'endpointModelStatusCode')
+        dict_list = response["endpointModelList"]
+        dict_list = self._replace_status_code_in_dict_list(dict_list, "endpointModelStatusCode")
 
         return response
 
     def get_endpoint_model_by_id(self, endpoint_model_id):
-        response = self.session.get(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-models/{endpoint_model_id}').json()
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-models/{endpoint_model_id}").json()
         self._isSuccessful(response)
 
-        dict = response['endpointModel']
-        dict = self._replace_status(dict, 'endpointModelStatusCode')
+        dict = response["endpointModel"]
+        dict = self._replace_status(dict, "endpointModelStatusCode")
 
         return dict
 
     def delete_endpoint_by_id(self, endpoint_id):
-        response = self.session.delete(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoints/{endpoint_id}').json()
+        response = self.session.delete(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoints/{endpoint_id}").json()
         self._isSuccessful(response)
 
         return response
 
     def delete_endpoint_stage_by_id(self, endpoint_stage_id):
-        response = self.session.delete(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-stages/{endpoint_stage_id}').json()
+        response = self.session.delete(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-stages/{endpoint_stage_id}").json()
         self._isSuccessful(response)
 
         return response
 
     def delete_endpoint_model_by_id(self, endpoint_model_id):
-        response = self.session.delete(f'{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-models/{endpoint_model_id}').json()
+        response = self.session.delete(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/endpoint-models/{endpoint_model_id}").json()
+        self._isSuccessful(response)
+
+        return response
+
+    def run_batch_inference(
+        self,
+        batch_inference_name,
+        instance_count,
+        timeout_minutes,
+        flavor_id,
+        model_id,
+        #
+        pod_count,
+        max_batch_size,
+        inference_timeout_seconds,
+        #
+        input_data_uri,
+        input_data_type_code,
+        include_glob_pattern,
+        exclude_glob_pattern,
+        output_upload_uri,
+        #
+        data_storage_size,
+        #
+        description,
+        tag_list,
+        use_log,
+    ):
+        body = {
+            "batchInferenceName": batch_inference_name,
+            "instanceCount": instance_count,
+            "timeoutMinutes": timeout_minutes,
+            "flavorId": flavor_id,
+            "modelId": model_id,
+            #
+            "podCount": pod_count,
+            "maxBatchSize": max_batch_size,
+            "inferenceTimeoutSeconds": inference_timeout_seconds,
+            #
+            "inputDataUri": input_data_uri,
+            "inputDataTypeCode": input_data_type_code,
+            "includeGlobPattern": include_glob_pattern,
+            "excludeGlobPattern": exclude_glob_pattern,
+            "outputUploadUri": output_upload_uri,
+            #
+            "dataStorageSize": data_storage_size,
+            #
+            "description": description,
+            "tagList": tag_list,
+            "useLog": use_log,
+        }
+
+        response = self.session.post(
+            f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/batch-inferences",
+            json=body,
+        ).json()
+
+        self._isSuccessful(response)
+        return response
+
+    def get_batch_inference_list(self):
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/batch-inferences").json()
+        self._isSuccessful(response)
+
+        dict_list = []
+        for batch_inference in response["batchInferenceList"]:
+            dict_list.append(
+                {
+                    "id": batch_inference["batchInferenceId"],
+                    "name": batch_inference["batchInferenceName"],
+                }
+            )
+        return dict_list
+
+    def get_batch_inference_by_id(self, batch_inference_id):
+        response = self.session.get(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/batch-inferences/{batch_inference_id}").json()
+        self._isSuccessful(response)
+
+        return response
+
+    def delete_batch_inference_by_id(self, batch_inference_id):
+        response = self.session.delete(f"{self._easymakerApiUrl}/v1.0/appkeys/{self._appkey}/batch-inferences/{batch_inference_id}").json()
         self._isSuccessful(response)
 
         return response
 
     def send_logncrash(self, logncrash_body):
         response = self.session.post(constants.LOGNCRASH_URL, json=logncrash_body).json()
         return response
```

## easymaker/cli/cli.py

```diff
@@ -1,64 +1,55 @@
 import argparse
-import easymaker
 import os
+
+import easymaker
 from easymaker.api.api_sender import ApiSender
-from easymaker.common import environment_variables
 
 
 def main():
-    parser = argparse.ArgumentParser(prog='EasyMaker', description='EasyMaker Command-line interface.')
-    parser.add_argument("--version", action='version', version=easymaker.__version__)
-    parser.add_argument("--profile", dest='profile', required=False)
-
-    parser.add_argument("--appkey", dest='appkey', required=True)
-    parser.add_argument("--region", dest='region', required=True)
-    parser.add_argument("--secret_key", dest='secret_key', required=True)
+    parser = argparse.ArgumentParser(prog="EasyMaker", description="EasyMaker Command-line interface.")
+    parser.add_argument("--version", action="version", version=easymaker.__version__)
+    parser.add_argument("--profile", dest="profile", required=False)
 
-    parser.add_argument("-instance", dest='instance', action='store_true',
-                        help='Supported instance list, usage: python -m easymaker -instance --appkey APPKEY --region REGION --secret_key SECRET_KEY')
+    parser.add_argument("--appkey", dest="appkey", required=True)
+    parser.add_argument("--region", dest="region", required=True)
+    parser.add_argument("--secret_key", dest="secret_key", required=True)
 
-    parser.add_argument("-image", dest='image', action='store_true',
-                        help='Supported image list, usage: python -m easymaker -image --appkey APPKEY --region REGION --secret_key SECRET_KEY')
+    parser.add_argument("-instance", dest="instance", action="store_true", help="Supported instance list, usage: python -m easymaker -instance --appkey APPKEY --region REGION --secret_key SECRET_KEY")
 
-    parser.add_argument("-experiment", dest='experiment', action='store_true',
-                        help='Experiment list, usage: python -m easymaker -experiment --appkey APPKEY --region REGION --secret_key SECRET_KEY')
+    parser.add_argument("-image", dest="image", action="store_true", help="Supported image list, usage: python -m easymaker -image --appkey APPKEY --region REGION --secret_key SECRET_KEY")
 
-    parser.add_argument("-training", dest='training', action='store_true',
-                        help='Training list, usage: python -m easymaker -training --appkey APPKEY --region REGION --secret_key SECRET_KEY')
+    parser.add_argument("-experiment", dest="experiment", action="store_true", help="Experiment list, usage: python -m easymaker -experiment --appkey APPKEY --region REGION --secret_key SECRET_KEY")
 
-    parser.add_argument("-tuning", dest='tuning', action='store_true',
-                        help='Hyperparameter Tuning list, usage: python -m easymaker -tuning --appkey APPKEY --region REGION --secret_key SECRET_KEY')
+    parser.add_argument("-training", dest="training", action="store_true", help="Training list, usage: python -m easymaker -training --appkey APPKEY --region REGION --secret_key SECRET_KEY")
 
-    parser.add_argument("-model", dest='model', action='store_true',
-                        help='Model list, usage: python -m easymaker -model --appkey APPKEY --region REGION --secret_key SECRET_KEY')
+    parser.add_argument("-tuning", dest="tuning", action="store_true", help="Hyperparameter Tuning list, usage: python -m easymaker -tuning --appkey APPKEY --region REGION --secret_key SECRET_KEY")
 
-    parser.add_argument("-endpoint", dest='endpoint', action='store_true',
-                        help='Endpoint list, usage: python -m easymaker -endpoint --appkey APPKEY --region REGION --secret_key SECRET_KEY')
+    parser.add_argument("-model", dest="model", action="store_true", help="Model list, usage: python -m easymaker -model --appkey APPKEY --region REGION --secret_key SECRET_KEY")
 
-    parser.add_argument("-algorithm", dest='algorithm', action='store_true',
-                        help='Algorithm list, usage: python -m easymaker -algorithm --appkey APPKEY --region REGION --secret_key SECRET_KEY')
+    parser.add_argument("-endpoint", dest="endpoint", action="store_true", help="Endpoint list, usage: python -m easymaker -endpoint --appkey APPKEY --region REGION --secret_key SECRET_KEY")
 
+    parser.add_argument("-algorithm", dest="algorithm", action="store_true", help="Algorithm list, usage: python -m easymaker -algorithm --appkey APPKEY --region REGION --secret_key SECRET_KEY")
 
     args = parser.parse_args()
 
     region = args.region
     appkey = args.appkey
     secret_key = args.secret_key
     if args.profile:
         os.environ["EM_PROFILE"] = args.profile
 
     api_sender = ApiSender(region, appkey, secret_key)
 
     if args.instance:
         for item_list in api_sender.get_instance_list():
-            print(item_list['name'])
+            print(item_list["name"])
     elif args.image:
         for item_list in api_sender.get_image_list():
-            print(item_list['name'])
+            print(item_list["name"])
     elif args.experiment:
         for item_list in api_sender.get_experiment_list():
             print(f'Experinemt Name : {item_list["name"]}, Experinemt Id : {item_list["id"]}')
     elif args.training:
         for item_list in api_sender.get_training_list():
             print(f'Training Name : {item_list["name"]}, Training Id : {item_list["id"]}')
     elif args.tuning:
@@ -72,8 +63,8 @@
             print(f'Endpoint Name : {item_list["name"]}, Endpoint Id : {item_list["id"]}')
     elif args.algorithm:
         for item_list in api_sender.get_algorithm_list():
             print(f'Algorithm Name : {item_list["name"]}, Algorithm Id : {item_list["id"]}, Available Training Images: {item_list["availableTrainingImageList"]}')
 
 
 if __name__ == "__main__":
-    main()
+    main()
```

## easymaker/common/constants.py

```diff
@@ -1,40 +1,41 @@
-DEFAULT_REGION = 'kr1'
-SUPPORTED_REGIONS = {
-    'kr1',
-    'kr3'
-    # 'kr2',
-    # 'us',
-    # 'jp',
-}
-
+DEFAULT_REGION = "kr1"
 EASYMAKER_API_WAIT_INTERVAL_SECONDS = 10
 
 # EasyMaker API URL
-EASYMAKER_API_URL = 'https://{}-easymaker.api.nhncloudservice.com'
-EASYMAKER_DEV_API_URL = 'https://{}-easymaker-{}.api.nhncloudservice.com'
+EASYMAKER_API_URL = "https://{}-easymaker.api.nhncloudservice.com"
+EASYMAKER_DEV_API_URL = "https://{}-easymaker-{}.api.nhncloudservice.com"
 
 # Object Storage URL
-OBJECT_STORAGE_TOKEN_URL = 'https://api-identity-infrastructure.nhncloudservice.com/v2.0/tokens'
+OBJECT_STORAGE_TOKEN_URL = "https://api-identity-infrastructure.nhncloudservice.com/v2.0/tokens"
 
 # Log & Crash URL
-LOGNCRASH_URL = 'https://api-logncrash.nhncloudservice.com/v2/log'
+LOGNCRASH_URL = "https://api-logncrash.nhncloudservice.com/v2/log"
 LOGNCRASH_MAX_MESSAGE_SIZE = 8000000  # Log&Crash limit body size(= 8388608)
 LOGNCRASH_MAX_BUFFER_SIZE = 40000000  # Log&Crash HTTP     52MB
 
-class HYPERPARAMETER_TYPE_CODE():
-    INT = 'int'
-    DOUBLE = 'double'
-    DISCRETE = 'discrete'
-    CATEGORICAL = 'categorical'
-
-class OBJECTIVE_TYPE_CODE():
-    MINIMIZE = 'MINIMIZE'
-    MAXIMIZE = 'MAXIMIZE'
-
-class TUNING_STRATEGY():
-    GRID = 'GRID'
-    RANDOM = 'RANDOM'
-    BAYESIAN_OPTIMIZATION = 'BAYESIAN_OPTIMIZATION'
 
-class EARLY_STOPPING_ALGORITHM():
-    MEDIAN = 'MEDIAN'
+class HYPERPARAMETER_TYPE_CODE:
+    INT = "int"
+    DOUBLE = "double"
+    DISCRETE = "discrete"
+    CATEGORICAL = "categorical"
+
+
+class OBJECTIVE_TYPE_CODE:
+    MINIMIZE = "MINIMIZE"
+    MAXIMIZE = "MAXIMIZE"
+
+
+class TUNING_STRATEGY:
+    GRID = "GRID"
+    RANDOM = "RANDOM"
+    BAYESIAN_OPTIMIZATION = "BAYESIAN_OPTIMIZATION"
+
+
+class EARLY_STOPPING_ALGORITHM:
+    MEDIAN = "MEDIAN"
+
+
+class INPUT_DATA_TYPE_CODE:
+    JSON = "JSON"
+    JSONL = "JSONL"
```

## easymaker/common/environment_variables.py

```diff
@@ -1,11 +1,11 @@
-EM_PROFILE = 'EM_PROFILE'
+EM_PROFILE = "EM_PROFILE"
 
-EM_REGION = 'EM_REGION'
+EM_REGION = "EM_REGION"
 
-EM_APPKEY = 'EM_APPKEY'
+EM_APPKEY = "EM_APPKEY"
 
-EM_SECRET_KEY = 'EM_SECRET_KEY'
+EM_SECRET_KEY = "EM_SECRET_KEY"
 
-EM_TOKEN = 'EM_TOKEN'
+EM_TOKEN = "EM_TOKEN"
 
-EM_GROUP_ID = 'EM_GROUP_ID'
+EM_GROUP_ID = "EM_GROUP_ID"
```

## easymaker/common/exceptions.py

 * *Ordering differences only*

```diff
@@ -7,8 +7,8 @@
 
 
 class EasyMakerRegionError(EasyMakerError):
     pass
 
 
 class EasyMakerDockerError(Exception):
-    pass
+    pass
```

## easymaker/common/utils/__init__.py

```diff
@@ -1,36 +1,9 @@
-from easymaker.common import constants
-from easymaker.common.exceptions import EasyMakerRegionError, EasyMakerError
-
-
-def validate_region(region: str) -> bool:
-    """Validates region against supported regions.
-
-    Args:
-        region: region to validate
-    Returns:
-        bool: True if no errors raised
-    Raises:
-        ValueError: If region is not in supported regions.
-    """
-    if not region:
-        raise EasyMakerRegionError(
-            f"Please provide a region"
-        )
-
-    region = region.lower()
-    if region not in constants.SUPPORTED_REGIONS:
-        raise EasyMakerRegionError(
-            f"Unsupported region"
-        )
-
-    return True
+from easymaker.common.exceptions import EasyMakerError
 
 
 def from_name_to_id(list: list, name: str) -> str:
     for item in list:
-        if item['name'] == name:
-            return item['id']
+        if item["name"] == name:
+            return item["id"]
 
-    raise EasyMakerError(
-        f"Invalid name : {name}"
-    )
+    raise EasyMakerError(f"Invalid name : {name}")
```

## easymaker/common/utils/status_code_utils.py

```diff
@@ -1,29 +1,28 @@
-RESOURCE_CREATE_STATUS_CODE = 'CREATE_IN_PROGRESS'
-RESOURCE_CREATE_STATUS_CODE_LIST = ['CREATE_IN_PROGRESS', 'CREATE_CLEAR_IN_PROGRESS', 'CREATE_CLEAR_FAILED',
-                                    'CREATE_CLUSTER_IN_PROGRESS', 'CREATE_NODEGROUP_IN_PROGRESS', 'CREATE_NAS_IN_PROGRESS', 'CREATE_K8S_RESOURCES_IN_PROGRESS', 'CREATE_KUBEFLOW_PIPELINE_RUN_IN_PROGRESS']
-RESOURCE_FAIL_STATUS_CODE = 'CREATE_FAILED'
-RESOURCE_FAIL_STATUS_CODE_LIST = ['CREATE_FAILED',
-                                  'FAILED_TO_CREATE_CLUSTER', 'FAILED_TO_CREATE_NODEGROUP', 'FAILED_TO_CREATE_NAS', 'FAILED_TO_CREATE_K8S_RESOURCES', 'FAILED_TO_CREATE_KUBEFLOW_PIPELINE_RUN']
+RESOURCE_CREATE_STATUS_CODE = "CREATE_IN_PROGRESS"
+RESOURCE_CREATE_STATUS_CODE_LIST = ["CREATE_IN_PROGRESS", "CREATE_CLEAR_IN_PROGRESS", "CREATE_CLEAR_FAILED", "CREATE_CLUSTER_IN_PROGRESS", "CREATE_NODEGROUP_IN_PROGRESS", "CREATE_NAS_IN_PROGRESS", "CREATE_K8S_RESOURCES_IN_PROGRESS", "CREATE_KUBEFLOW_PIPELINE_RUN_IN_PROGRESS"]
+RESOURCE_FAIL_STATUS_CODE = "CREATE_FAILED"
+RESOURCE_FAIL_STATUS_CODE_LIST = ["CREATE_FAILED", "FAILED_TO_CREATE_CLUSTER", "FAILED_TO_CREATE_NODEGROUP", "FAILED_TO_CREATE_NAS", "FAILED_TO_CREATE_K8S_RESOURCES", "FAILED_TO_CREATE_KUBEFLOW_PIPELINE_RUN"]
 
-RESOURCE_STOP_IN_PROGRESS_CODE = 'STOP_IN_PROGRESS'
-RESOURCE_STOP_IN_PROGRESS_CODE_LIST = ['STOP_IN_PROGRESS', 'STOP_FAILED']
+RESOURCE_STOP_IN_PROGRESS_CODE = "STOP_IN_PROGRESS"
+RESOURCE_STOP_IN_PROGRESS_CODE_LIST = ["STOP_IN_PROGRESS", "STOP_FAILED"]
 
-RESOURCE_COMPLETE_IN_PROGRESS_CODE = 'COMPLETE_IN_PROGRESS'
-RESOURCE_COMPLETE_IN_PROGRESS_CODE_LIST = ['COMPLETE_IN_PROGRESS', 'COMPLETE_FAILED']
+RESOURCE_COMPLETE_IN_PROGRESS_CODE = "COMPLETE_IN_PROGRESS"
+RESOURCE_COMPLETE_IN_PROGRESS_CODE_LIST = ["COMPLETE_IN_PROGRESS", "COMPLETE_FAILED"]
+
+RESOURCE_FAIL_TRAIN_IN_PROGRESS_CODE = "FAIL_TRAIN_IN_PROGRESS"
+RESOURCE_FAIL_TRAIN_IN_PROGRESS_CODE_LIST = ["FAIL_TRAIN_IN_PROGRESS", "FAIL_TRAIN_FAILED"]
 
-RESOURCE_FAIL_TRAIN_IN_PROGRESS_CODE = 'FAIL_TRAIN_IN_PROGRESS'
-RESOURCE_FAIL_TRAIN_IN_PROGRESS_CODE_LIST = ['FAIL_TRAIN_IN_PROGRESS', 'FAIL_TRAIN_FAILED']
 
 def replace_status_code(status):
     if status in RESOURCE_CREATE_STATUS_CODE_LIST:
         return RESOURCE_CREATE_STATUS_CODE
     elif status in RESOURCE_FAIL_STATUS_CODE_LIST:
         return RESOURCE_FAIL_STATUS_CODE
     elif status in RESOURCE_STOP_IN_PROGRESS_CODE_LIST:
         return RESOURCE_STOP_IN_PROGRESS_CODE
     elif status in RESOURCE_COMPLETE_IN_PROGRESS_CODE_LIST:
         return RESOURCE_COMPLETE_IN_PROGRESS_CODE
     elif status in RESOURCE_FAIL_TRAIN_IN_PROGRESS_CODE_LIST:
         return RESOURCE_FAIL_TRAIN_IN_PROGRESS_CODE
     else:
-        return status
+        return status
```

## easymaker/endpoint/endpoint.py

```diff
@@ -1,150 +1,155 @@
-import requests
 import time
 from datetime import timedelta
+
+import requests
+
 import easymaker
-from easymaker.common import exceptions
-from easymaker.common import utils
+from easymaker.common import constants, exceptions, utils
 from easymaker.common.utils import status_code_utils
-from easymaker.common import constants
+
 
 class Endpoint:
     def __init__(self, endpoint_id=None):
         """
         Args:
             endpoint_id (str): Endpoint Id
         """
         self.easymaker_api_sender = easymaker.easymaker_config.api_sender
         if endpoint_id is not None:
             self.endpoint_id = endpoint_id
 
-    def create(self,
-               endpoint_name,
-               endpoint_instance_name,
-               endpoint_model_resource_list,
-               endpoint_instance_count=1,
-               endpoint_description=None,
-               tag_list=None,
-               use_log=False,
-               wait=True,
-               autoscaler_enable=False,
-               autoscaler_min_node_count=1,
-               autoscaler_max_node_count=10,
-               autoscaler_scale_down_enable=True,
-               autoscaler_scale_down_util_threshold=50,
-               autoscaler_scale_down_unneeded_time=10,
-               autoscaler_scale_down_delay_after_add=10,
-               ):
+    def create(
+        self,
+        endpoint_name,
+        endpoint_instance_name,
+        endpoint_model_resource_list,
+        endpoint_instance_count=1,
+        endpoint_description=None,
+        tag_list=None,
+        use_log=False,
+        wait=True,
+        autoscaler_enable=False,
+        autoscaler_min_node_count=1,
+        autoscaler_max_node_count=10,
+        autoscaler_scale_down_enable=True,
+        autoscaler_scale_down_util_threshold=50,
+        autoscaler_scale_down_unneeded_time=10,
+        autoscaler_scale_down_delay_after_add=10,
+    ):
         """
         Returns:
             endpoint_id(str)
         """
 
         self.instance_list = self.easymaker_api_sender.get_instance_list()
-        response = self.easymaker_api_sender.create_endpoint(endpoint_name=endpoint_name,
-                                                             endpoint_description=endpoint_description,
-                                                             flavor_id=utils.from_name_to_id(self.instance_list, endpoint_instance_name),
-                                                             endpoint_model_resource_list=endpoint_model_resource_list,
-                                                             node_count=endpoint_instance_count,
-                                                             tag_list=tag_list,
-                                                             use_log=use_log,
-                                                             ca_enable=autoscaler_enable,
-                                                             ca_min_node_count=autoscaler_min_node_count,
-                                                             ca_max_node_count=autoscaler_max_node_count,
-                                                             ca_scale_down_enable=autoscaler_scale_down_enable,
-                                                             ca_scale_down_util_thresh=autoscaler_scale_down_util_threshold,
-                                                             ca_scale_down_unneeded_time=autoscaler_scale_down_unneeded_time,
-                                                             ca_scale_down_delay_after_add=autoscaler_scale_down_delay_after_add,
-                                                             )
+        response = self.easymaker_api_sender.create_endpoint(
+            endpoint_name=endpoint_name,
+            endpoint_description=endpoint_description,
+            flavor_id=utils.from_name_to_id(self.instance_list, endpoint_instance_name),
+            endpoint_model_resource_list=endpoint_model_resource_list,
+            node_count=endpoint_instance_count,
+            tag_list=tag_list,
+            use_log=use_log,
+            ca_enable=autoscaler_enable,
+            ca_min_node_count=autoscaler_min_node_count,
+            ca_max_node_count=autoscaler_max_node_count,
+            ca_scale_down_enable=autoscaler_scale_down_enable,
+            ca_scale_down_util_thresh=autoscaler_scale_down_util_threshold,
+            ca_scale_down_unneeded_time=autoscaler_scale_down_unneeded_time,
+            ca_scale_down_delay_after_add=autoscaler_scale_down_delay_after_add,
+        )
 
-        self.endpoint_id = response['endpoint']['endpointId']
+        self.endpoint_id = response["endpoint"]["endpointId"]
         default_endpoint_stage_info = self.get_default_endpoint_stage()
-        endpoint_stage_id = default_endpoint_stage_info['endpointStageId']
+        endpoint_stage_id = default_endpoint_stage_info["endpointStageId"]
         if wait:
             waiting_time_seconds = 0
-            endpoint_status = status_code_utils.replace_status_code(response['endpoint']['endpointStatusCode'])
-            while endpoint_status != 'ACTIVE':
-                print(f'[AI EasyMaker] Endpoint create status : {endpoint_status} ({timedelta(seconds=waiting_time_seconds)}) Please wait...')
+            endpoint_status = status_code_utils.replace_status_code(response["endpoint"]["endpointStatusCode"])
+            while endpoint_status != "ACTIVE":
+                print(f"[AI EasyMaker] Endpoint create status : {endpoint_status} ({timedelta(seconds=waiting_time_seconds)}) Please wait...")
                 time.sleep(constants.EASYMAKER_API_WAIT_INTERVAL_SECONDS)
                 waiting_time_seconds += constants.EASYMAKER_API_WAIT_INTERVAL_SECONDS
                 endpoint = self.easymaker_api_sender.get_endpoint_by_id(self.endpoint_id)
-                endpoint_status = endpoint['endpointStatusCode']
-                if 'FAIL' in endpoint_status:
-                    endpoint['endpoint']['endpointStatusCode'] = endpoint_status
+                endpoint_status = endpoint["endpointStatusCode"]
+                if "FAIL" in endpoint_status:
+                    endpoint["endpoint"]["endpointStatusCode"] = endpoint_status
                     raise exceptions.EasyMakerError(endpoint)
 
-            endpoint_stage_status = 'CREATE_REQUESTED'
-            while endpoint_stage_status != 'ACTIVE':
-                print(f'[AI EasyMaker] Endpoint stage create status : {endpoint_stage_status} ({timedelta(seconds=waiting_time_seconds)}) Please wait...')
+            endpoint_stage_status = "CREATE_REQUESTED"
+            while endpoint_stage_status != "ACTIVE":
+                print(f"[AI EasyMaker] Endpoint stage create status : {endpoint_stage_status} ({timedelta(seconds=waiting_time_seconds)}) Please wait...")
                 time.sleep(constants.EASYMAKER_API_WAIT_INTERVAL_SECONDS)
                 waiting_time_seconds += constants.EASYMAKER_API_WAIT_INTERVAL_SECONDS
                 default_endpoint_stage_info = self.easymaker_api_sender.get_endpoint_stage_by_id(endpoint_stage_id)
-                endpoint_stage_status = default_endpoint_stage_info['endpointStageStatusCode']
-                if 'FAIL' in endpoint_stage_status:
+                endpoint_stage_status = default_endpoint_stage_info["endpointStageStatusCode"]
+                if "FAIL" in endpoint_stage_status:
                     raise exceptions.EasyMakerError(default_endpoint_stage_info)
-            print(f'[AI EasyMaker] Endpoint create complete. Endpoint Id : {self.endpoint_id}, Default Stage Id : {endpoint_stage_id}')
+            print(f"[AI EasyMaker] Endpoint create complete. Endpoint Id : {self.endpoint_id}, Default Stage Id : {endpoint_stage_id}")
         else:
-            print(f'[AI EasyMaker] Endpoint create request complete. Endpoint Id : {self.endpoint_id}')
+            print(f"[AI EasyMaker] Endpoint create request complete. Endpoint Id : {self.endpoint_id}")
         return self.endpoint_id
 
-    def create_stage(self,
-                     stage_name,
-                     endpoint_instance_name,
-                     endpoint_model_resource_list,
-                     endpoint_instance_count=1,
-                     stage_description=None,
-                     tag_list=None,
-                     use_log=False,
-                     wait=True,
-                     autoscaler_enable=False,
-                     autoscaler_min_node_count=1,
-                     autoscaler_max_node_count=10,
-                     autoscaler_scale_down_enable=True,
-                     autoscaler_scale_down_util_threshold=50,
-                     autoscaler_scale_down_unneeded_time=10,
-                     autoscaler_scale_down_delay_after_add=10,
-                     ):
+    def create_stage(
+        self,
+        stage_name,
+        endpoint_instance_name,
+        endpoint_model_resource_list,
+        endpoint_instance_count=1,
+        stage_description=None,
+        tag_list=None,
+        use_log=False,
+        wait=True,
+        autoscaler_enable=False,
+        autoscaler_min_node_count=1,
+        autoscaler_max_node_count=10,
+        autoscaler_scale_down_enable=True,
+        autoscaler_scale_down_util_threshold=50,
+        autoscaler_scale_down_unneeded_time=10,
+        autoscaler_scale_down_delay_after_add=10,
+    ):
         """
         Returns:
             endpoint_stage_id(str)
         """
 
         self.instance_list = self.easymaker_api_sender.get_instance_list()
-        response = self.easymaker_api_sender.create_stage(endpoint_id=self.endpoint_id,
-                                                          stage_name=stage_name,
-                                                          stage_description=stage_description,
-                                                          flavor_id=utils.from_name_to_id(self.instance_list, endpoint_instance_name),
-                                                          endpoint_model_resource_list=endpoint_model_resource_list,
-                                                          node_count=endpoint_instance_count,
-                                                          tag_list=tag_list,
-                                                          use_log=use_log,
-                                                          ca_enable=autoscaler_enable,
-                                                          ca_min_node_count=autoscaler_min_node_count,
-                                                          ca_max_node_count=autoscaler_max_node_count,
-                                                          ca_scale_down_enable=autoscaler_scale_down_enable,
-                                                          ca_scale_down_util_thresh=autoscaler_scale_down_util_threshold,
-                                                          ca_scale_down_unneeded_time=autoscaler_scale_down_unneeded_time,
-                                                          ca_scale_down_delay_after_add=autoscaler_scale_down_delay_after_add,
-                                                          )
+        response = self.easymaker_api_sender.create_stage(
+            endpoint_id=self.endpoint_id,
+            stage_name=stage_name,
+            stage_description=stage_description,
+            flavor_id=utils.from_name_to_id(self.instance_list, endpoint_instance_name),
+            endpoint_model_resource_list=endpoint_model_resource_list,
+            node_count=endpoint_instance_count,
+            tag_list=tag_list,
+            use_log=use_log,
+            ca_enable=autoscaler_enable,
+            ca_min_node_count=autoscaler_min_node_count,
+            ca_max_node_count=autoscaler_max_node_count,
+            ca_scale_down_enable=autoscaler_scale_down_enable,
+            ca_scale_down_util_thresh=autoscaler_scale_down_util_threshold,
+            ca_scale_down_unneeded_time=autoscaler_scale_down_unneeded_time,
+            ca_scale_down_delay_after_add=autoscaler_scale_down_delay_after_add,
+        )
         endpoint_stage = {}
-        endpoint_stage_id = response['endpointStage']['endpointStageId']
+        endpoint_stage_id = response["endpointStage"]["endpointStageId"]
         if wait:
             waiting_time_seconds = 0
-            endpoint_stage_status = 'CREATE_REQUESTED'
-            while endpoint_stage_status != 'ACTIVE':
-                print(f'[AI EasyMaker] Endpoint stage create status : {endpoint_stage_status} ({timedelta(seconds=waiting_time_seconds)}) Please wait...')
+            endpoint_stage_status = "CREATE_REQUESTED"
+            while endpoint_stage_status != "ACTIVE":
+                print(f"[AI EasyMaker] Endpoint stage create status : {endpoint_stage_status} ({timedelta(seconds=waiting_time_seconds)}) Please wait...")
                 time.sleep(constants.EASYMAKER_API_WAIT_INTERVAL_SECONDS)
                 waiting_time_seconds += constants.EASYMAKER_API_WAIT_INTERVAL_SECONDS
                 endpoint_stage = self.easymaker_api_sender.get_endpoint_stage_by_id(endpoint_stage_id)
-                endpoint_stage_status = endpoint_stage['endpointStageStatusCode']
-                if 'FAIL' in endpoint_stage_status:
+                endpoint_stage_status = endpoint_stage["endpointStageStatusCode"]
+                if "FAIL" in endpoint_stage_status:
                     raise exceptions.EasyMakerError(endpoint_stage)
-            print(f'[AI EasyMaker] Stage create complete. Stage Id : {endpoint_stage_id}')
+            print(f"[AI EasyMaker] Stage create complete. Stage Id : {endpoint_stage_id}")
         else:
-            print(f'[AI EasyMaker] Stage create request complete.')
+            print(f"[AI EasyMaker] Stage create request complete.")
         return endpoint_stage_id
 
     def get_endpoint_list(self):
         return self.easymaker_api_sender.get_endpoint_list()
 
     def get_endpoint_by_id(self):
         return self.easymaker_api_sender.get_endpoint_by_id(self.endpoint_id)
@@ -152,15 +157,15 @@
     def get_endpoint_stage_list(self):
         return self.easymaker_api_sender.get_endpoint_stage_list(self.endpoint_id)
 
     def get_default_endpoint_stage(self):
         endpoint_stage_list = self.easymaker_api_sender.get_endpoint_stage_list(self.endpoint_id)
 
         for endpoint_stage in endpoint_stage_list:
-            if endpoint_stage['defaultStage']:
+            if endpoint_stage["defaultStage"]:
                 return endpoint_stage
 
         return None
 
     def get_endpoint_stage_by_id(self, endpoint_stage_id):
         return self.easymaker_api_sender.get_endpoint_stage_by_id(endpoint_stage_id=endpoint_stage_id)
 
@@ -168,27 +173,27 @@
         return self.easymaker_api_sender.get_endpoint_model_list(endpoint_stage_id=endpoint_stage_id)
 
     def get_endpoint_model_by_id(self, endpoint_model_id):
         return self.easymaker_api_sender.get_endpoint_model_by_id(endpoint_model_id=endpoint_model_id)
 
     def delete_endpoint(self, endpoint_id):
         response = self.easymaker_api_sender.delete_endpoint_by_id(endpoint_id=endpoint_id)
-        print(f'[AI EasyMaker] Endpoint delete request complete. Endpoint Id : {endpoint_id}')
+        print(f"[AI EasyMaker] Endpoint delete request complete. Endpoint Id : {endpoint_id}")
         return response
 
     def delete_endpoint_stage(self, endpoint_stage_id):
         response = self.easymaker_api_sender.delete_endpoint_stage_by_id(endpoint_stage_id=endpoint_stage_id)
-        print(f'[AI EasyMaker] Endpoint stage delete request complete. Endpoint stage Id : {endpoint_stage_id}')
+        print(f"[AI EasyMaker] Endpoint stage delete request complete. Endpoint stage Id : {endpoint_stage_id}")
         return response
 
     def delete_endpoint_model(self, endpoint_model_id):
         response = self.easymaker_api_sender.delete_endpoint_model_by_id(endpoint_model_id=endpoint_model_id)
-        print(f'[AI EasyMaker] Endpoint model delete request complete. Endpoint model Id : {endpoint_model_id}')
+        print(f"[AI EasyMaker] Endpoint model delete request complete. Endpoint model Id : {endpoint_model_id}")
         return response
 
     def predict(self, endpoint_stage_info, model_id, json=None, files=None, data=None, headers=None):
-        endpoint_url = 'https://' + endpoint_stage_info['apigwStageUrl']
-        resource_uri = next((x for x in endpoint_stage_info['endpointModelList'] if x['modelId'] == model_id), {}).get('apigwResourceUri', '')
+        endpoint_url = "https://" + endpoint_stage_info["apigwStageUrl"]
+        resource_uri = next((x for x in endpoint_stage_info["endpointModelList"] if x["modelId"] == model_id), {}).get("apigwResourceUri", "")
         endpoint_url = endpoint_url + resource_uri
 
         response = requests.post(endpoint_url, json=json, files=files, data=data, headers=headers).json()
         return response
```

## easymaker/experiment/experiment.py

```diff
@@ -1,49 +1,45 @@
 import time
 from datetime import timedelta
+
 import easymaker
-from easymaker.common import exceptions
-from easymaker.common import constants
+from easymaker.common import constants, exceptions
 from easymaker.common.utils import status_code_utils
 
 
 class Experiment:
     def __init__(self):
         self.easymaker_api_sender = easymaker.easymaker_config.api_sender
 
-    def create(self,
-               experiment_name,
-               experiment_description=None,
-               wait=True):
+    def create(self, experiment_name, experiment_description=None, wait=True):
         """
         Args:
             experiment_name (str): Experiment name
             experiment_description (str): Experiment description
             wait (bool): wait for the job to complete
         Returns:
             experiment_id
         """
-        response = self.easymaker_api_sender.create_experiment(experiment_name=experiment_name,
-                                                               experiment_description=experiment_description)
-        experiment_id = response['experiment']['experimentId']
+        response = self.easymaker_api_sender.create_experiment(experiment_name=experiment_name, experiment_description=experiment_description)
+        experiment_id = response["experiment"]["experimentId"]
         if wait:
             waiting_time_seconds = 0
-            experiment_status = status_code_utils.replace_status_code(response['experiment']['experimentStatusCode'])
-            while experiment_status != 'ACTIVE':
-                print(f'[AI EasyMaker] Experiment create status : {experiment_status} ({timedelta(seconds=waiting_time_seconds)}) Please wait...')
+            experiment_status = status_code_utils.replace_status_code(response["experiment"]["experimentStatusCode"])
+            while experiment_status != "ACTIVE":
+                print(f"[AI EasyMaker] Experiment create status : {experiment_status} ({timedelta(seconds=waiting_time_seconds)}) Please wait...")
                 time.sleep(constants.EASYMAKER_API_WAIT_INTERVAL_SECONDS)
                 waiting_time_seconds += constants.EASYMAKER_API_WAIT_INTERVAL_SECONDS
                 experiment = self.easymaker_api_sender.get_experiment_by_id(experiment_id)
-                experiment_status = status_code_utils.replace_status_code(experiment['experiment']['experimentStatusCode'])
-                if 'FAIL' in experiment_status:
-                    experiment['experiment']['experimentStatusCode'] = experiment_status
+                experiment_status = status_code_utils.replace_status_code(experiment["experiment"]["experimentStatusCode"])
+                if "FAIL" in experiment_status:
+                    experiment["experiment"]["experimentStatusCode"] = experiment_status
                     raise exceptions.EasyMakerError(experiment)
-            print(f'[AI EasyMaker] Experiment create complete. Experiment Id : {experiment_id}')
+            print(f"[AI EasyMaker] Experiment create complete. Experiment Id : {experiment_id}")
         else:
-            print(f'[AI EasyMaker] Experiment create request complete. Experiment Id : {experiment_id}')
+            print(f"[AI EasyMaker] Experiment create request complete. Experiment Id : {experiment_id}")
 
         return experiment_id
 
     def delete(self, experiment_id):
         response = self.easymaker_api_sender.delete_experiment_by_id(experiment_id=experiment_id)
-        print(f'[AI EasyMaker] Experiment delete request complete. Experiment Id : {experiment_id}')
+        print(f"[AI EasyMaker] Experiment delete request complete. Experiment Id : {experiment_id}")
         return response
```

## easymaker/image/docker_builder.py

```diff
@@ -1,178 +1,159 @@
 # -*- coding: utf-8 -*-
-import docker
 import json
-import tempfile
 import os
 import tarfile
-from easymaker.common import constants
-from easymaker.common import exceptions
+import tempfile
+
+import docker
+
+from easymaker.common import constants, exceptions
 
 
 class DockerBuilder:
-    def __init__(self,
-                 container_registry=None,
-                 container_username=None,
-                 container_password=None
-                 ):
+    def __init__(self, container_registry=None, container_username=None, container_password=None):
 
         self.container_registry = container_registry
         self.container_username = container_username
         self.container_password = container_password
 
         # TODO Default Worker    Docker   (base_url)
-        self.docker_client = docker.APIClient(version='auto')
+        self.docker_client = docker.APIClient(version="auto")
 
     def _login(self, registry, username, password):
-        self.docker_client.login(
-            registry=registry,
-            username=username,
-            password=password,
-            reauth=True
-        )
-
-    def build(self, build_image, dockerfile_path=None,
-              base_image=None, docker_command=None, contents_dir=None, work_dir=None, install_requirements_before_copy=False,
-              ):
-        '''
+        self.docker_client.login(registry=registry, username=username, password=password, reauth=True)
+
+    def build(
+        self,
+        build_image,
+        dockerfile_path=None,
+        base_image=None,
+        docker_command=None,
+        contents_dir=None,
+        work_dir=None,
+        install_requirements_before_copy=False,
+    ):
+        """
         :param build_image:     
         :param dockerfile_path: dockerfile path    ,       ,
         :param contents_dir:       
         :param base_image: docker base image
         :param docker_command: dockerfile CMD   
         :param work_dir:      
         :return:
-        '''
-        self._login(constants.DEFAULT_CONTAINER_REGISTRY_URI,
-                    constants.DEFAULT_CONTAINER_REGISTRY_USERNAME,
-                    constants.DEFAULT_CONTAINER_REGISTRY_PASSWORD)
+        """
+        self._login(constants.DEFAULT_CONTAINER_REGISTRY_URI, constants.DEFAULT_CONTAINER_REGISTRY_USERNAME, constants.DEFAULT_CONTAINER_REGISTRY_PASSWORD)
 
         if dockerfile_path:
             if not contents_dir:
                 contents_dir = os.path.dirname(dockerfile_path)
         else:
             dockerfile_path = self._write_dockerfile(
                 docker_command=docker_command,
                 base_image=base_image,
                 work_dir=work_dir,
                 install_requirements_before_copy=install_requirements_before_copy,
             )
 
-        _context_tar_path = self._context_tar_gz(dockerfile_path=dockerfile_path,
-                                                 contents_dir=contents_dir)
+        _context_tar_path = self._context_tar_gz(dockerfile_path=dockerfile_path, contents_dir=contents_dir)
 
-        with open(_context_tar_path, 'rb') as fileobj:
-            build_output = self.docker_client.build(
-                fileobj=fileobj,
-                tag=build_image,
-                custom_context=True,
-                encoding='utf-8'
-            )
+        with open(_context_tar_path, "rb") as fileobj:
+            build_output = self.docker_client.build(fileobj=fileobj, tag=build_image, custom_context=True, encoding="utf-8")
             for line in build_output:
                 self._process_stream(line)
 
     def push(self, image):
-        self._login(self.container_registry,
-                    self.container_username,
-                    self.container_password)
+        self._login(self.container_registry, self.container_username, self.container_password)
 
-        print('Publishing image {}...'.format(image))
+        print("Publishing image {}...".format(image))
         for line in self.docker_client.push(image, stream=True):
             self._process_stream(line)
 
     def _process_stream(self, line):
         """
         Parse the docker command output by line
         """
-        lines = line.decode('utf-8').strip().split('\n')
+        lines = line.decode("utf-8").strip().split("\n")
         for line in lines:
             try:
                 json_data = json.loads(line)
-                if json_data.get('error'):
-                    msg = str(json_data.get('error', json_data))
-                    print('Build failed: %s', msg)
-                    raise exceptions.EasyMakerDockerError('Image build failed: ' + msg)
+                if json_data.get("error"):
+                    msg = str(json_data.get("error", json_data))
+                    print("Build failed: %s", msg)
+                    raise exceptions.EasyMakerDockerError("Image build failed: " + msg)
                 else:
-                    if json_data.get('stream'):
-                        msg = 'Build output: {}'.format(
-                            json_data['stream'].strip())
-                    elif json_data.get('status'):
-                        msg = 'Push output: {} {}'.format(
-                            json_data['status'],
-                            json_data.get('progress')
-                        )
-                    elif json_data.get('aux'):
-                        msg = 'Push finished: {}'.format(json_data.get('aux'))
+                    if json_data.get("stream"):
+                        msg = "Build output: {}".format(json_data["stream"].strip())
+                    elif json_data.get("status"):
+                        msg = "Push output: {} {}".format(json_data["status"], json_data.get("progress"))
+                    elif json_data.get("aux"):
+                        msg = "Push finished: {}".format(json_data.get("aux"))
                     else:
                         msg = str(json_data)
                     print(msg)
 
             except json.JSONDecodeError:
-                print('JSON decode error: {}'.format(line))
+                print("JSON decode error: {}".format(line))
 
     def _write_dockerfile(
-            self,
-            base_image=None,
-            docker_command=None,
-            destination=None,
-            work_dir=None,
-            install_requirements_before_copy=False,
+        self,
+        base_image=None,
+        docker_command=None,
+        destination=None,
+        work_dir=None,
+        install_requirements_before_copy=False,
     ):
         if not work_dir:
             work_dir = constants.DEFAULT_WORKDIR
         if not destination:
             _, destination = tempfile.mkstemp(prefix="/tmp/dockerfile_")
 
-        content_lines = ["FROM {}".format(base_image),
-                         "WORKDIR {}".format(work_dir),
-                         "ENV EASYMAKER_RUNTIME 1"]
+        content_lines = ["FROM {}".format(base_image), "WORKDIR {}".format(work_dir), "ENV EASYMAKER_RUNTIME 1"]
 
         if install_requirements_before_copy:
             content_lines.append("COPY ./requirements.txt {}".format(work_dir))
-        content_lines.append("RUN if [ -e requirements.txt ];" +
-                             "then pip install --no-cache -r requirements.txt; fi")
+        content_lines.append("RUN if [ -e requirements.txt ];" + "then pip install --no-cache -r requirements.txt; fi")
         copy_context = "COPY ./ {}".format(work_dir)
         content_lines.append(copy_context)
 
         if docker_command:
             content_lines.append("CMD {}".format(" ".join(docker_command)))
 
         content = "\n".join(content_lines)
-        with open(destination, 'w') as f:
+        with open(destination, "w") as f:
             f.write(content)
         return destination
 
     def _context_tar_gz(self, dockerfile_path, contents_dir=None, output_file=None):
         if not output_file:
             _, output_file = tempfile.mkstemp(prefix="/tmp/fairing_context_")
-        print(f'Creating docker context: {output_file}')
+        print(f"Creating docker context: {output_file}")
         with tarfile.open(output_file, "w:gz", dereference=True) as tar:
-            print(f'Context: {output_file}, Adding {dockerfile_path}')
-            tar.add(dockerfile_path, arcname='Dockerfile')
+            print(f"Context: {output_file}, Adding {dockerfile_path}")
+            tar.add(dockerfile_path, arcname="Dockerfile")
             if contents_dir:
-                print(f'Context: {output_file}, Adding {contents_dir}')
-                tar.add(contents_dir, arcname='.')
+                print(f"Context: {output_file}, Adding {contents_dir}")
+                tar.add(contents_dir, arcname=".")
 
         return output_file
 
 
 # TODO.  
 if __name__ == "__main__":
-    USER_CONTAINER_REGISTRY_URI = '1bc85ba3-kr1-registry.container.cloud.toast.com/easymaker'
-    CONTAINER_USERNAME = 'I7XDyq6mxK4DKLUfWbFB'
-    CONTAINER_PASSWORD = 'z6aJqeCXAtYCFNCI'
+    USER_CONTAINER_REGISTRY_URI = "1bc85ba3-kr1-registry.container.cloud.toast.com/easymaker"
+    CONTAINER_USERNAME = "I7XDyq6mxK4DKLUfWbFB"
+    CONTAINER_PASSWORD = "z6aJqeCXAtYCFNCI"
 
-    TRAINING_IMAGE = USER_CONTAINER_REGISTRY_URI + '/build_test:0.5'
+    TRAINING_IMAGE = USER_CONTAINER_REGISTRY_URI + "/build_test:0.5"
 
     docker_builder = DockerBuilder(USER_CONTAINER_REGISTRY_URI, CONTAINER_USERNAME, CONTAINER_PASSWORD)
 
     # build example
-    docker_builder.build(build_image=TRAINING_IMAGE,
-                         dockerfile_path='/Users/nhn/IdeaProjects/EasyMaker.SDK/sample/docker/Dockerfile')
+    docker_builder.build(build_image=TRAINING_IMAGE, dockerfile_path="/Users/nhn/IdeaProjects/EasyMaker.SDK/sample/docker/Dockerfile")
     # docker_builder.build(build_image=TRAINING_IMAGE,
     #                      base_image='centos:latest',
     #                      contents_dir='/Users/nhn/IdeaProjects/EasyMaker.SDK/sample/docker',
     #                      work_dir='/app/',
     #                      docker_command=['echo hello'])
 
     # push
-    docker_builder.push(TRAINING_IMAGE)
+    docker_builder.push(TRAINING_IMAGE)
```

## easymaker/log/logger.py

```diff
@@ -1,62 +1,51 @@
-import easymaker
-from easymaker.common import exceptions
-from easymaker.common import constants
-import time
-import threading
 import atexit
+import threading
+import time
+
+import easymaker
+from easymaker.common import constants, exceptions
 
 
 class Logger:
     def __init__(self, logncrash_appkey=None):
         """
         Args:
             logncrash_appkey (str): NHN Cloud Log&Crash app_key
         """
         self.easymaker_api_sender = easymaker.easymaker_config.api_sender
         self.logncrash_appkey = logncrash_appkey
         self.buffer = []
         atexit.register(self._flush_message)  # python  flush 
         threading.Timer(1, self._flush_message).start()  # 1 flush
 
-    def send(self,
-             log_message,
-             log_level='INFO',
-             project_version='1.0.0',
-             parameters={}):
+    def send(self, log_message, log_level="INFO", project_version="1.0.0", parameters={}):
         """
         Args:
             log_message (str): size limit 8000000
         """
         try:
-            logncrash_body = {
-                'category': 'easymaker.sdk',
-                'logType': 'NHN Cloud - AI EasyMaker',
-                'projectName': self.logncrash_appkey,
-                'body': log_message,
-                'logLevel': log_level,
-                'projectVersion': project_version,
-                'sendTime': time.time(),
-                'host': 'easymaker'
-            }
+            logncrash_body = {"category": "easymaker.sdk", "logType": "NHN Cloud - AI EasyMaker", "projectName": self.logncrash_appkey, "body": log_message, "logLevel": log_level, "projectVersion": project_version, "sendTime": time.time(), "host": "easymaker"}
             logncrash_body.update(parameters)
-            logncrash_body.update({
-                'logVersion': 'v2',
-            })
+            logncrash_body.update(
+                {
+                    "logVersion": "v2",
+                }
+            )
 
             if len(str(logncrash_body)) > constants.LOGNCRASH_MAX_MESSAGE_SIZE:
                 self._flush_message()
-                raise exceptions.EasyMakerError('Log message size more than limit size')
+                raise exceptions.EasyMakerError("Log message size more than limit size")
 
             if self.logncrash_appkey:
                 self.buffer.append(logncrash_body)
                 if len(str(self.buffer)) > constants.LOGNCRASH_MAX_BUFFER_SIZE:
                     self._flush_message()
 
         except Exception as e:
-            print(f'{e}')
+            print(f"{e}")
 
     def _flush_message(self):
         if len(self.buffer) == 0:
             return
         self.easymaker_api_sender.send_logncrash(logncrash_body=self.buffer)
         self.buffer = []
```

## easymaker/storage/objectstorage.py

```diff
@@ -1,85 +1,81 @@
 # -*- coding: utf-8 -*-
-import os.path
-from requests.sessions import Session
-from requests.adapters import HTTPAdapter, Retry
 import hashlib
+import os.path
+import re
 from datetime import datetime
+
 from pytz import timezone
+from requests.adapters import HTTPAdapter, Retry
+from requests.sessions import Session
 
-from easymaker.common import constants
-from easymaker.common import exceptions
 from easymaker.api.api_sender import ApiSender
+from easymaker.common import constants, exceptions
 
 
 class ObjectStorage:
     DUPLICATE_CHECK_FILE_SIZE = 100 * 1024 * 1024  # 100MB        
     MULTIPART_UPLOAD_FILE_SIZE_THRESHOLD = 2 * 1024 * 1024 * 1024  # 2GB    (2,147,483,647bytes  OverflowError  5G->2G )
     MULTIPART_UPLOAD_CHUNK_SIZE = 500 * 1024 * 1024  # 500MB    
     MAX_OBJECT_LIST_COUNT = 10000
 
     def __init__(self, easymaker_region=None, username=None, password=None):
         self.token_expires = None
         self.api_sender = None
 
         if easymaker_region:
             self.region = easymaker_region
-        elif os.environ.get('EM_REGION'):
-            self.region = os.environ.get('EM_REGION')
+        elif os.environ.get("EM_REGION"):
+            self.region = os.environ.get("EM_REGION")
         else:
             self.region = constants.DEFAULT_REGION
         self.username = username
         self.password = password
 
         self.session = Session()
-        self.session.mount('https://', HTTPAdapter(max_retries=Retry(total=3, backoff_factor=1)))
+        self.session.mount("https://", HTTPAdapter(max_retries=Retry(total=3, backoff_factor=1)))
 
     def _get_token(self, tenant_id=None):
         if tenant_id:
             self.tenant_id = tenant_id
 
         if self.token_expires is not None:
-            if os.environ.get('EM_TOKEN'):
-                self.now = datetime.now(timezone('Asia/Seoul'))
+            if os.environ.get("EM_TOKEN"):
+                self.now = datetime.now(timezone("Asia/Seoul"))
             else:
                 self.now = datetime.utcnow()
             time_diff = self.token_expires - self.now
             if time_diff.total_seconds() > 600:
                 return
 
-        self.api_sender = ApiSender(self.region,
-                                    os.environ.get('EM_APPKEY'),
-                                    os.environ.get('EM_SECRET_KEY'))
-        response = self.api_sender.get_objectstorage_token(tenant_id=self.tenant_id,
-                                                           username=self.username,
-                                                           password=self.password)
+        self.api_sender = ApiSender(self.region, os.environ.get("EM_APPKEY"), os.environ.get("EM_SECRET_KEY"))
+        response = self.api_sender.get_objectstorage_token(tenant_id=self.tenant_id, username=self.username, password=self.password)
         try:
-            self.token = response['access']['token']
+            self.token = response["access"]["token"]
         except KeyError:
             print(response)
 
-        self.token_id = self.token['id']
+        self.token_id = self.token["id"]
 
-        if os.environ.get('EM_TOKEN'):
-            self.token_expires = datetime.strptime(self.token['expires'], '%Y-%m-%dT%H:%M:%S.%f%z')
+        if os.environ.get("EM_TOKEN"):
+            self.token_expires = datetime.strptime(self.token["expires"], "%Y-%m-%dT%H:%M:%S.%f%z")
         else:
-            self.token_expires = datetime.strptime(self.token['expires'], '%Y-%m-%dT%H:%M:%SZ')
+            self.token_expires = datetime.strptime(self.token["expires"], "%Y-%m-%dT%H:%M:%SZ")
 
     def _get_request_header(self):
         self._get_token(self.tenant_id)
-        return {'X-Auth-Token': self.token_id}
+        return {"X-Auth-Token": self.token_id}
 
     def _get_object_list(self, container_url, req_header, object_path, maker=None):
-        response = self.session.get(container_url, headers=req_header, params={'prefix': object_path,
-                                                                               'marker': maker})
+        response = self.session.get(container_url, headers=req_header, params={"prefix": object_path, "marker": maker})
 
         if response.status_code != 200 and response.status_code != 204:
             raise exceptions.EasyMakerError(response)
 
-        return response.text.split('\n')[:-1]
+        return response.text.split("\n")[:-1]
 
     def upload(self, easymaker_obs_uri, local_path):
         """
         Args:
             easymaker_obs_uri : easymaker obs directory uri (obs://{object_storage_endpoint}/{container_name}/{path})
             local_path : upload local path (file or directory)
         """
@@ -88,26 +84,24 @@
 
         if os.path.isfile(local_path):
             upload_url = os.path.join(obs_full_url, os.path.basename(local_path))
             self._upload_file(upload_url, local_path)
 
         if os.path.isdir(local_path):
             file_path_list = []
-            for (root, dirs, files) in os.walk(local_path):
+            for root, dirs, files in os.walk(local_path):
                 for file in files:
                     file_path_list.append(os.path.join(root, file))
 
             for upload_file_path in file_path_list:
-                upload_url = os.path.join(obs_full_url,
-                                          os.path.relpath(upload_file_path,
-                                                          os.path.abspath(local_path)))
+                upload_url = os.path.join(obs_full_url, os.path.relpath(upload_file_path, os.path.abspath(local_path)))
                 self._upload_file(upload_url, upload_file_path)
 
     def _calc_file_md5_hash(self, file_path):
-        f = open(file_path, 'rb')
+        f = open(file_path, "rb")
         data = f.read()
         hash = hashlib.md5(data).hexdigest()
         return hash
 
     def _is_duplicate_file(self, request_url, local_file_path):
         file_size = os.path.getsize(local_file_path)
 
@@ -117,17 +111,17 @@
         self._get_token(self.tenant_id)
         req_header = self._get_request_header()
 
         response = self.session.head(request_url, headers=req_header)
         if response.status_code != 200:
             return False
 
-        if response.headers['content-length'] == str(file_size):
+        if response.headers["content-length"] == str(file_size):
             #   ETag    ETag      (concatenate) MD5        
-            if response.headers['etag'] == self._calc_file_md5_hash(local_file_path):
+            if response.headers["etag"] == self._calc_file_md5_hash(local_file_path):
                 return True
 
         return False
 
     def _upload_file(self, upload_url, upload_file_path):
         """
         Upload files under 5G
@@ -138,49 +132,48 @@
         if self._is_duplicate_file(upload_url, upload_file_path):
             return
 
         if os.path.getsize(upload_file_path) >= self.MULTIPART_UPLOAD_FILE_SIZE_THRESHOLD:
             return self._upload_large_file(upload_url, upload_file_path)
 
         req_header = self._get_request_header()
-        with open(upload_file_path, 'rb') as f:
+        with open(upload_file_path, "rb") as f:
             return self.session.put(upload_url, headers=req_header, data=f.read())
 
     def _upload_large_file(self, upload_url, upload_file_path):
         """
         Objects with a capacity exceeding 2 GB are uploaded in segments of 2 GB or less.
         """
         req_header = self._get_request_header()
 
-        with open(upload_file_path, 'rb') as f:
+        with open(upload_file_path, "rb") as f:
             chunk_index = 1
             chunk_size = self.MULTIPART_UPLOAD_CHUNK_SIZE
             total_bytes_read = 0
             obj_size = os.path.getsize(upload_file_path)
 
             while total_bytes_read < obj_size:
                 remained_bytes = obj_size - total_bytes_read
                 if remained_bytes < chunk_size:
                     chunk_size = remained_bytes
 
-                request_url = '%s/%03d' % (upload_url, chunk_index)
-                self.session.put(
-                    request_url, headers=req_header, data=f.read(chunk_size))
+                request_url = "%s/%03d" % (upload_url, chunk_index)
+                self.session.put(request_url, headers=req_header, data=f.read(chunk_size))
                 total_bytes_read += chunk_size
                 f.seek(total_bytes_read)
                 chunk_index += 1
 
         # create manifest
         req_header = self._get_request_header()
         # X-Object-Manifest : AUTH_*****/  
-        uri_element_list = upload_url.split('/')
+        uri_element_list = upload_url.split("/")
         for idx, val in enumerate(uri_element_list):
-            if val.startswith('AUTH_'):
-                object_manifest = '/'.join(uri_element_list[idx + 1:])
-        req_header['X-Object-Manifest'] = object_manifest
+            if val.startswith("AUTH_"):
+                object_manifest = "/".join(uri_element_list[idx + 1 :])
+        req_header["X-Object-Manifest"] = object_manifest
         return self.session.put(upload_url, headers=req_header)
 
     def download(self, easymaker_obs_uri, download_dir_path):
         """
         Args:
             easymaker_obs_uri : easymaker obs uri (obs://{object_storage_endpoint}/{container_name}/{path})
             download_dir_path : download local path (directory)
@@ -193,27 +186,27 @@
     def _download(self, easymaker_obs_uri, download_dir_path, maker=None):
         obs_full_url, _, container_url, tenant_id, _, object_prefix = parse_obs_uri(easymaker_obs_uri)
         self._get_token(tenant_id)
         isDirectoryObject = False
         file_object_list = []
         object_list = self._get_object_list(container_url, self._get_request_header(), object_prefix, maker)
         for obj in object_list:
-            if (object_prefix.endswith('/') == False) and (obj == object_prefix):  # target object is file
+            if (object_prefix.endswith("/") == False) and (obj == object_prefix):  # target object is file
                 download_file_path = os.path.join(download_dir_path, os.path.basename(object_prefix))
                 # object : depth1/file1
                 # download_file_path => download_dir_path + /file1
                 self._download_file(container_url, object_prefix, download_file_path)
                 return object_list
 
-            if object_prefix.endswith('/') == False:
-                object_prefix = ''.join([object_prefix, '/'])
+            if object_prefix.endswith("/") == False:
+                object_prefix = "".join([object_prefix, "/"])
 
             if obj.startswith(object_prefix):
                 isDirectoryObject = True
-                if not obj.endswith('/'):
+                if not obj.endswith("/"):
                     file_object_list.append(obj)
 
         if isDirectoryObject:
             for file_object in file_object_list:
                 download_file_path = os.path.join(download_dir_path, os.path.relpath(file_object, object_prefix))
                 # object : deps1/deps2, file_object : deps1/deps2/deps3/file1
                 # download_file_path => download_dir_path + /deps3/file1
@@ -228,21 +221,21 @@
             download_file_path : download local path (file)
         """
         request_url = os.path.join(container_url, file_object)
         req_header = self._get_request_header()
         response = self.session.get(request_url, headers=req_header)
 
         if response.status_code != 200:
-            raise exceptions.EasyMakerError(f'Object storage download fail {response.json()}')
+            raise exceptions.EasyMakerError(f"Object storage download fail {response.json()}")
         download_file_dir = os.path.dirname(download_file_path)
         if os.path.isfile(download_file_dir):
-            raise exceptions.EasyMakerError(f'{download_file_dir} already exists as file. Please check if there is a file and a folder with the same names in object storage.')
-     
+            raise exceptions.EasyMakerError(f"{download_file_dir} already exists as file. Please check if there is a file and a folder with the same names in object storage.")
+
         os.makedirs(os.path.dirname(download_file_path), exist_ok=True)
-        with open(download_file_path, 'wb') as f:
+        with open(download_file_path, "wb") as f:
             f.write(response.content)
 
     def find_object_list(self, easymaker_obs_uri, file_extension=None):
         _, _, container_url, tenant_id, _, object_prefix = parse_obs_uri(easymaker_obs_uri)
         self._get_token(tenant_id)
         object_list = self._get_object_list(container_url, self._get_request_header(), object_prefix)
 
@@ -260,64 +253,49 @@
         _, _, container_url, tenant_id, _, object_prefix = parse_obs_uri(easymaker_obs_uri)
         self._get_token(tenant_id)
 
         isDirectoryObject = False
         file_object_list = []
         object_list = self.find_object_list(easymaker_obs_uri, file_extension)
         for object in object_list:
-            if (object_prefix.endswith('/') == False) and (object == object_prefix):  # target object is file
+            if (object_prefix.endswith("/") == False) and (object == object_prefix):  # target object is file
                 request_url = os.path.join(container_url, object_prefix)
                 return self._delete_file(request_url)
 
-            if object_prefix.endswith('/') == False:
-                object_prefix = ''.join([object_prefix, '/'])
+            if object_prefix.endswith("/") == False:
+                object_prefix = "".join([object_prefix, "/"])
 
             if object.startswith(object_prefix):
                 isDirectoryObject = True
-                if not object.endswith('/'):
+                if not object.endswith("/"):
                     file_object_list.append(object)
 
         if isDirectoryObject:
             for file_object in file_object_list:
                 request_url = os.path.join(container_url, file_object)
                 self._delete_file(request_url)
 
     def _delete_file(self, request_url):
-        print(f'Delete Object : {request_url}')
+        print(f"Delete Object : {request_url}")
         response = self.session.delete(request_url, headers=self._get_request_header())
         if response.status_code != 200 and response.status_code != 204 and response.status_code != 404:
             raise exceptions.EasyMakerError(response)
 
         return response
 
 
 def parse_obs_uri(easymaker_obs_uri):
-    uri_split = easymaker_obs_uri.split("://")
-
-    if len(uri_split) != 2 or uri_split[0].lower() != 'obs' or len(uri_split[1].split('//')) > 1:
-        raise exceptions.EasyMakerError(f'Object storage uri parse fail. Invalid uri {easymaker_obs_uri}')
-
-    obs_full_url = 'https://' + uri_split[1]
-
-    uri_list = obs_full_url.split('/')
-
-    if len(uri_list) < 7:
-        raise exceptions.EasyMakerError(f'Object storage uri parse fail. Invalid uri {easymaker_obs_uri}')
-
-    obs_host = uri_list[2]
-    if uri_list[4].startswith('AUTH_'):
-        tenant_id = uri_list[4][5:]
-        container_url = '/'.join(uri_list[:6])
-    else:
-        raise exceptions.EasyMakerError(f'Object storage uri parse fail. Invalid uri {easymaker_obs_uri}')
+    obs_full_url, number_of_subs_made = re.subn("^(obs)://(.+)$", r"https://\2", easymaker_obs_uri)
+    obs_uri_pattern = re.compile("^(?P<container_url>https://(?P<obs_host>[^/]+)/(?P<version>[^/]+)/AUTH_(?P<tenant_id>[^/]+)/(?P<container_name>[^/]+))/?(?P<object_prefix>.*)$")
+    match = obs_uri_pattern.match(obs_full_url)
 
-    container_name = uri_list[5]
-    object_prefix = '/'.join(uri_list[6:])
+    if number_of_subs_made != 1 or match is None:
+        raise exceptions.EasyMakerError(f"Object storage uri parse fail. Invalid uri {easymaker_obs_uri}")
 
-    return obs_full_url, obs_host, container_url, tenant_id, container_name, object_prefix
+    return obs_full_url, match.group("obs_host"), match.group("container_url"), match.group("tenant_id"), match.group("container_name"), match.group("object_prefix")
 
 
 def download(easymaker_obs_uri, download_dir_path, easymaker_region=None, username=None, password=None):
     """
     Args:
         easymaker_obs_uri (str): easymaker obs uri (obs://{object_storage_endpoint}/{container_name}/{path})
         download_dir_path (str): download local path (directory)
```

## easymaker/training/hyperparameter_tuning.py

```diff
@@ -1,120 +1,122 @@
 import time
 from datetime import timedelta
+
 import easymaker
-from easymaker.common import exceptions
-from easymaker.common import utils
+from easymaker.common import constants, exceptions, utils
 from easymaker.common.utils import status_code_utils
-from easymaker.common import constants
 
 
 class HyperparameterTuning:
     _framework_name = None
     _framework_version = None
 
     def __init__(self):
         self.easymaker_api_sender = easymaker.easymaker_config.api_sender
         self.instance_list = self.easymaker_api_sender.get_instance_list()
         self.image_list = self.easymaker_api_sender.get_image_list()
         self.algorithm_list = self.easymaker_api_sender.get_algorithm_list()
 
-    def run(self,
-            experiment_id=None,
-            hyperparameter_tuning_name=None,
-            hyperparameter_tuning_description=None,
-            algorithm_name=None,
-            image_name=None,
-            instance_name=None,
-            distributed_node_count=1,  # Integer
-            parallel_trial_count=1,  # Integer
-            data_storage_size=None,
-            source_dir_uri=None,
-            entry_point=None,
-            hyperparameter_spec_list=None,  # [{"name": "","type": easymaker.HYPERPARAMETER_TYPE_CODE,"feasibleSpace": {"min": "","max": "","list": "","step": "",}}, ]
-            dataset_list=None,
-            check_point_input_uri=None,
-            check_point_upload_uri=None,
-            model_upload_uri=None,
-            timeout_hours=720,
-            tag_list=None,
-            use_log=False,
-            wait=True,
-            metric_list=None,  # name    [{"name": ""}, {"name": ""}]  
-            metric_regex=None,  # ""
-            objective_metric_name=None,  # name   {"name": ""}  
-            objective_type_code=None,  # easymaker.OBJECTIVE_TYPE_CODE.MINIMIZE, MAXIMIZE
-            objective_goal=None,  # double
-            max_failed_trial_count=None,  # Integer
-            max_trial_count=None,  # Integer
-            tuning_strategy_name=None,  # easymaker.TUNING_STRATEGY.BAYESIAN_OPTIMIZATION, RANDOM, GRID
-            tuning_strategy_random_state=None,  # Integer
-            early_stopping_algorithm=None,  # easymaker.EARLY_STOPPING_ALGORITHM.MEDIAN
-            early_stopping_min_trial_count=3,
-            early_stopping_start_step=4,
-            use_torchrun=False,
-            nproc_per_node=0,
-            ):
+    def run(
+        self,
+        experiment_id=None,
+        hyperparameter_tuning_name=None,
+        hyperparameter_tuning_description=None,
+        algorithm_name=None,
+        image_name=None,
+        instance_name=None,
+        distributed_node_count=1,  # Integer
+        parallel_trial_count=1,  # Integer
+        data_storage_size=None,
+        source_dir_uri=None,
+        entry_point=None,
+        hyperparameter_spec_list=None,  # [{"name": "","type": easymaker.HYPERPARAMETER_TYPE_CODE,"feasibleSpace": {"min": "","max": "","list": "","step": "",}}, ]
+        dataset_list=None,
+        check_point_input_uri=None,
+        check_point_upload_uri=None,
+        model_upload_uri=None,
+        timeout_hours=720,
+        tag_list=None,
+        use_log=False,
+        wait=True,
+        metric_list=None,  # name    [{"name": ""}, {"name": ""}]  
+        metric_regex=None,  # ""
+        objective_metric_name=None,  # name   {"name": ""}  
+        objective_type_code=None,  # easymaker.OBJECTIVE_TYPE_CODE.MINIMIZE, MAXIMIZE
+        objective_goal=None,  # double
+        max_failed_trial_count=None,  # Integer
+        max_trial_count=None,  # Integer
+        tuning_strategy_name=None,  # easymaker.TUNING_STRATEGY.BAYESIAN_OPTIMIZATION, RANDOM, GRID
+        tuning_strategy_random_state=None,  # Integer
+        early_stopping_algorithm=None,  # easymaker.EARLY_STOPPING_ALGORITHM.MEDIAN
+        early_stopping_min_trial_count=3,
+        early_stopping_start_step=4,
+        use_torchrun=False,
+        nproc_per_node=0,
+    ):
         """
         Returns:
             hyperparameter_tuning_id
         """
+
         def convertMetricFormat(name):
             return {"name": name}
 
         # run hyperparameter tuning
-        response = self.easymaker_api_sender.run_hyperparameter_tuning(hyperparameter_tuning_name=hyperparameter_tuning_name,
-                                                                       hyperparameter_tuning_description=hyperparameter_tuning_description,
-                                                                       experiment_id=experiment_id,
-                                                                       algorithm_id=utils.from_name_to_id(self.algorithm_list, algorithm_name) if algorithm_name else None,
-                                                                       image_id=utils.from_name_to_id(self.image_list, image_name),
-                                                                       flavor_id=utils.from_name_to_id(self.instance_list, instance_name),
-                                                                       distributed_node_count=distributed_node_count,
-                                                                       parallel_trial_count=parallel_trial_count,
-                                                                       data_storage_size=data_storage_size,
-                                                                       source_dir_uri=source_dir_uri,
-                                                                       entry_point=entry_point,
-                                                                       hyperparameter_spec_list=hyperparameter_spec_list,
-                                                                       dataset_list=dataset_list,
-                                                                       check_point_input_uri=check_point_input_uri,
-                                                                       check_point_upload_uri=check_point_upload_uri,
-                                                                       model_upload_uri=model_upload_uri,
-                                                                       timeout_hours=timeout_hours,
-                                                                       tag_list=tag_list,
-                                                                       use_log=use_log,
-                                                                       metric_list=list(map(convertMetricFormat, metric_list)) if metric_list else None,
-                                                                       metric_regex=metric_regex,
-                                                                       objective_metric=convertMetricFormat(objective_metric_name) if objective_metric_name else None,
-                                                                       objective_type_code=objective_type_code,
-                                                                       objective_goal=objective_goal,
-                                                                       max_failed_trial_count=max_failed_trial_count,
-                                                                       max_trial_count=max_trial_count,
-                                                                       tuning_strategy_name=tuning_strategy_name,
-                                                                       tuning_strategy_random_state=tuning_strategy_random_state,
-                                                                       early_stopping_algorithm=early_stopping_algorithm,
-                                                                       early_stopping_min_trial_count=early_stopping_min_trial_count,
-                                                                       early_stopping_start_step=early_stopping_start_step,
-                                                                       use_torchrun=use_torchrun,
-                                                                       nproc_per_node=nproc_per_node,
-                                                                       )
+        response = self.easymaker_api_sender.run_hyperparameter_tuning(
+            hyperparameter_tuning_name=hyperparameter_tuning_name,
+            hyperparameter_tuning_description=hyperparameter_tuning_description,
+            experiment_id=experiment_id,
+            algorithm_id=utils.from_name_to_id(self.algorithm_list, algorithm_name) if algorithm_name else None,
+            image_id=utils.from_name_to_id(self.image_list, image_name),
+            flavor_id=utils.from_name_to_id(self.instance_list, instance_name),
+            distributed_node_count=distributed_node_count,
+            parallel_trial_count=parallel_trial_count,
+            data_storage_size=data_storage_size,
+            source_dir_uri=source_dir_uri,
+            entry_point=entry_point,
+            hyperparameter_spec_list=hyperparameter_spec_list,
+            dataset_list=dataset_list,
+            check_point_input_uri=check_point_input_uri,
+            check_point_upload_uri=check_point_upload_uri,
+            model_upload_uri=model_upload_uri,
+            timeout_hours=timeout_hours,
+            tag_list=tag_list,
+            use_log=use_log,
+            metric_list=list(map(convertMetricFormat, metric_list)) if metric_list else None,
+            metric_regex=metric_regex,
+            objective_metric=convertMetricFormat(objective_metric_name) if objective_metric_name else None,
+            objective_type_code=objective_type_code,
+            objective_goal=objective_goal,
+            max_failed_trial_count=max_failed_trial_count,
+            max_trial_count=max_trial_count,
+            tuning_strategy_name=tuning_strategy_name,
+            tuning_strategy_random_state=tuning_strategy_random_state,
+            early_stopping_algorithm=early_stopping_algorithm,
+            early_stopping_min_trial_count=early_stopping_min_trial_count,
+            early_stopping_start_step=early_stopping_start_step,
+            use_torchrun=use_torchrun,
+            nproc_per_node=nproc_per_node,
+        )
 
-        hyperparameter_tuning_id = response['hyperparameterTuning']['hyperparameterTuningId']
+        hyperparameter_tuning_id = response["hyperparameterTuning"]["hyperparameterTuningId"]
         if wait:
             waiting_time_seconds = 0
-            hyperparameter_tuning_status = status_code_utils.replace_status_code(response['hyperparameterTuning']['hyperparameterTuningStatusCode'])
-            while hyperparameter_tuning_status != 'COMPLETE':
-                print(f'[AI EasyMaker] Hyperparameter Tuning create status : {hyperparameter_tuning_status} ({timedelta(seconds=waiting_time_seconds)}) Please wait...')
+            hyperparameter_tuning_status = status_code_utils.replace_status_code(response["hyperparameterTuning"]["hyperparameterTuningStatusCode"])
+            while hyperparameter_tuning_status != "COMPLETE":
+                print(f"[AI EasyMaker] Hyperparameter Tuning create status : {hyperparameter_tuning_status} ({timedelta(seconds=waiting_time_seconds)}) Please wait...")
                 time.sleep(constants.EASYMAKER_API_WAIT_INTERVAL_SECONDS)
                 waiting_time_seconds += constants.EASYMAKER_API_WAIT_INTERVAL_SECONDS
                 hyperparameter_tuning = self.easymaker_api_sender.get_hyperparameter_tuning_by_id(hyperparameter_tuning_id)
-                hyperparameter_tuning_status = status_code_utils.replace_status_code(hyperparameter_tuning['hyperparameterTuning']['hyperparameterTuningStatusCode'])
-                if 'FAIL' in hyperparameter_tuning_status or 'STOPPED' in hyperparameter_tuning_status:
-                    hyperparameter_tuning['hyperparameterTuning']['hyperparameterTuningStatusCode'] = hyperparameter_tuning_status
+                hyperparameter_tuning_status = status_code_utils.replace_status_code(hyperparameter_tuning["hyperparameterTuning"]["hyperparameterTuningStatusCode"])
+                if "FAIL" in hyperparameter_tuning_status or "STOPPED" in hyperparameter_tuning_status:
+                    hyperparameter_tuning["hyperparameterTuning"]["hyperparameterTuningStatusCode"] = hyperparameter_tuning_status
                     raise exceptions.EasyMakerError(hyperparameter_tuning)
-            print(f'[AI EasyMaker] Hyperparameter Tuning create complete. Hyperparameter Tuning Id : {hyperparameter_tuning_id}')
+            print(f"[AI EasyMaker] Hyperparameter Tuning create complete. Hyperparameter Tuning Id : {hyperparameter_tuning_id}")
         else:
-            print(f'[AI EasyMaker] Hyperparameter Tuning create request complete. Hyperparameter Tuning Id : {hyperparameter_tuning_id}')
+            print(f"[AI EasyMaker] Hyperparameter Tuning create request complete. Hyperparameter Tuning Id : {hyperparameter_tuning_id}")
         return hyperparameter_tuning_id
 
     def delete(self, hyperparameter_tuning_id):
         response = self.easymaker_api_sender.delete_hyperparameter_tuning_by_id(hyperparameter_tuning_id=hyperparameter_tuning_id)
-        print(f'[AI EasyMaker] Hyperparameter Tuning delete request complete. Hyperparameter Tuning Id : {hyperparameter_tuning_id}')
-        return response
+        print(f"[AI EasyMaker] Hyperparameter Tuning delete request complete. Hyperparameter Tuning Id : {hyperparameter_tuning_id}")
+        return response
```

## easymaker/training/model.py

```diff
@@ -1,65 +1,59 @@
 import easymaker
 
 
 class Model:
     def __init__(self):
         self.easymaker_api_sender = easymaker.easymaker_config.api_sender
 
-    def create(self,
-               model_name,
-               training_id=None,
-               hyperparameter_tuning_id=None,
-               model_description=None,
-               tag_list=None,
-               ):
+    def create(
+        self,
+        model_name,
+        training_id=None,
+        hyperparameter_tuning_id=None,
+        model_description=None,
+        tag_list=None,
+    ):
         """
         Args:
             model_name (str): Experiment name
             training_id (str): Training ID
             hyperparameter_tuning_id (str): Hyperparameter Tuning ID
             model_description (str): Experiment description
             tag_list (list): tags
         Returns:
             model_id
         """
-        response = self.easymaker_api_sender.create_model(model_name=model_name,
-                                                          training_id=training_id,
-                                                          hyperparameter_tuning_id=hyperparameter_tuning_id,
-                                                          model_description=model_description,
-                                                          tag_list=tag_list)
+        response = self.easymaker_api_sender.create_model(model_name=model_name, training_id=training_id, hyperparameter_tuning_id=hyperparameter_tuning_id, model_description=model_description, tag_list=tag_list)
 
-        self.model_id = response['model']['modelId']
-        print(f'[AI EasyMaker] Model create complete. Model Id : {self.model_id}')
+        self.model_id = response["model"]["modelId"]
+        print(f"[AI EasyMaker] Model create complete. Model Id : {self.model_id}")
         return self.model_id
 
-    def create_by_model_uri(self,
-                            model_name,
-                            framework_code,
-                            model_uri,
-                            model_description=None,
-                            tag_list=None,
-                            ):
+    def create_by_model_uri(
+        self,
+        model_name,
+        framework_code,
+        model_uri,
+        model_description=None,
+        tag_list=None,
+    ):
         """
         Args:
             model_name (str): Experiment name
             framework_code (str): easymaker.TENSORFLOW or easymaker.PYTORCH
             model_uri (str): model uri (NHN Cloud Object Storage or NAS)
             model_description (str): Experiment description
             tag_list (list): tags
         Returns:
             model_id
         """
-        response = self.easymaker_api_sender.create_model(model_name=model_name,
-                                                          framework_code=framework_code,
-                                                          model_uri=model_uri,
-                                                          model_description=model_description,
-                                                          tag_list=tag_list)
+        response = self.easymaker_api_sender.create_model(model_name=model_name, framework_code=framework_code, model_uri=model_uri, model_description=model_description, tag_list=tag_list)
 
-        self.model_id = response['model']['modelId']
-        print(f'[AI EasyMaker] Model create complete. Model Id : {self.model_id}')
+        self.model_id = response["model"]["modelId"]
+        print(f"[AI EasyMaker] Model create complete. Model Id : {self.model_id}")
         return self.model_id
 
     def delete(self, model_id):
         response = self.easymaker_api_sender.delete_model_by_id(model_id=model_id)
-        print(f'[AI EasyMaker] Model delete request complete. Model Id : {model_id}')
-        return response
+        print(f"[AI EasyMaker] Model delete request complete. Model Id : {model_id}")
+        return response
```

## easymaker/training/training.py

```diff
@@ -1,92 +1,71 @@
 import time
 from datetime import timedelta
+
 import easymaker
-from easymaker.common import exceptions
-from easymaker.common import utils
+from easymaker.common import constants, exceptions, utils
 from easymaker.common.utils import status_code_utils
-from easymaker.common import constants
 
 
 class Training:
     _framework_name = None
     _framework_version = None
 
     def __init__(self):
         self.easymaker_api_sender = easymaker.easymaker_config.api_sender
         self.instance_list = self.easymaker_api_sender.get_instance_list()
         self.image_list = self.easymaker_api_sender.get_image_list()
         self.algorithm_list = self.easymaker_api_sender.get_algorithm_list()
 
-    def run(self,
-            experiment_id=None,
-            training_name=None,
-            training_description=None,
-            train_image_name=None,
-            train_instance_name=None,
-            distributed_node_count=1,
-            data_storage_size=None,
-            source_dir_uri=None,
-            entry_point=None,
-            algorithm_name=None,
-            hyperparameter_list=None,
-            dataset_list=None,
-            check_point_input_uri=None,
-            check_point_upload_uri=None,
-            model_upload_uri=None,
-            timeout_hours=720,
-            tag_list=None,
-            use_log=False,
-            wait=True,
-            use_torchrun=False,
-            nproc_per_node=0
-            ):
+    def run(self, experiment_id=None, training_name=None, training_description=None, train_image_name=None, train_instance_name=None, distributed_node_count=1, data_storage_size=None, source_dir_uri=None, entry_point=None, algorithm_name=None, hyperparameter_list=None, dataset_list=None, check_point_input_uri=None, check_point_upload_uri=None, model_upload_uri=None, timeout_hours=720, tag_list=None, use_log=False, wait=True, use_torchrun=False, nproc_per_node=0):
         """
         Returns:
             training_id
         """
 
         # run training
-        response = self.easymaker_api_sender.run_training(training_name=training_name,
-                                                          training_description=training_description,
-                                                          experiment_id=experiment_id,
-                                                          image_id=utils.from_name_to_id(self.image_list, train_image_name),
-                                                          flavor_id=utils.from_name_to_id(self.instance_list, train_instance_name),
-                                                          distributed_node_count=distributed_node_count,
-                                                          data_storage_size=data_storage_size,
-                                                          source_dir_uri=source_dir_uri,
-                                                          entry_point=entry_point,
-                                                          algorithm_id=utils.from_name_to_id(self.algorithm_list, algorithm_name) if algorithm_name else None,
-                                                          hyperparameter_list=hyperparameter_list,
-                                                          dataset_list=dataset_list,
-                                                          check_point_input_uri=check_point_input_uri,
-                                                          check_point_upload_uri=check_point_upload_uri,
-                                                          model_upload_uri=model_upload_uri,
-                                                          training_type_code='NORMAL',
-                                                          timeout_hours=timeout_hours,
-                                                          tag_list=tag_list,
-                                                          use_log=use_log,
-                                                          use_torchrun=use_torchrun,
-                                                          nproc_per_node=nproc_per_node)
+        response = self.easymaker_api_sender.run_training(
+            training_name=training_name,
+            training_description=training_description,
+            experiment_id=experiment_id,
+            image_id=utils.from_name_to_id(self.image_list, train_image_name),
+            flavor_id=utils.from_name_to_id(self.instance_list, train_instance_name),
+            distributed_node_count=distributed_node_count,
+            data_storage_size=data_storage_size,
+            source_dir_uri=source_dir_uri,
+            entry_point=entry_point,
+            algorithm_id=utils.from_name_to_id(self.algorithm_list, algorithm_name) if algorithm_name else None,
+            hyperparameter_list=hyperparameter_list,
+            dataset_list=dataset_list,
+            check_point_input_uri=check_point_input_uri,
+            check_point_upload_uri=check_point_upload_uri,
+            model_upload_uri=model_upload_uri,
+            training_type_code="NORMAL",
+            timeout_hours=timeout_hours,
+            tag_list=tag_list,
+            use_log=use_log,
+            use_torchrun=use_torchrun,
+            nproc_per_node=nproc_per_node,
+        )
 
-        training_id = response['training']['trainingId']
+        training_id = response["training"]["trainingId"]
         if wait:
             waiting_time_seconds = 0
-            training_status = status_code_utils.replace_status_code(response['training']['trainingStatusCode'])
-            while training_status != 'COMPLETE':
-                print(f'[AI EasyMaker] Training create status : {training_status} ({timedelta(seconds=waiting_time_seconds)}) Please wait...')
+            training_status = status_code_utils.replace_status_code(response["training"]["trainingStatusCode"])
+            while training_status != "COMPLETE":
+                print(f"[AI EasyMaker] Training create status : {training_status} ({timedelta(seconds=waiting_time_seconds)}) Please wait...")
                 time.sleep(constants.EASYMAKER_API_WAIT_INTERVAL_SECONDS)
                 waiting_time_seconds += constants.EASYMAKER_API_WAIT_INTERVAL_SECONDS
                 training = self.easymaker_api_sender.get_training_by_id(training_id)
-                training_status = status_code_utils.replace_status_code(training['training']['trainingStatusCode'])
-                if 'FAIL' in training_status or 'STOPPED' in training_status:
-                    training['training']['trainingStatusCode'] = training_status
+                training_status = status_code_utils.replace_status_code(training["training"]["trainingStatusCode"])
+                if "FAIL" in training_status or "STOPPED" in training_status:
+                    training["training"]["trainingStatusCode"] = training_status
                     raise exceptions.EasyMakerError(training)
-            print(f'[AI EasyMaker] Training create complete. Training Id : {training_id}')
+            print(f"[AI EasyMaker] Training create complete. Training Id : {training_id}")
         else:
-            print(f'[AI EasyMaker] Training create request complete. Training Id : {training_id}')
+            print(f"[AI EasyMaker] Training create request complete. Training Id : {training_id}")
         return training_id
 
     def delete(self, training_id):
         response = self.easymaker_api_sender.delete_training_by_id(training_id=training_id)
-        print(f'[AI EasyMaker] Training delete request complete. Training Id : {training_id}')
-        return response
+        print(f"[AI EasyMaker] Training delete request complete. Training Id : {training_id}")
+        return response
```

## Comparing `easymaker-1.1.4.dist-info/METADATA` & `easymaker-1.1.5b0.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 Metadata-Version: 2.1
 Name: easymaker
-Version: 1.1.4
+Version: 1.1.5b0
 Summary: AI EasyMaker SDK for Python.
 Home-page: https://www.nhncloud.com
 Author: NHN Cloud AI EasyMaker Services
 License: Apache License 2.0
 Keywords: NHN Cloud AI EasyMaker
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Programming Language :: Python :: 3.8
 Description-Content-Type: text/markdown
-Requires-Dist: pytest ~=7.1.1
-Requires-Dist: setuptools ~=57.0.0
-Requires-Dist: requests ~=2.27.1
-Requires-Dist: importlib-metadata ~=4.11.3
-Requires-Dist: argparse ~=1.4.0
-Requires-Dist: docker ~=5.0.3
-Requires-Dist: pytz ~=2022.2.1
+Requires-Dist: pytest ==7.1.1
+Requires-Dist: setuptools ==57.0.0
+Requires-Dist: requests ==2.27.1
+Requires-Dist: importlib-metadata ==4.11.3
+Requires-Dist: argparse ==1.4.0
+Requires-Dist: docker ==5.0.3
+Requires-Dist: pytz ==2022.2.1
 
 # NHN AI EasyMaker SDK
 
 ```
 # Initialize EasyMaker SDK
 import easymaker
```

